
[{
        "context": "Gradient Descent is an iterative optimization algorithm used to find a local minimum of a differentiable function. The algorithm takes steps proportional to the negative of the gradient of the function at the current point. The learning rate determines the size of these steps.",
        "question": "Explain the core mechanism of the Gradient Descent algorithm and the role of the learning rate.",
        "student_answer": "Gradient Descent is an iterative optimization method that minimizes a function by moving in the direction opposite to the function's gradient. The learning rate is a hyperparameter that controls the step size at each iteration, determining how quickly the algorithm converges to a minimum.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent. The answer is concise and accurately describes the iterative process, the use of the negative gradient, and the function of the learning rate.\"}"
    },
    {
        "context": "The bias-variance tradeoff is a fundamental concept in supervised learning. Bias is the error from erroneous assumptions in the learning algorithm, leading to underfitting. Variance is the error from sensitivity to small fluctuations in the training set, leading to overfitting. A good model balances both.",
        "question": "Describe the bias-variance tradeoff and its relationship to underfitting and overfitting.",
        "student_answer": "The bias-variance tradeoff involves balancing two types of errors. High bias stems from overly simple assumptions, causing the model to underfit the data. High variance comes from the model being too sensitive to the training data, causing it to overfit. The goal is to find a sweet spot between them.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"A perfect and clear explanation. The answer correctly defines both bias and variance and accurately links them to underfitting and overfitting, respectively.\"}"
    },
    {
        "context": "L2 Regularization, also known as Ridge Regression, adds a penalty term to the loss function that is proportional to the square of the magnitude of the coefficients. This discourages large coefficient values, effectively shrinking them towards zero and reducing model complexity to prevent overfitting.",
        "question": "What is L2 Regularization and how does it help prevent overfitting?",
        "student_answer": "L2 Regularization adds a penalty to the loss function equal to the sum of the squared values of the model's coefficients. By penalizing large coefficients, it forces the model to have smaller, more distributed weights, which reduces its complexity and makes it less likely to overfit the training data.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct. The answer accurately identifies the penalty term as the sum of squared coefficients and correctly explains its effect on reducing model complexity.\"}"
    },
    {
        "context": "A Support Vector Machine (SVM) constructs a hyperplane or set of hyperplanes in a high-dimensional space, which can be used for classification or regression. The optimal hyperplane is the one that has the largest margin, which is the distance between the hyperplane and the nearest data points (support vectors) of any class.",
        "question": "How does a Support Vector Machine (SVM) find the optimal separation boundary for classification?",
        "student_answer": "An SVM finds the optimal separation boundary by identifying the hyperplane that maximizes the margin between the different classes. The margin is defined as the distance to the closest data points from each class, which are called support vectors. Maximizing this margin leads to better generalization.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"An accurate and complete answer. It correctly identifies the concepts of maximizing the margin and the role of support vectors in defining the optimal hyperplane.\"}"
    },
    {
        "context": "The K-Means algorithm is an iterative clustering algorithm that partitions a dataset into K pre-defined, non-overlapping subgroups (clusters). It works by assigning each data point to the cluster with the nearest mean (cluster centroid) and then recalculating the centroid of each cluster based on the new assignments.",
        "question": "Explain the two main steps of the K-Means clustering algorithm.",
        "student_answer": "K-Means operates in two repeating steps. First is the 'assignment step,' where each data point is assigned to the cluster whose centroid is closest (e.g., by Euclidean distance). Second is the 'update step,' where the centroid of each cluster is recalculated as the mean of all data points assigned to it.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect. The answer correctly identifies and describes the two core iterative steps of the K-Means algorithm: assignment and update.\"}"
    },
   
    {
        "context": "L1 regularization (Lasso) adds a penalty equal to the absolute value of the magnitude of coefficients. L2 regularization (Ridge) adds a penalty equal to the square of the magnitude of coefficients. L1 can produce sparse models by shrinking some coefficients to exactly zero.",
        "question": "Contrast L1 and L2 regularization, focusing on their effect on model coefficients.",
        "student_answer": "L1 and L2 are both regularization techniques. L1 uses the squared magnitude of coefficients, which shrinks them towards zero. L2 uses the absolute value, which is why it can make some coefficients exactly zero, creating sparse models.",
        "target_json": "{\"score_30\": 5, \"key_coverage\": 50, \"missing_concepts\": [\"Correct penalty for L1\", \"Correct penalty for L2\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"There is a critical misconception here. The student has swapped the definitions and effects of L1 and L2 regularization. L1 uses the absolute value for sparsity, and L2 uses the squared value for shrinkage.\"}"
    },
    {
        "context": "In a Decision Tree, entropy is a measure of impurity or disorder in a node. A node with high entropy has a mix of different classes, while a node with zero entropy is pure (contains only one class). Information Gain is the reduction in entropy achieved by splitting the data on an attribute.",
        "question": "Explain the role of entropy and information gain in building a decision tree.",
        "student_answer": "In a decision tree, we want to increase entropy at each split. Information gain measures how much the entropy increases after a split. We choose the split that gives the highest information gain, leading to the most disordered child nodes.",
        "target_json": "{\"score_30\": 2, \"key_coverage\": 25, \"missing_concepts\": [\"Goal is to decrease entropy\", \"Information gain is reduction in entropy\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"The fundamental goal is misunderstood. The objective of a split in a decision tree is to *decrease* entropy (reduce impurity), not increase it. Information gain measures this *reduction* in entropy.\"}"
    },
    {
        "context": "The learning rate in Gradient Descent is a scalar hyperparameter that determines the step size at each iteration. A learning rate that is too small can lead to slow convergence, while a learning rate that is too large can cause the algorithm to overshoot the minimum and diverge.",
        "question": "What happens if the learning rate in Gradient Descent is set too high?",
        "student_answer": "If the learning rate is set too high, the algorithm will take very small steps towards the minimum. This will make the training process extremely slow, and it might get stuck in a local minimum before reaching the global one.",
        "target_json": "{\"score_30\": 4, \"key_coverage\": 10, \"missing_concepts\": [\"Overshooting the minimum\", \"Divergence\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"This is incorrect. A high learning rate causes the algorithm to take large steps, which often leads to overshooting the minimum and can cause the loss to oscillate or diverge, not converge slowly.\"}"
    },
    {
        "context": "The 'K' in K-Means represents the number of clusters the algorithm will partition the data into. It is a hyperparameter that must be specified by the user before running the algorithm. The choice of K significantly impacts the clustering results.",
        "question": "What does the 'K' in K-Means represent, and how is it determined?",
        "student_answer": "The 'K' in K-Means stands for 'Kernel', which is the function used to measure the distance between data points. The algorithm automatically determines the best kernel to use based on the data's distribution.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 0, \"missing_concepts\": [\"K is the number of clusters\", \"K is a user-defined hyperparameter\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"This is a fundamental misunderstanding. The K in K-Means refers to the number of clusters, a hyperparameter set by the user, not a kernel function.\"}"
    },
    {
        "context": "High variance in a model means it is highly sensitive to the training data, capturing noise as if it were a real pattern. This leads to overfitting, where the model performs well on training data but poorly on unseen test data.",
        "question": "What does it mean for a model to have high variance?",
        "student_answer": "A model with high variance is too simple and makes strong assumptions about the data. This causes it to perform poorly on both the training and test sets, a problem known as underfitting.",
        "target_json": "{\"score_30\": 3, \"key_coverage\": 10, \"missing_concepts\": [\"Sensitivity to training data\", \"Overfitting\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"The answer incorrectly describes high bias, not high variance. High variance is associated with model complexity and overfitting, not simplicity and underfitting.\"}"
    },
    
    {
        "context": "Gradient Descent is an optimization algorithm. It iteratively adjusts model parameters to minimize a loss function by moving in the direction of the negative gradient.",
        "question": "How does Gradient Descent work?",
        "student_answer": "Gradient Descent works by using a 'Stochastic Flux Capacitor' to estimate the curvature of the loss function. It then applies a 'Quantum Annealing' step to jump directly to the global minimum, bypassing local minima entirely.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 0, \"missing_concepts\": [\"Iterative steps\", \"Negative gradient\", \"Loss function\"], \"hallucinations\": [\"Stochastic Flux Capacitor\", \"Quantum Annealing step\"], \"bias_check\": false, \"feedback\": \"This answer is entirely fabricated. It uses non-existent, nonsensical terms. Gradient Descent is an iterative process of moving along the negative gradient.\"}"
    },
    {
        "context": "A Support Vector Machine (SVM) uses a hyperplane to separate data. The kernel trick allows SVMs to work in a high-dimensional feature space to find a non-linear boundary.",
        "question": "Explain the purpose of the kernel trick in SVMs.",
        "student_answer": "The kernel trick in SVMs uses a 'Laplacian Bridge' to project the data into a negative-dimensional space. This allows the 'Singularity Separator' to find a boundary that can classify even temporally entangled data points.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 0, \"missing_concepts\": [\"High-dimensional feature space\", \"Non-linear separation\"], \"hallucinations\": [\"Laplacian Bridge\", \"Negative-dimensional space\", \"Singularity Separator\"], \"bias_check\": false, \"feedback\": \"The answer is pure fiction and demonstrates a complete lack of understanding. The terms used are invented. The kernel trick enables non-linear classification by mapping data to higher dimensions.\"}"
    },
    {
        "context": "The bias-variance tradeoff involves balancing errors from a model that is too simple (bias) versus one that is too complex (variance).",
        "question": "Explain the bias-variance tradeoff.",
        "student_answer": "The bias-variance tradeoff is managed by the 'Equilibrium Constant'. High bias is countered by applying 'Inverse Complexity Filtering', while high variance is reduced using a 'Stability Manifold'. The goal is to keep the constant at 1.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 0, \"missing_concepts\": [\"Underfitting\", \"Overfitting\", \"Model complexity\"], \"hallucinations\": [\"Equilibrium Constant\", \"Inverse Complexity Filtering\", \"Stability Manifold\"], \"bias_check\": false, \"feedback\": \"This response consists of invented terminology. The concepts mentioned do not exist in the context of the bias-variance tradeoff.\"}"
    },
    {
        "context": "A Decision Tree is a supervised learning algorithm that uses a tree-like structure of decisions. Splits are made based on features to partition the data into purer subsets.",
        "question": "How does a Decision Tree make a split?",
        "student_answer": "A Decision Tree makes a split using a method called 'Recursive Entropy Inversion'. It calculates the 'Gini Flux' for each potential split and chooses the one that maximizes the 'Node Instability Coefficient', ensuring the tree grows asymmetrically.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 0, \"missing_concepts\": [\"Information Gain\", \"Gini Impurity\", \"Reducing impurity\"], \"hallucinations\": [\"Recursive Entropy Inversion\", \"Gini Flux\", \"Node Instability Coefficient\"], \"bias_check\": false, \"feedback\": \"This answer is nonsensical and uses fabricated terms. Decision trees use metrics like Gini Impurity or Information Gain to make splits that *reduce* impurity.\"}"
    },
    {
        "context": "Regularization techniques like L1 and L2 are used to prevent overfitting by adding a penalty for model complexity to the loss function.",
        "question": "What is the purpose of regularization in machine learning?",
        "student_answer": "Regularization prevents overfitting by adding a 'Complexity Tax' to the model's parameters. This is calculated using the 'Heisenberg Uncertainty Principle' for weights, which ensures that the 'Parameter Space' remains flat and avoids 'Coefficient Warping'.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 10, \"missing_concepts\": [\"Penalty term\", \"Loss function\", \"L1/L2 norms\"], \"hallucinations\": [\"Complexity Tax\", \"Heisenberg Uncertainty Principle for weights\", \"Coefficient Warping\"], \"bias_check\": false, \"feedback\": \"While the student correctly identifies the purpose (preventing overfitting), the explanation is composed of invented, pseudo-scientific terms. The mechanism is completely wrong.\"}"
    },
    
    {
        "context": "The K-Means algorithm partitions n observations into k clusters in which each observation belongs to the cluster with the nearest mean.",
        "question": "Explain how the K-Means algorithm works.",
        "student_answer": "You pick a number K. Then the algorithm puts the data into K groups. It finds the middle of the groups and moves the points around until the groups are good.",
        "target_json": "{\"score_30\": 12, \"key_coverage\": 40, \"missing_concepts\": [\"Centroid\", \"Assignment step\", \"Update step\", \"Iterative process\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"The answer provides a very high-level, non-technical intuition but lacks key terminology. It fails to mention centroids, the assignment/update steps, or the iterative nature of the algorithm.\"}"
    },
    {
        "context": "A Decision Tree uses a tree-like model of decisions. To classify an instance, it is routed down the tree from the root node. At each internal node, a test is applied to one of the instance's attributes, and each branch from the node corresponds to a possible outcome of the test.",
        "question": "How does a trained Decision Tree classify a new data point?",
        "student_answer": "The new data point goes into the top of the tree. It answers questions at each level and then follows the path down. At the end, it lands in a leaf, and that's the prediction.",
        "target_json": "{\"score_30\": 15, \"key_coverage\": 50, \"missing_concepts\": [\"Root node\", \"Internal node\", \"Attribute test\", \"Leaf node\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"The answer is conceptually correct but lacks the specific terminology of decision trees. It omits terms like root/internal/leaf nodes and attribute tests.\"}"
    },
    {
        "context": "The bias-variance tradeoff is a central problem in supervised learning. Bias is error from erroneous assumptions (underfitting), and variance is error from sensitivity to small fluctuations in the training set (overfitting).",
        "question": "Describe the bias-variance tradeoff.",
        "student_answer": "It's about the model's errors. If the model is too simple, it has high bias. If it's too complex, it has high variance. You need to find a balance.",
        "target_json": "{\"score_30\": 14, \"key_coverage\": 60, \"missing_concepts\": [\"Definition of bias as error from assumptions\", \"Definition of variance as sensitivity to data\", \"Link to underfitting/overfitting\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"The answer correctly links simplicity to bias and complexity to variance but fails to define what bias and variance actually are or explicitly connect them to underfitting and overfitting.\"}"
    },
    {
        "context": "L1 regularization adds a penalty term proportional to the absolute value of the coefficients. This can force some coefficients to become exactly zero, performing feature selection.",
        "question": "What is a key advantage of L1 regularization over L2?",
        "student_answer": "L1 is better because it can remove features from the model. It just gets rid of the ones that aren't important.",
        "target_json": "{\"score_30\": 16, \"key_coverage\": 65, \"missing_concepts\": [\"Sparsity\", \"Coefficients being set to zero\", \"Absolute value penalty\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"The answer identifies the main advantage (feature selection) but does not explain the mechanism. It fails to mention that it achieves this by forcing coefficients to zero, creating a sparse model.\"}"
    },
    {
        "context": "A Support Vector Machine (SVM) is a supervised learning model that uses a hyperplane to separate data into classes. The best hyperplane is the one that has the largest margin between classes.",
        "question": "What is the fundamental principle behind Support Vector Machines?",
        "student_answer": "SVMs try to draw a line between the data points of different classes. The goal is to make the space between the line and the points as big as possible.",
        "target_json": "{\"score_30\": 17, \"key_coverage\": 70, \"missing_concepts\": [\"Hyperplane\", \"Margin\", \"Support Vectors\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"The answer describes the core idea of maximizing the separation but uses informal language (line, space) instead of the correct terms (hyperplane, margin). It also omits the concept of support vectors.\"}"
    },
    
    {
        "context": "Convolutional Neural Networks (CNNs) are highly effective for image processing tasks because they utilize convolutional layers that scan over input data using kernels, enabling local feature extraction and spatial hierarchy learning.",
        "question": "Why are convolutional layers important in CNNs for image data?",
        "student_answer": "They help the network look at small parts of an image at a time to find features.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 80, \"missing_concepts\": [\"spatial hierarchy learning\", \"kernels\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of localized feature extraction, but did not mention how layers capture hierarchical representations or the role of kernels.\"}"
    },
    {
        "context": "Recurrent Neural Networks (RNNs) process sequential data by maintaining hidden states that carry over information from previous time steps, allowing the network to model temporal dependencies.",
        "question": "What are hidden states in RNNs used for?",
        "student_answer": "Hidden states hold information from previous steps, so the model knows what came before.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Complete and accurate description of hidden states and their function in modeling temporal dependencies.\"}"
    },
    {
        "context": "Transformer models leverage self-attention mechanisms to allow each word in a sequence to attend to every other word, capturing long-range dependencies and context more effectively than RNNs.",
        "question": "How do transformers manage to capture long-range dependencies in text?",
        "student_answer": "Transformers use attention so words can focus on other words, no matter how far apart.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 90, \"missing_concepts\": [\"self-attention mechanism\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Mostly correct, but did not refer specifically to the self-attention mechanism that enables this behavior.\"}"
    },
    {
        "context": "The attention mechanism computes a weighted combination of all elements in a sequence, enabling the network to focus on specific parts of the input most relevant to each output step.",
        "question": "What role does the attention mechanism play in sequence models?",
        "student_answer": "It lets the model check out the most important parts of the input for each output.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 85, \"missing_concepts\": [\"weighted combination computation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good summary, but missed the technical detail that attention computes weighted combinations over the input.\"}"
    },
    {
        "context": "Layer normalization helps stabilize and accelerate training in deep learning architectures by normalizing activations within each layer, reducing internal covariate shift.",
        "question": "Why is layer normalization useful in deep models?",
        "student_answer": "It cleans up layer outputs so training is smoother and faster.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 80, \"missing_concepts\": [\"internal covariate shift\", \"normalizing activations\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Solid practical explanation, but missing the technical term internal covariate shift and the detail about normalizing activations.\"}"
    },
    {
        "context": "Gated Recurrent Units (GRUs) are a type of RNN cell that use update and reset gates to control the flow of information, making them efficient for sequence modeling with less risk of vanishing gradients.",
        "question": "How do GRUs reduce the risk of vanishing gradients?",
        "student_answer": "The gates in GRUs help keep important info for longer, which deals with vanishing gradients.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 95, \"missing_concepts\": [\"update gate\", \"reset gate\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct reasoning, but lacked naming the specific gates: update and reset.\"}"
    },
    {
        "context": "Feedforward layers in transformer models serve to further transform the output of attention layers by applying position-wise non-linear transformations.",
        "question": "What do feedforward layers do in a transformer?",
        "student_answer": "They process the attention output with extra nonlinear stuff at each position.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate explanation using appropriate technical language, well done.\"}"
    },
    {
        "context": "CNNs are typically composed of convolutional layers, pooling layers, and fully connected layers, which together enable hierarchical feature extraction from images.",
        "question": "Name the main types of layers in a typical CNN.",
        "student_answer": "Convolutional, pooling, and fully connected layers.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correctly listed all key layer types in CNNs.\"}"
    },
    {
        "context": "Bidirectional RNNs process sequence data both forward and backward, capturing context from both past and future time steps for each point in the sequence.",
        "question": "What is the advantage of a bidirectional RNN?",
        "student_answer": "They can see the context before and after each point in a sequence.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely correct and covers both directions of information flow.\"}"
    },
    {
        "context": "In the self-attention mechanism, input embeddings are transformed into three distinct vectors: Query (Q), Key (K), and Value (V). The Query vector represents the current token's focus. The Key vectors of all other tokens represent their 'advertised' relevance. The Value vectors contain the actual information of the tokens. An attention score is calculated by the dot product of a Query with all Keys, which is then used to create a weighted sum of the Value vectors.",
        "question": "Explain the roles of Query, Key, and Value vectors in the self-attention mechanism.",
        "student_answer": "The Query is what a word is looking for, the Key is what other words are offering, and the Value is the information they provide. The mechanism matches the Query with Keys to decide how much of each Value to use.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 90, \"missing_concepts\": [\"dot product\", \"weighted sum\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent intuitive explanation. It correctly captures the roles but omits the specific mathematical operations, namely the dot-product for scoring and the weighted sum of values.\"}"
    },
    {
        "context": "Dropout is a regularization technique for neural networks that prevents overfitting. During training, it randomly sets a fraction of input units to 0 at each update. This forces the network to learn more robust features that are not reliant on any single neuron.",
        "question": "What is Dropout and how does it work to prevent overfitting?",
        "student_answer": "Dropout is a regularization method where you randomly turn off some neurons during training. This makes the network less co-dependent and helps it generalize better to new data, thus preventing overfitting.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect. The answer correctly identifies Dropout as a regularization technique, explains its mechanism of randomly deactivating neurons, and accurately states its purpose in preventing overfitting.\"}"
    },
    {
        "context": "CNNs use convolutional filters to capture local spatial patterns, pooling to reduce dimensionality, and stacked layers to learn hierarchical features.",
        "question": "What core operation enables CNNs to extract spatially local features?",
        "student_answer": "They mostly just max-pool everything and hope the patterns show up.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 1, \"missing_concepts\": [\"convolutional filters\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"CNNs rely on convolution operations, not pooling, as the primary mechanism for detecting spatial patterns.\"}"
    },
    {
        "context": "RNNs maintain hidden states that propagate information across time steps, enabling sequence modeling.",
        "question": "How do RNNs maintain information across timesteps?",
        "student_answer": "They use a hidden state vector that keeps getting updated as each input arrives.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation with correct emphasis on hidden-state propagation.\"}"
    },
    {
        "context": "Transformers use self-attention to compute relationships between all pairs of tokens simultaneously, enabling efficient parallel processing.",
        "question": "Why are Transformers more parallelizable than RNNs?",
        "student_answer": "Because they look at all the tokens at once using self-attention instead of going step by step.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate and concise description.\"}"
    },
    {
        "context": "Attention mechanisms assign weights to different input elements, highlighting relevant information for downstream tasks.",
        "question": "What is the purpose of attention weights?",
        "student_answer": "It tells the network which parts of the input matter more.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct explanation of attention weight purpose.\"}"
    },
    {
        "context": "CNNs use kernels, strides, and padding to systematically scan input images for features.",
        "question": "What role does padding play in CNNs?",
        "student_answer": "Padding is like putting a frame around the picture so the filters don’t shrink the output too fast.",
        "target_json": "{\"score_30\": 24, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good intuition; padding preserves spatial dimensions.\"}"
    },
    {
        "context": "RNNs suffer from vanishing gradients, and LSTMs/GRUs mitigate this with gating mechanisms.",
        "question": "How do LSTMs help reduce vanishing gradients?",
        "student_answer": "They have gates that control how info flows, so stuff doesn’t vanish as fast.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 2, \"missing_concepts\": [\"cell state mechanism\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct but incomplete—LSTMs preserve long-term information using the cell state.\"}"
    },
    {
        "context": "Transformer encoders compute self-attention over all input tokens to build contextual representations.",
        "question": "What is self-attention used for in a Transformer encoder?",
        "student_answer": "It helps the model figure out how each token relates to the others.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate explanation of self-attention purpose.\"}"
    },
    {
        "context": "Pooling layers provide translation invariance and reduce spatial dimensions.",
        "question": "Why is pooling used in CNN architectures?",
        "student_answer": "To make the image smaller and kinda keep the important stuff.",
        "target_json": "{\"score_30\": 22, \"key_coverage\": 2, \"missing_concepts\": [\"translation invariance\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Correct idea, but missing mention of translation invariance.\"}"
    },
    {
        "context": "RNNs process sequences sequentially, limiting their parallelization capability.",
        "question": "What limits RNN parallelization?",
        "student_answer": "They have to go one timestep at a time since each step depends on the last.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Complete explanation.\"}"
    },
    {
        "context": "Multi-head attention allows the model to capture multiple types of token relationships by using multiple attention projections.",
        "question": "Why are multiple heads useful in attention mechanisms?",
        "student_answer": "So the model can look at different aspects of the data at once.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 2, \"missing_concepts\": [\"multiple projections\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good but missing that each head uses separate projections.\"}"
    },
    {
        "context": "CNN filters learn edges, textures, and patterns through hierarchical processing.",
        "question": "How do CNN filters progressively learn features?",
        "student_answer": "By stacking more layers so each layer picks up fancier features.",
        "target_json": "{\"score_30\": 23, \"key_coverage\": 1, \"missing_concepts\": [\"hierarchical feature learning\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"General idea correct but phrasing too vague.\"}"
    },
    {
        "context": "GRUs simplify LSTM architecture while preserving gating mechanisms for long-term memory.",
        "question": "What distinguishes a GRU from an LSTM?",
        "student_answer": "GRUs have fewer gates and are simpler but kinda do the same thing.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate summary of GRU vs LSTM.\"}"
    },
    {
        "context": "Transformers avoid recurrence entirely and rely on attention.",
        "question": "Do Transformers use recurrence to process sequences?",
        "student_answer": "Nope, they ditched that stuff and just use attention everywhere lol.",
        "target_json": "{\"score_30\": 20, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Concept correct but informal slang detected.\"}"
    },
    {
        "context": "Attention mechanisms compute weighted sums of value vectors according to compatibility scores between queries and keys.",
        "question": "What components define attention computation?",
        "student_answer": "Queries, keys, and values—kinda like matching signals.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation.\"}"
    },
    {
        "context": "CNN strides determine how far filters move during convolution.",
        "question": "How do strides affect CNN outputs?",
        "student_answer": "Bigger strides mean the filter jumps more, so the output shrinks.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct and clear description.\"}"
    },
    {
        "context": "RNNs encode sequence order inherently due to their stepwise processing.",
        "question": "How do RNNs inherently capture sequence order?",
        "student_answer": "Because they read stuff in order, one token after the other.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 2, \"missing_concepts\": [\"hidden-state dependency\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good but should mention that hidden states carry past information.\"}"
    },
    {
        "context": "Positional encodings provide Transformers with information about input order.",
        "question": "Why do Transformers need positional encodings?",
        "student_answer": "Because otherwise they’d have no clue about the order of tokens.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation.\"}"
    },
    {
        "context": "Layer normalization in Transformers stabilizes training by normalizing activations across features.",
        "question": "What is the benefit of layer normalization?",
        "student_answer": "It keeps the activations from getting too wild and makes training smoother.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"normalized across features\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good but missing detail on what dimension is normalized.\"}"
    },
    {
        "context": "Attention heads operate in parallel to compute diverse context representations.",
        "question": "How do attention heads operate in a Transformer?",
        "student_answer": "They kinda run side by side so the model learns different stuff at once.",
        "target_json": "{\"score_30\": 21, \"key_coverage\": 1, \"missing_concepts\": [\"parallel computation\", \"distinct projections\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Informal but partially correct; missing technical details.\"}"
    },
    {
        "context": "Pooling reduces feature map dimensions while retaining key activations.",
        "question": "What do pooling layers achieve?",
        "student_answer": "They lower the resolution but keep the strong signals.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 2, \"missing_concepts\": [\"feature retention mechanism\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good summary but could be more precise.\"}"
    },
    {
        "context": "CNNs exploit local connectivity and weight sharing to detect spatial patterns efficiently.",
        "question": "Why does weight sharing make CNNs more efficient?",
        "student_answer": "Because you reuse the same filters everywhere instead of learning a bunch of new ones.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 2, \"missing_concepts\": [\"local connectivity benefit\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct but missing detail on how local connectivity pairs with weight sharing.\"}"
    },
    {
        "context": "Bidirectional RNNs process sequences in forward and backward directions to capture full context.",
        "question": "What advantage does a bidirectional RNN offer?",
        "student_answer": "It looks both ways so it knows the past and the future.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"improved contextual representations\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good idea but missing explicit mention of richer context representation.\"}"
    },
    {
        "context": "Transformers rely on scaled dot-product attention for stable gradients when computing similarity scores.",
        "question": "Why is the dot-product attention scaled?",
        "student_answer": "To keep the numbers from blowing up when vectors get bigger.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate explanation of scaling for numerical stability.\"}"
    },
    {
        "context": "Attention mechanisms involve computing compatibility between queries and keys.",
        "question": "In attention, how are relevance scores computed?",
        "student_answer": "You compare queries with keys by doing dot products.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"softmax normalization\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct but should mention the softmax step.\"}"
    },
    {
        "context": "CNNs derive translation invariance primarily from pooling and shared filters.",
        "question": "What architectural features allow CNNs to be translation invariant?",
        "student_answer": "Pooling does that, I think.",
        "target_json": "{\"score_30\": 15, \"key_coverage\": 1, \"missing_concepts\": [\"weight sharing\", \"convolutional filters\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Incomplete—translation invariance arises from pooling and shared convolutional filters.\"}"
    },
    {
        "context": "RNN hidden states propagate information through sequential processing steps.",
        "question": "What is the main role of the hidden state in an RNN?",
        "student_answer": "It stores the memory of what happened before.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Solid answer describing memory propagation.\"}"
    },
    {
        "context": "Transformer decoders use causal masking to preserve autoregressive constraints.",
        "question": "Why do Transformer decoders use masking?",
        "student_answer": "So they don’t cheat by looking at future tokens.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 2, \"missing_concepts\": [\"causal structure\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate but missing explicit mention of causal constraint.\"}"
    },
    {
        "context": "Positional encodings inject sequence order into Transformer inputs which otherwise lack recurrence.",
        "question": "How do Transformers incorporate order information?",
        "student_answer": "They add some sinusoidal patterns to token embeddings.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct explanation.\"}"
    },
    {
        "context": "CNN depth contributes to hierarchical representation learning.",
        "question": "Why add more convolutional layers to a CNN?",
        "student_answer": "More layers mean it can detect more complicated patterns.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"hierarchical feature learning detail\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good answer but could mention hierarchical feature abstraction.\"}"
    },
    {
        "context": "GRUs combine update and reset gates to manage long-term dependencies with fewer parameters.",
        "question": "What is the purpose of the update gate in a GRU?",
        "student_answer": "It decides how much old info to keep.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate and concise.\"}"
    },
    {
        "context": "Transformers use feed-forward networks after attention blocks to transform representations.",
        "question": "What role does the feed-forward network play in Transformer layers?",
        "student_answer": "It processes the attended info and mixes it up more.",
        "target_json": "{\"score_30\": 22, \"key_coverage\": 1, \"missing_concepts\": [\"nonlinear transformation\", \"feature projection\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Partially correct but missing technical details.\"}"
    },
    {
        "context": "RNNs struggle with long-range dependencies due to vanishing gradients.",
        "question": "Why do standard RNNs have difficulty learning long-range dependencies?",
        "student_answer": "The gradients die out as they go back in time.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation.\"}"
    },
    {
        "context": "Multi-head attention uses parallel projections to capture different relationships.",
        "question": "What does each attention head learn in parallel?",
        "student_answer": "Different kinds of relationships between tokens.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"separate learned projections\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Conceptually correct but needs detail.\"}"
    },
    {
        "context": "CNN filters detect patterns by convolving over spatial neighborhoods.",
        "question": "What determines the receptive field in CNNs?",
        "student_answer": "How big the filter is and how many layers you stack.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate explanation of receptive field growth.\"}"
    },
    {
        "context": "Residual connections allow deep networks like ResNets and Transformers to train stably.",
        "question": "Why are residual connections useful?",
        "student_answer": "They help the model avoid getting stuck because they let info skip layers.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"gradient flow improvements\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good but missing mention of gradient flow benefits.\"}"
    },
    {
        "context": "Self-attention computes token interactions globally, not just locally.",
        "question": "How does self-attention differ from convolution?",
        "student_answer": "Attention looks everywhere; conv only looks at nearby pixels.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 2, \"missing_concepts\": [\"global receptive field\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate but missing terminology.\"}"
    },
    {
        "context": "Layer normalization stabilizes training by normalizing across features.",
        "question": "Which dimensions does layer normalization operate on?",
        "student_answer": "On the features of each sample.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Fully correct.\"}"
    },
    {
        "context": "RNN variants like LSTMs introduce memory cells to preserve long-term information.",
        "question": "What is the purpose of the cell state in an LSTM?",
        "student_answer": "It keeps important info alive for a long time.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"controlled by gates\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct but can mention gate control.\"}"
    },
    {
        "context": "Transformers gain efficiency by parallelizing attention computations across tokens.",
        "question": "How do Transformers achieve parallelism during training?",
        "student_answer": "All tokens run through the attention at the same time.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 2, \"missing_concepts\": [\"removal of recurrence\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation but incomplete.\"}"
    },
    {
        "context": "Pooling layers compress spatial information while keeping salient signals.",
        "question": "What is a downside of aggressive pooling?",
        "student_answer": "You can lose too much detail.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct—detail loss is the main drawback.\"}"
    },
    
    {
        "context": "Batch normalization normalizes the input across a batch of samples to have mean zero and variance one, stabilizing and accelerating training in deep networks.",
        "question": "How does batch normalization improve training stability?",
        "student_answer": "It standardizes inputs so the network trains faster and more stable.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"mean zero and variance one\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good general understanding, but missed the specific normalization targets of mean zero and variance one.\"}"
    },
    {
        "context": "Skip connections, or residual connections, enable gradients to flow directly through multiple layers by allowing the output of one layer to bypass subsequent layers.",
        "question": "What is the mechanism by which skip connections help train very deep networks?",
        "student_answer": "They create shortcuts for information to flow around layers, making backprop easier.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"bypass layers\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct concept about gradient flow, but imprecise about how connections bypass layers.\"}"
    },
    {
        "context": "1x1 convolutional filters in CNNs are used for dimensionality reduction and can be applied across channels without changing spatial dimensions.",
        "question": "What is a practical use of 1x1 convolutional filters?",
        "student_answer": "They reduce the number of channels in the feature maps.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate and direct answer about the dimensionality reduction purpose of 1x1 convolutions.\"}"
    },
    {
        "context": "Positional encoding in transformers provides the model with information about the position of tokens in a sequence, compensating for the lack of inherent sequential processing.",
        "question": "Why do transformers need positional encodings?",
        "student_answer": "Because without order info, the transformer can't tell where words are in the sequence.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of positional encoding necessity in attention-based models.\"}"
    },
    {
        "context": "Depthwise separable convolutions reduce computational complexity by separating the convolution into depthwise and pointwise components rather than standard convolutions.",
        "question": "How do depthwise separable convolutions reduce computational cost?",
        "student_answer": "They split convolutions into two steps instead of doing it all at once.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"depthwise\", \"pointwise\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct principle but missing the specific terminology for the two components.\"}"
    },
    {
        "context": "The softmax activation function in output layers converts raw scores into probability distributions, ensuring outputs sum to one for multi-class classification.",
        "question": "Why is softmax used in the output layer for classification tasks?",
        "student_answer": "It turns scores into probabilities that add up to 1.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer, correctly describes both the function and its purpose.\"}"
    },
    {
        "context": "Dilation in convolutional layers increases the receptive field of filters without increasing parameters, by spacing out kernel weights.",
        "question": "What advantage does dilation provide in convolutional layers?",
        "student_answer": "It lets the filter see a bigger area without adding more weights.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of dilation's benefit for expanding receptive field.\"}"
    },
    {
        "context": "The vanishing gradient problem occurs when gradients become very small during backpropagation through many layers, slowing or stopping training.",
        "question": "What is the vanishing gradient problem and why does it matter?",
        "student_answer": "When gradients get super small through many layers, the early layers don't learn.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"backpropagation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good intuition but could have mentioned backpropagation explicitly.\"}"
    },
    {
        "context": "Weight decay or L2 regularization adds a penalty term proportional to the squared weights to the loss function, discouraging large weight values.",
        "question": "How does L2 regularization prevent overfitting?",
        "student_answer": "It penalizes big weights so the model stays simpler and doesn't memorize.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"squared weights\", \"penalty term\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Sound reasoning about regularization, but missed specific mention of squared weights and penalty terms.\"}"
    },
    {
        "context": "Separable convolutions decouple spatial and channel-wise operations, enabling more efficient feature extraction with fewer parameters.",
        "question": "Why are separable convolutions more efficient than standard convolutions?",
        "student_answer": "They split the operation into simpler parts that use less computation.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"spatial and channel-wise operations\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct efficiency insight, though could specify spatial and channel-wise separation.\"}"
    },
    {
        "context": "Attention heads in transformers allow the model to attend to information from multiple representation subspaces simultaneously, enriching the learned representations.",
        "question": "Why do transformers use multiple attention heads instead of a single head?",
        "student_answer": "Multiple heads let the model focus on different stuff at the same time.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"representation subspaces\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good intuition, but more precise would be mentioning different representation subspaces.\"}"
    },
    {
        "context": "The cross-entropy loss function measures the difference between predicted probability distributions and true labels, commonly used for classification.",
        "question": "Why is cross-entropy commonly used for training classification networks?",
        "student_answer": "It compares the model's output probabilities with the true class.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct and well-articulated explanation of cross-entropy's role in classification.\"}"
    },
    {
        "context": "Gradient clipping bounds gradient values during backpropagation, preventing exploding gradients that can destabilize training.",
        "question": "How does gradient clipping help during training?",
        "student_answer": "It stops gradients from getting too large and messing up the training.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate and concise explanation of gradient clipping's stabilizing effect.\"}"
    },
    {
        "context": "Dilated convolutions increase the receptive field exponentially, enabling deeper networks to capture larger context without increasing kernel sizes.",
        "question": "How do dilated convolutions enable larger receptive fields?",
        "student_answer": "They space out the kernel weights so the filter covers more area.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of how dilation extends the receptive field.\"}"
    },
    {
        "context": "RNN cells maintain hidden states that are updated at each time step, allowing sequential dependencies to be captured through recurrent connections.",
        "question": "How do hidden states enable RNNs to model sequential data?",
        "student_answer": "Each hidden state carries info from the past, so the network remembers what came before.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of how hidden states preserve sequential information.\"}"
    },
    {
        "context": "Feature pyramids in CNNs build multi-scale representations by creating a hierarchy of feature maps at different resolutions.",
        "question": "What advantage do feature pyramids provide in computer vision models?",
        "student_answer": "They let the model see features at different scales, which helps detect things of different sizes.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer explaining multi-scale feature detection benefits.\"}"
    },
    {
        "context": "The ReLU activation function outputs zero for negative inputs and the input value for positive inputs, introducing non-linearity efficiently.",
        "question": "Why is ReLU preferred over sigmoid for hidden layers?",
        "student_answer": "ReLU is faster and doesn't have the vanishing gradient issue that sigmoid does.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Comprehensive answer covering both computational efficiency and gradient flow benefits.\"}"
    },
    {
        "context": "Convolutional layers share weights across spatial positions, dramatically reducing parameters compared to fully connected layers while maintaining spatial structure.",
        "question": "Why do CNNs use weight sharing in convolutional layers?",
        "student_answer": "It keeps the number of parameters down and captures patterns that repeat in images.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer addressing both parameter efficiency and pattern detection.\"}"
    },
    {
        "context": "Bidirectional transformers process input sequences both forward and backward, enabling richer contextual representations than unidirectional models.",
        "question": "What is the advantage of bidirectional processing in BERT-like models?",
        "student_answer": "By reading both directions, the model understands context from all around each token.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of bidirectional context modeling advantages.\"}"
    },
    {
        "context": "Attention mechanisms compute similarity scores between queries and keys, then use softmax normalization to create attention weights that sum to one.",
        "question": "How do attention weights indicate which parts of the input are important?",
        "student_answer": "The attention weights show how much each part of the input matters for that output.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Clear and accurate description of attention weights' interpretability.\"}"
    },
    {
        "context": "Gating mechanisms in neural networks control information flow by using learned sigmoid or tanh gates to scale intermediate representations.",
        "question": "What is the purpose of gating mechanisms in recurrent architectures?",
        "student_answer": "Gates let the network choose what info to keep or throw away.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"sigmoid or tanh gates\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Solid conceptual understanding, but could specify that gates use sigmoid or tanh functions.\"}"
    },
    {
        "context": "Artificial Neural Networks (ANNs) are computational models inspired by biological neurons, consisting of interconnected nodes organized in layers that process information through weighted connections.",
        "question": "Explain how weights in an ANN determine the network's behavior.",
        "student_answer": "Weights in an ANN determine the network's behavior by controlling the strength of connections between neurons. During training, backpropagation adjusts these weights to minimize the loss function, allowing the network to learn patterns in the data.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains weight function, training mechanism, and learning process.\"}"
    },
    {
        "context": "Overfitting occurs when a model learns the training data too well, including noise and outliers, leading to poor generalization on unseen test data.",
        "question": "What is the difference between overfitting and underfitting?",
        "student_answer": "Overfitting happens when the model memorizes training data and performs well on training but poorly on test data. Underfitting occurs when the model is too simple to capture patterns, resulting in poor performance on both training and test data.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 4, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer. Clear distinction between both concepts with correct characterization of each.\"}"
    },
    {
        "context": "Convolutional Neural Networks (CNNs) use convolutional layers with learnable filters to extract spatial features from input data, particularly effective for image processing.",
        "question": "How do convolutional filters contribute to feature extraction in CNNs?",
        "student_answer": "Convolutional filters scan across the input image and detect local patterns like edges, textures, and shapes at different layers, building hierarchical representations from low-level to high-level features.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate and comprehensive. Correctly describes filter operation and hierarchical feature extraction.\"}"
    },
    {
        "context": "Deep Neural Networks (DNNs) contain multiple hidden layers that enable learning complex non-linear relationships in data through stacked transformations.",
        "question": "Why can DNNs learn more complex patterns than shallow networks?",
        "student_answer": "DNNs can learn more complex patterns because each layer applies a non-linear transformation, and stacking multiple layers creates a more expressive function. The depth allows the network to build increasingly abstract representations.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect. Explains non-linearity stacking and abstraction hierarchy correctly.\"}"
    },
    {
        "context": "Reinforcement Learning (RL) involves an agent learning to make decisions by interacting with an environment, receiving rewards or penalties based on actions taken.",
        "question": "What is the main goal of a reinforcement learning agent?",
        "student_answer": "The main goal of an RL agent is to maximize cumulative reward over time by learning the optimal policy that maps states to actions, balancing exploration of new actions with exploitation of known good actions.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer. Correctly identifies goal, policy concept, and exploration-exploitation tradeoff.\"}"
    },
    {
        "context": "L1 and L2 regularization are techniques that add penalty terms to the loss function to discourage large weights. L1 adds the absolute value of weights, while L2 adds the squared weights.",
        "question": "What is the key difference between L1 and L2 regularization and their effects?",
        "student_answer": "L1 regularization promotes sparse solutions by driving some weights exactly to zero, making it useful for feature selection. L2 regularization distributes weight penalties more evenly, keeping smaller weights. L1 produces sharper solutions while L2 produces smoother solutions.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [\"absolute value vs squared weights terminology\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of effects but slightly imprecise on the mathematical distinction. Should emphasize L1 uses absolute values while L2 uses squared values.\"}"
    },
    {
        "context": "Precision and Recall are evaluation metrics where Precision is the ratio of true positives to all positive predictions, and Recall is the ratio of true positives to all actual positives.",
        "question": "When would you prioritize Recall over Precision?",
        "student_answer": "You would prioritize Recall when false negatives are more costly than false positives. For example, in disease detection, missing a sick patient (false negative) is worse than incorrectly flagging a healthy person (false positive).",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Very good answer with relevant example. Minor: could have been more explicit about Precision-Recall tradeoff.\"}"
    },
    {
        "context": "Unsupervised Learning involves training models on unlabeled data to discover hidden patterns, structures, or representations without predefined target variables.",
        "question": "Name three common unsupervised learning algorithms and their purposes.",
        "student_answer": "K-Means clusters data into K groups by minimizing within-cluster variance. PCA reduces dimensionality by finding principal components. Hierarchical clustering builds dendrograms to show relationships between data points at different granularities.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly names three algorithms and accurately describes their purposes.\"}"
    },
    {
        "context": "Batch Normalization normalizes layer inputs to have zero mean and unit variance, stabilizing and accelerating training in deep networks.",
        "question": "How does Batch Normalization reduce the internal covariate shift problem?",
        "student_answer": "Batch Normalization keeps the distribution of layer inputs stable by normalizing to zero mean and unit variance. This reduces internal covariate shift because each layer doesn't need to constantly adapt to changing input distributions.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation. Correctly identifies the normalization mechanism and its effect on covariate shift.\"}"
    },
    {
        "context": "Gradient Descent is an optimization algorithm that iteratively updates parameters by moving in the direction of the negative gradient to minimize the loss function.",
        "question": "What problem does Stochastic Gradient Descent (SGD) solve compared to Batch Gradient Descent?",
        "student_answer": "SGD updates parameters using a single sample instead of the entire batch, which makes it faster and helps escape local minima. However, SGD has higher variance in updates and may not converge smoothly to the global minimum.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"computational efficiency in large datasets\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good answer with correct trade-offs. Could mention that SGD is more memory efficient for large datasets.\"}"
    },
    {
        "context": "Activation functions introduce non-linearity into neural networks, enabling them to learn complex patterns. Common activations include ReLU, Sigmoid, and Tanh.",
        "question": "Why is ReLU preferred over Sigmoid in hidden layers of deep networks?",
        "student_answer": "ReLU is preferred because it doesn't saturate for positive values, avoiding the vanishing gradient problem that Sigmoid suffers from. Additionally, ReLU is computationally cheaper than Sigmoid since it only requires a simple thresholding operation.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Addresses vanishing gradient issue and computational efficiency correctly.\"}"
    },
    {
        "context": "The Dropout technique randomly deactivates neurons during training with probability p, forcing the network to learn robust representations without relying on co-adaptation.",
        "question": "How does Dropout help prevent overfitting?",
        "student_answer": "Dropout prevents overfitting by randomly zeroing out neurons during training, creating an ensemble effect. This forces the network to learn multiple independent representations, reducing dependence on specific neurons and improving generalization.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation. Correctly describes the ensemble effect and robustness mechanism.\"}"
    },
    {
        "context": "Clustering is an unsupervised learning task that groups similar data points together based on distance metrics or similarity measures.",
        "question": "What is the key difference between K-Means and DBSCAN clustering algorithms?",
        "student_answer": "K-Means requires specifying the number of clusters K in advance and assigns each point to the nearest centroid. DBSCAN is density-based and doesn't require specifying cluster numbers; it discovers clusters and identifies outliers automatically.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [\"distance metrics\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good comparison. Could mention that they use different distance metrics and have different computational complexities.\"}"
    },
    {
        "context": "Backpropagation is the algorithm that computes gradients of the loss function with respect to weights through the chain rule, enabling weight updates.",
        "question": "Explain why backpropagation is efficient for training neural networks.",
        "student_answer": "Backpropagation uses the chain rule to compute gradients layer-by-layer, reusing intermediate computations. This dynamic programming approach makes it much faster than computing gradients independently for each weight, reducing computational complexity.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains chain rule, intermediate computation reuse, and efficiency gains.\"}"
    },
    {
        "context": "The curse of dimensionality refers to problems that arise when working with high-dimensional data, including sparse data, computational expense, and difficulty in visualization.",
        "question": "Why does the curse of dimensionality make machine learning harder?",
        "student_answer": "As dimensions increase, data becomes increasingly sparse, requiring exponentially more samples to maintain the same density. This leads to increased computational cost, overfitting risk, and difficulty finding meaningful patterns in sparse space.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"exponential growth of volume\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Strong answer with good intuition. Could mention that volume grows exponentially with dimensions, creating exponential sparsity.\"}"
    },
    {
        "context": "Transfer Learning involves taking a pre-trained model and fine-tuning it on a new task, leveraging learned features to improve performance on related problems.",
        "question": "Why is Transfer Learning effective when you have limited labeled data?",
        "student_answer": "Transfer Learning works well with limited data because the pre-trained model has already learned general features from large datasets. By fine-tuning only the later layers, you can adapt these features to your specific task without requiring massive amounts of new labeled data.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer. Correctly explains feature reuse and why layer fine-tuning is effective with limited data.\"}"
    },
    {
        "context": "Cross-validation is a model evaluation technique that splits data into K folds, training and testing K times to get a more robust estimate of model performance.",
        "question": "What is the advantage of K-Fold Cross-Validation over a simple train-test split?",
        "student_answer": "K-Fold Cross-Validation uses all data for both training and testing across multiple splits, providing a more stable and reliable performance estimate. This reduces variance in the evaluation and helps detect overfitting better than a single train-test split.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains variance reduction and the benefit of multiple train-test iterations.\"}"
    },
    {
        "context": "Dimensionality Reduction techniques like PCA project high-dimensional data onto lower-dimensional subspaces while preserving variance.",
        "question": "What does PCA do and what is its main limitation?",
        "student_answer": "PCA finds orthogonal directions of maximum variance and projects data onto these principal components. However, PCA assumes linear relationships and may miss non-linear patterns. Additionally, the transformed features become harder to interpret.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [\"orthogonality constraint\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good answer but mixed explanation. PCA assumes LINEAR relationships, not non-linear ones. Should clarify that it PRESERVES linear structure but misses non-linear patterns.\"}"
    },
    {
        "context": "Hyperparameter tuning involves selecting optimal values for parameters that are not learned during training, such as learning rate, batch size, and regularization strength.",
        "question": "Describe what the learning rate controls and why it matters.",
        "student_answer": "The learning rate controls the magnitude of weight updates during gradient descent. A very high learning rate may cause divergence, while a very low learning rate leads to slow convergence. Tuning the learning rate is crucial for efficient and stable training.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer. Correctly explains learning rate effects and the balance between convergence speed and stability.\"}"
    },
    {
        "context": "Support Vector Machines (SVMs) find the optimal separating hyperplane by maximizing the margin between classes while allowing some misclassification through soft margins.",
        "question": "What is the purpose of the kernel trick in SVMs?",
        "student_answer": "The kernel trick allows SVMs to handle non-linearly separable data by implicitly mapping data to higher-dimensional spaces without explicitly computing the transformation, reducing computational cost while enabling non-linear classification.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains implicit mapping, computational efficiency, and non-linear capability.\"}"
    },
    {
        "context": "Ensemble methods combine multiple weak learners to create a strong predictor by aggregating their predictions through voting or averaging.",
        "question": "How do Random Forests improve upon single decision trees?",
        "student_answer": "Random Forests train multiple decision trees on random subsets of data and features, then average their predictions. This reduces overfitting and variance through ensemble averaging, producing more robust and generalized models than single trees.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer. Correctly describes bootstrap sampling, random feature selection, and variance reduction.\"}"
    },
    {
        "context": "The Gradient Boosting framework sequentially trains models where each new model learns to correct errors from previous models by fitting residuals.",
        "question": "How is Gradient Boosting different from Random Forests in terms of model training?",
        "student_answer": "Gradient Boosting trains models sequentially, with each model correcting previous errors, while Random Forests train models in parallel independently. Gradient Boosting focuses on residual learning, making it more prone to overfitting but often achieving better performance when properly tuned.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"weak learners\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good comparison but slightly incomplete. Could clarify that both use weak learners but combine them differently.\"}"
    },
    {
        "context": "Neural Network initialization strategies like Xavier and He initialization set initial weights to appropriate scales to prevent vanishing or exploding gradients during early training.",
        "question": "Why is proper weight initialization important in deep neural networks?",
        "student_answer": "Proper weight initialization ensures that activations and gradients have appropriate magnitudes throughout the network during early training. Poor initialization can lead to vanishing or exploding gradients, significantly slowing down or preventing convergence.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains activation/gradient scaling and convergence implications.\"}"
    },
    {
        "context": "Attention Mechanisms allow models to dynamically focus on relevant parts of the input by computing attention weights that emphasize important features.",
        "question": "How do attention mechanisms improve model interpretability?",
        "student_answer": "Attention mechanisms produce interpretable weights that show which input elements the model focused on for each prediction. This transparency allows us to understand model decisions and identify potential biases or errors in learned patterns.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation. Correctly describes weight transparency and interpretability benefits.\"}"
    },
    {
        "context": "Collaborative Filtering is an unsupervised recommendation technique that predicts user preferences by finding similar users or items based on historical behavior.",
        "question": "What is the main challenge of Collaborative Filtering?",
        "student_answer": "The cold start problem is the main challenge. When new users or items have no historical data, the system cannot make reliable recommendations. Additionally, the high dimensionality of user-item matrices creates computational challenges.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"sparsity\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good answer addressing cold start problem. Could mention data sparsity as another significant challenge.\"}"
    },
    {
        "context": "An autoencoder is an unsupervised neural network that learns to reconstruct input data by compressing it through a bottleneck layer, discovering low-dimensional representations.",
        "question": "What distinguishes a Variational Autoencoder (VAE) from a standard Autoencoder?",
        "student_answer": "VAEs learn a probabilistic latent space distribution instead of a deterministic one, allowing for meaningful interpolation and generation of new samples. VAEs use a reparameterization trick to maintain differentiability during sampling from the latent distribution.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains probabilistic latent space and reparameterization trick.\"}"
    },
    {
        "context": "Generative Adversarial Networks (GANs) consist of a generator that creates fake data and a discriminator that distinguishes fake from real, trained in a minimax game.",
        "question": "Why are GANs difficult to train compared to other generative models?",
        "student_answer": "GANs are difficult to train because the generator and discriminator compete in an adversarial process, leading to mode collapse where the generator produces limited variety. Additionally, training instability and convergence difficulties arise from the minimax objective and balancing two competing networks.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer. Correctly identifies mode collapse, training instability, and the minimax challenge.\"}"
    },
    {
        "context": "The Q-Learning algorithm in Reinforcement Learning learns action values (Q-values) by updating estimates based on the Bellman equation and environment feedback.",
        "question": "What is the exploration-exploitation tradeoff in Q-Learning?",
        "student_answer": "The exploration-exploitation tradeoff balances trying new actions (exploration) to discover better strategies versus using known good actions (exploitation). Epsilon-greedy strategies handle this by occasionally taking random actions with probability epsilon.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"optimal balance problem\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of epsilon-greedy. Could add that finding the optimal balance between exploration and exploitation remains an open problem.\"}"
    },
    {
        "context": "A Recurrent Neural Network (RNN) processes sequences by maintaining hidden states that are updated at each time step, allowing information flow across time steps.",
        "question": "Why do vanilla RNNs struggle with long sequences, and how do LSTMs address this?",
        "student_answer": "Vanilla RNNs suffer from vanishing gradients when processing long sequences because gradients shrink exponentially through many time steps. LSTMs use forget gates and memory cells to maintain information across long sequences, allowing gradients to flow more effectively.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains vanishing gradient problem and LSTM solution with memory cells.\"}"
    },
    {
        "context": "Precision = TP/(TP+FP), Recall = TP/(TP+FN), where TP = True Positives, FP = False Positives, FN = False Negatives.",
        "question": "When would you prioritize Precision over Recall?",
        "student_answer": "You would prioritize Precision when false positives are expensive. For example, in spam detection, incorrectly marking legitimate emails as spam is worse than missing some spam emails, so you want high precision to minimize false alarms.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer with appropriate use case demonstrating high precision importance.\"}"
    },
    {
        "context": "A Decision Tree learns by recursively partitioning the input space using features that maximize information gain, creating a tree of decision nodes.",
        "question": "What causes overfitting in Decision Trees and how can it be prevented?",
        "student_answer": "Decision Trees overfit when they grow too deep, learning noise in the training data. This is prevented through pruning, limiting tree depth, setting minimum samples per leaf, or using ensemble methods like Random Forests that aggregate multiple trees.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 4, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Comprehensive answer covering causes and multiple prevention strategies effectively.\"}"
    },
    {
        "context": "The False Positive Rate (FPR) is the ratio of false positives to all actual negatives, used in ROC curve analysis.",
        "question": "How do you interpret the AUC (Area Under ROC Curve) metric?",
        "student_answer": "AUC represents the probability that the model ranks a random positive example higher than a random negative example. An AUC of 0.5 indicates random guessing, while 1.0 indicates perfect classification. AUC is threshold-independent and useful for imbalanced datasets.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of AUC interpretation, probabilistic meaning, and advantages for imbalanced data.\"}"
    },
    {
        "context": "Logistic Regression is a linear classification model that outputs probabilities using the sigmoid function: P(y=1|x) = 1/(1+e^(-wx+b)).",
        "question": "Why is Logistic Regression considered a linear model despite using the sigmoid function?",
        "student_answer": "Logistic Regression is linear because the decision boundary is defined by a linear combination of features (wx+b), even though sigmoid is applied afterwards. The sigmoid is just a transformation that converts linear predictions into probabilities.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent clarification. Correctly explains that linearity refers to feature combinations, not the output transformation.\"}"
    },
    {
        "context": "The Mean Squared Error (MSE) loss function is calculated as MSE = (1/n) * Σ(y_i - ŷ_i)^2, commonly used for regression tasks.",
        "question": "Why might you use Mean Absolute Error (MAE) instead of MSE for regression?",
        "student_answer": "MAE uses absolute differences instead of squared differences, making it more robust to outliers since large errors don't get amplified as much. MAE is also more interpretable because it's in the same units as the target variable.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains outlier robustness and interpretability advantages of MAE.\"}"
    },
    {
        "context": "Tokenization is the preprocessing step that converts text into individual tokens (words, subwords, or characters) that can be processed by NLP models.",
        "question": "What are the advantages of subword tokenization over word tokenization?",
        "student_answer": "Subword tokenization handles out-of-vocabulary words better by breaking them into known subunits, reducing vocabulary size and computational complexity. It also captures morphological information and handles rare words more effectively than fixed word vocabularies.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer covering OOV handling, vocabulary efficiency, and morphological benefits.\"}"
    },
    {
        "context": "Feature Scaling standardizes input features to have similar ranges, important for distance-based algorithms like K-Means and gradient-based optimization.",
        "question": "What is the difference between normalization and standardization in feature scaling?",
        "student_answer": "Normalization scales features to a range like [0,1] using min-max scaling, while standardization scales to have mean 0 and standard deviation 1 using z-score transformation. Standardization is preferred for algorithms assuming normally distributed data, while normalization preserves original distribution shape.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"preserving relative distances\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation with correct formulas. Could mention that standardization better preserves relative distances between points.\"}"
    },
    {
        "context": "Feature Engineering involves creating new features or transforming existing ones to improve model performance and capture domain knowledge.",
        "question": "Why is feature engineering considered both an art and a science?",
        "student_answer": "Feature engineering requires domain expertise and intuition (art) combined with systematic experimentation and validation (science). Good features dramatically improve model performance, but discovering them requires understanding the problem context, not just mathematical optimization.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer perfectly capturing the balance between intuition and systematic approach in feature engineering.\"}"
    },
    {
        "context": "The Confusion Matrix is a table showing True Positives, True Negatives, False Positives, and False Negatives for a classification model.",
        "question": "How do you calculate the F1-Score and when should you use it?",
        "student_answer": "F1-Score is the harmonic mean of precision and recall: F1 = 2*(Precision*Recall)/(Precision+Recall). It's useful when you need to balance both false positives and false negatives, particularly with imbalanced datasets where accuracy alone is misleading.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer with correct formula and appropriate use case explanation.\"}"
    },
    {
        "context": "Artificial Neural Networks (ANNs) are computational models inspired by biological neurons, consisting of interconnected nodes organized in layers that process information through weighted connections.",
        "question": "Explain how weights in an ANN determine the network's behavior.",
        "student_answer": "Weights multiply input values and control signal strength. They are adjusted during training using backpropagation to minimize errors. The network learns by finding optimal weight values that map inputs to outputs.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"loss function minimization\", \"gradient descent mechanism\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good basic explanation but missing details about how weights minimize loss and the role of gradient descent in weight updates.\"}"
    },
    {
        "context": "Overfitting occurs when a model learns the training data too well, including noise and outliers, leading to poor generalization on unseen test data.",
        "question": "What causes overfitting in neural networks?",
        "student_answer": "Overfitting happens when the network has too many parameters relative to training data size. The model memorizes specific training examples including noise. This occurs when model capacity exceeds what is needed to learn true patterns.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation covering model capacity and memorization of noise. Complete answer.\"}"
    },
    {
        "context": "Convolutional Neural Networks (CNNs) use convolutional layers with learnable filters to extract spatial features from input data, particularly effective for image processing.",
        "question": "How do convolutional filters contribute to feature extraction in CNNs?",
        "student_answer": "The filters apply a transformation called a Flux Convolution that detects edges at different wavelengths. Multiple Flux layers stack together to build abstract features.",
        "target_json": "{\"score_30\": 5, \"key_coverage\": 1, \"missing_concepts\": [\"local pattern detection\", \"spatial hierarchy\", \"learnable kernels\"], \"hallucinations\": [\"Flux Convolution\", \"wavelengths in filters\"], \"bias_check\": false, \"feedback\": \"Incorrect terminology. Filters perform convolution, not Flux Convolution. Filters detect local patterns like edges, not wavelengths. Answer contains invented technical terms.\"}"
    },
    {
        "context": "Deep Neural Networks (DNNs) contain multiple hidden layers that enable learning complex non-linear relationships in data through stacked transformations.",
        "question": "Why can DNNs learn more complex patterns than shallow networks?",
        "student_answer": "Deep networks have way more neurons so they can memorize everything better than shallow ones.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 1, \"missing_concepts\": [\"non-linear transformations\", \"function approximation\", \"hierarchical representations\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Oversimplified and contains informal language. Incorrectly equates depth with memorization capacity. Should explain non-linear composition and hierarchical feature learning.\"}"
    },
    {
        "context": "Reinforcement Learning (RL) involves an agent learning to make decisions by interacting with an environment, receiving rewards or penalties based on actions taken.",
        "question": "What is the main goal of a reinforcement learning agent?",
        "student_answer": "The agent tries to find a policy that maximizes total reward. It learns which actions are good in different states through trial and error, receiving feedback from the environment.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"exploration-exploitation tradeoff\", \"temporal discounting\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good fundamental understanding but missing important concepts like exploration-exploitation balance and discounted future rewards.\"}"
    },
    {
        "context": "L1 and L2 regularization are techniques that add penalty terms to the loss function to discourage large weights. L1 adds the absolute value of weights, while L2 adds the squared weights.",
        "question": "What is the key difference between L1 and L2 regularization and their effects?",
        "student_answer": "L1 regularization is better for preventing overfitting because it reduces all weights equally, while L2 regularization allows some large weights. L1 always produces better results than L2.",
        "target_json": "{\"score_30\": 12, \"key_coverage\": 2, \"missing_concepts\": [\"sparsity from L1\", \"weight distribution effects\", \"feature selection\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Tricky error. Reversed the effects: L1 promotes sparsity by driving weights to zero, L2 distributes penalties evenly. Neither is universally better; they suit different problems.\"}"
    },
    {
        "context": "Precision and Recall are evaluation metrics where Precision is the ratio of true positives to all positive predictions, and Recall is the ratio of true positives to all actual positives.",
        "question": "What is the relationship between Precision and Recall?",
        "student_answer": "Precision and Recall measure the same thing using different denominators, so they are basically identical metrics that always move together.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 1, \"missing_concepts\": [\"inverse relationship\", \"threshold tradeoff\", \"different optimization goals\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Tricky error. Precision and Recall have an inverse relationship and move in opposite directions when changing decision thresholds. They measure different aspects of classification performance.\"}"
    },
    {
        "context": "Unsupervised Learning involves training models on unlabeled data to discover hidden patterns, structures, or representations without predefined target variables.",
        "question": "What is a fundamental limitation of unsupervised learning?",
        "student_answer": "Unsupervised learning cannot work on real data because there is no ground truth to validate results. Models trained without labels will definitely fail in production environments.",
        "target_json": "{\"score_30\": 15, \"key_coverage\": 1, \"missing_concepts\": [\"validation difficulty\", \"evaluation metrics\", \"practical applications\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Major error. Unsupervised learning is widely used in production (clustering, anomaly detection, dimensionality reduction). The challenge is evaluation, not feasibility.\"}"
    },
    {
        "context": "Batch Normalization normalizes layer inputs to have zero mean and unit variance, stabilizing and accelerating training in deep networks.",
        "question": "How does Batch Normalization improve training?",
        "student_answer": "Batch Normalization uses the Gaussian Probability Shift mechanism to redistribute layer outputs according to a quantum distribution, enabling quantum acceleration of training.",
        "target_json": "{\"score_30\": 3, \"key_coverage\": 0, \"missing_concepts\": [\"internal covariate shift\", \"mean and variance normalization\", \"training stability\"], \"hallucinations\": [\"Gaussian Probability Shift\", \"quantum distribution\", \"quantum acceleration\"], \"bias_check\": false, \"feedback\": \"Severe hallucination. Batch Normalization simply normalizes to zero mean and unit variance. There is no Gaussian Probability Shift or quantum distribution involved.\"}"
    },
    {
        "context": "Gradient Descent is an optimization algorithm that iteratively updates parameters by moving in the direction of the negative gradient to minimize the loss function.",
        "question": "What is the difference between gradient descent and stochastic gradient descent?",
        "student_answer": "Gradient descent uses random samples while SGD uses the entire dataset. This makes SGD slower but more accurate.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 1, \"missing_concepts\": [\"batch processing\", \"convergence characteristics\", \"computational efficiency\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Tricky error. You have this backwards. Gradient Descent uses the full dataset, SGD uses random samples. SGD is faster per update but noisier.\"}"
    },
    {
        "context": "Activation functions introduce non-linearity into neural networks, enabling them to learn complex patterns. Common activations include ReLU, Sigmoid, and Tanh.",
        "question": "What problem does ReLU solve that Sigmoid has?",
        "student_answer": "ReLU is smoother than Sigmoid, making it easier for backpropagation to compute smooth gradients without sudden jumps in the derivative.",
        "target_json": "{\"score_30\": 14, \"key_coverage\": 1, \"missing_concepts\": [\"vanishing gradient problem\", \"computational efficiency\", \"saturation regions\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Tricky error. ReLU is actually less smooth than Sigmoid. The advantage is that ReLU avoids saturation and vanishing gradients that Sigmoid suffers from, not smoothness.\"}"
    },
    {
        "context": "The Dropout technique randomly deactivates neurons during training with probability p, forcing the network to learn robust representations without relying on co-adaptation.",
        "question": "How does Dropout prevent overfitting?",
        "student_answer": "Dropout removes the most important neurons randomly during training, forcing the model to develop backup pathways for information flow.",
        "target_json": "{\"score_30\": 18, \"key_coverage\": 2, \"missing_concepts\": [\"ensemble interpretation\", \"co-adaptation prevention\", \"random deactivation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Partial misunderstanding. Dropout deactivates neurons uniformly at random, not preferentially important ones. The benefit comes from ensemble effects, not backup pathways.\"}"
    },
    {
        "context": "Clustering is an unsupervised learning task that groups similar data points together based on distance metrics or similarity measures.",
        "question": "What is the main disadvantage of K-Means clustering?",
        "student_answer": "K-Means requires knowing K beforehand, which is difficult. Additionally, it can get stuck in local minima and produces spherical clusters only.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer. Correctly identifies K specification challenge, local minima issue, and assumption of spherical cluster shapes.\"}"
    },
    {
        "context": "Backpropagation is the algorithm that computes gradients of the loss function with respect to weights through the chain rule, enabling weight updates.",
        "question": "Why can backpropagation compute gradients efficiently?",
        "student_answer": "Backpropagation works by randomly sampling the gradient space and averaging millions of samples to approximate the true gradient direction.",
        "target_json": "{\"score_30\": 5, \"key_coverage\": 0, \"missing_concepts\": [\"chain rule\", \"dynamic programming\", \"computational reuse\"], \"hallucinations\": [\"gradient space sampling\", \"millions of samples\"], \"bias_check\": false, \"feedback\": \"Major hallucination. Backpropagation uses the chain rule and dynamic programming, not random sampling. It computes exact gradients by reusing intermediate computations.\"}"
    },
    {
        "context": "The curse of dimensionality refers to problems that arise when working with high-dimensional data, including sparse data, computational expense, and difficulty in visualization.",
        "question": "How does the curse of dimensionality affect distance-based algorithms?",
        "student_answer": "In high dimensions, all pairwise distances between points become approximately equal, making it hard for distance-based algorithms like K-Means and KNN to distinguish between neighbors and outliers.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains distance concentration problem in high dimensions and its impact on distance-based methods.\"}"
    },
    {
        "context": "Transfer Learning involves taking a pre-trained model and fine-tuning it on a new task, leveraging learned features to improve performance on related problems.",
        "question": "When should you use transfer learning instead of training from scratch?",
        "student_answer": "Transfer learning works better than training from scratch only if the source and target domains are completely identical in every way.",
        "target_json": "{\"score_30\": 12, \"key_coverage\": 1, \"missing_concepts\": [\"domain similarity spectrum\", \"limited data scenarios\", \"computational efficiency\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Tricky error. Transfer learning is valuable even with moderate domain differences, especially with limited target data. Perfect identity is not required.\"}"
    },
    {
        "context": "Cross-validation is a model evaluation technique that splits data into K folds, training and testing K times to get a more robust estimate of model performance.",
        "question": "Why is stratified K-fold cross-validation preferred for classification?",
        "student_answer": "Stratified K-fold ensures each fold has approximately the same class distribution as the entire dataset, preventing class imbalance issues that could bias performance estimates in imbalanced datasets.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains stratification and its importance for maintaining class distribution across folds.\"}"
    },
    {
        "context": "Dimensionality Reduction techniques like PCA project high-dimensional data onto lower-dimensional subspaces while preserving variance.",
        "question": "What are the assumptions PCA makes about the data?",
        "student_answer": "PCA assumes data follows a normal distribution with a single peak. If data has multiple modes or non-Gaussian structure, PCA will fail to find meaningful components.",
        "target_json": "{\"score_30\": 22, \"key_coverage\": 2, \"missing_concepts\": [\"linearity assumption\", \"orthogonality\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Partially correct but incomplete. PCA's main assumption is that important structure is captured by directions of maximum variance. It doesn't strictly require normality but does assume linearity.\"}"
    },
    {
        "context": "Hyperparameter tuning involves selecting optimal values for parameters that are not learned during training, such as learning rate, batch size, and regularization strength.",
        "question": "What is the best method for hyperparameter tuning?",
        "student_answer": "Grid search is always the best method because it systematically tries every combination and guarantees finding the optimal hyperparameters.",
        "target_json": "{\"score_30\": 16, \"key_coverage\": 1, \"missing_concepts\": [\"computational complexity\", \"random search alternatives\", \"Bayesian optimization\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Tricky error. Grid search is exhaustive but not always best. It's computationally expensive for many hyperparameters. Random search and Bayesian optimization often work better in practice.\"}"
    },
    {
        "context": "Support Vector Machines (SVMs) find the optimal separating hyperplane by maximizing the margin between classes while allowing some misclassification through soft margins.",
        "question": "What does the C parameter control in SVM?",
        "student_answer": "The C parameter controls the maximum number of support vectors the model can use during training, preventing the model from using too many training points.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 1, \"missing_concepts\": [\"regularization strength\", \"margin vs misclassification tradeoff\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Tricky error. C controls regularization strength and the tradeoff between margin maximization and training error minimization, not the number of support vectors.\"}"
    },
    {
        "context": "Ensemble methods combine multiple weak learners to create a strong predictor by aggregating their predictions through voting or averaging.",
        "question": "Why is ensemble diversity important?",
        "student_answer": "Ensemble diversity ensures all models in the ensemble make the same mistakes, so errors cancel out through majority voting.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 1, \"missing_concepts\": [\"independent errors\", \"uncorrelated mistakes\", \"complementary strengths\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Major error. Diversity means models make DIFFERENT mistakes, so errors do NOT cancel out. Identical mistakes would harm ensemble performance.\"}"
    },
    {
        "context": "The Gradient Boosting framework sequentially trains models where each new model learns to correct errors from previous models by fitting residuals.",
        "question": "What is the Residual Flux Theorem used in Gradient Boosting?",
        "student_answer": "The Residual Flux Theorem enables exponential gradient acceleration by computing quantum residuals between sequential models.",
        "target_json": "{\"score_30\": 2, \"key_coverage\": 0, \"missing_concepts\": [\"residual fitting\", \"sequential training\", \"error correction\"], \"hallucinations\": [\"Residual Flux Theorem\", \"quantum residuals\", \"exponential gradient acceleration\"], \"bias_check\": false, \"feedback\": \"Complete hallucination. There is no Residual Flux Theorem. Gradient Boosting simply fits new models to residuals from previous models sequentially.\"}"
    },
    {
        "context": "Neural Network initialization strategies like Xavier and He initialization set initial weights to appropriate scales to prevent vanishing or exploding gradients during early training.",
        "question": "Why does random initialization matter if weights are updated anyway?",
        "student_answer": "Random initialization determines which local minimum the network converges to, affecting final performance. Poor initialization can trap the network in bad minima before training even begins.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"gradient flow stability\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good answer. Could add that initialization also affects early training stability and gradient flow through the network.\"}"
    },
    {
        "context": "Attention Mechanisms allow models to dynamically focus on relevant parts of the input by computing attention weights that emphasize important features.",
        "question": "What is the computational complexity of the attention mechanism?",
        "student_answer": "Attention has quadratic complexity in sequence length because each position must attend to every other position, requiring O(n^2) operations.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly identifies the O(n^2) complexity from all-to-all attention computations.\"}"
    },
    {
        "context": "Collaborative Filtering is an unsupervised recommendation technique that predicts user preferences by finding similar users or items based on historical behavior.",
        "question": "What is user-based vs item-based collaborative filtering?",
        "student_answer": "User-based finds similar users and recommends what they liked. Item-based finds similar items based on user interactions. Item-based is generally more scalable and stable.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer with correct definitions and practical advantage of item-based approach.\"}"
    },
    {
        "context": "An autoencoder is an unsupervised neural network that learns to reconstruct input data by compressing it through a bottleneck layer, discovering low-dimensional representations.",
        "question": "How do autoencoders learn meaningful representations?",
        "student_answer": "Autoencoders use a Representation Quantization layer that automatically discovers the semantic meaning of features by analyzing the training data distribution curve.",
        "target_json": "{\"score_30\": 6, \"key_coverage\": 1, \"missing_concepts\": [\"bottleneck compression\", \"reconstruction loss\", \"information bottleneck\"], \"hallucinations\": [\"Representation Quantization layer\", \"semantic meaning analysis\", \"distribution curve\"], \"bias_check\": false, \"feedback\": \"Hallucination detected. Autoencoders learn representations through compression in bottleneck layers and reconstruction loss, not through invented Representation Quantization.\"}"
    },
    {
        "context": "Generative Adversarial Networks (GANs) consist of a generator that creates fake data and a discriminator that distinguishes fake from real, trained in a minimax game.",
        "question": "What is mode collapse in GANs?",
        "student_answer": "Mode collapse occurs when the generator learns to produce only a few types of outputs and ignores most of the diversity in the true data distribution.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect definition of mode collapse and its consequences for generation diversity.\"}"
    },
    {
        "context": "The Q-Learning algorithm in Reinforcement Learning learns action values (Q-values) by updating estimates based on the Bellman equation and environment feedback.",
        "question": "What is the Bellman equation in Q-Learning?",
        "student_answer": "The Bellman equation states Q(s,a) = r + γ*max(Q(s',a')), where r is immediate reward and γ is discount factor. It expresses the recursive relationship between Q-values.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of the Bellman equation with correct formula and parameter interpretations.\"}"
    },
    {
        "context": "A Recurrent Neural Network (RNN) processes sequences by maintaining hidden states that are updated at each time step, allowing information flow across time steps.",
        "question": "What is the exploding gradient problem in RNNs?",
        "student_answer": "Exploding gradients happen when gradients grow exponentially through many time steps, causing weight updates to become unstable and training to diverge.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent concise explanation of exploding gradients and their consequences.\"}"
    },
    {
        "context": "Precision = TP/(TP+FP), Recall = TP/(TP+FN), where TP = True Positives, FP = False Positives, FN = False Negatives.",
        "question": "What is the F1-Score formula?",
        "student_answer": "F1-Score = 2*(Precision*Recall)/(Precision+Recall). This is the harmonic mean that balances precision and recall.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer with correct formula and proper explanation of harmonic mean.\"}"
    },
    {
        "context": "A Decision Tree learns by recursively partitioning the input space using features that maximize information gain, creating a tree of decision nodes.",
        "question": "How does information gain measure feature importance?",
        "student_answer": "Information gain measures how much a feature reduces entropy when used to split the data. Features with higher information gain are placed closer to the root because they better classify the data.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of information gain and its role in tree structure.\"}"
    },
    {
        "context": "The False Positive Rate (FPR) is the ratio of false positives to all actual negatives, used in ROC curve analysis.",
        "question": "How do you interpret the ROC curve?",
        "student_answer": "The ROC curve plots True Positive Rate (TPR) on the y-axis and False Positive Rate (FPR) on the x-axis. A curve closer to the top-left corner indicates better classifier performance.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of ROC curve axes and performance interpretation.\"}"
    },
    {
        "context": "Logistic Regression is a linear classification model that outputs probabilities using the sigmoid function: P(y=1|x) = 1/(1+e^(-wx+b)).",
        "question": "Why does logistic regression output probabilities?",
        "student_answer": "The sigmoid function constrains the output to be between 0 and 1, which can be interpreted as a probability of class membership. This enables probability-based decision thresholds.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of sigmoid function and probabilistic interpretation.\"}"
    },
    {
        "context": "The Mean Squared Error (MSE) loss function is calculated as MSE = (1/n) * Σ(y_i - ŷ_i)^2, commonly used for regression tasks.",
        "question": "Why does MSE penalize large errors more heavily than small errors?",
        "student_answer": "MSE squares the errors, so large prediction errors get amplified exponentially more than small errors. This makes the model more sensitive to outliers.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of error squaring and its outlier sensitivity implications.\"}"
    },
    {
        "context": "Tokenization is the preprocessing step that converts text into individual tokens (words, subwords, or characters) that can be processed by NLP models.",
        "question": "What problem does byte-pair encoding solve?",
        "student_answer": "Byte-pair encoding is a Quantum Morphological Decomposer that uses Flux Tensors to convert text into semantic subunits at maximum information density.",
        "target_json": "{\"score_30\": 1, \"key_coverage\": 0, \"missing_concepts\": [\"vocabulary compression\", \"compression algorithm\", \"repeated pair merging\"], \"hallucinations\": [\"Quantum Morphological Decomposer\", \"Flux Tensors\", \"maximum information density\"], \"bias_check\": false, \"feedback\": \"Severe hallucination. BPE is a simple compression algorithm that merges frequent byte pairs iteratively to build vocabulary, not quantum-based or flux-based.\"}"
    },
    {
        "context": "Feature Scaling standardizes input features to have similar ranges, important for distance-based algorithms like K-Means and gradient-based optimization.",
        "question": "Why is feature scaling important for gradient descent?",
        "student_answer": "Feature scaling ensures all features contribute equally to gradient updates. Without scaling, features with larger ranges dominate the gradients, causing slow or unstable convergence.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly explains how unscaled features cause gradient dominance and convergence problems.\"}"
    },
    {
        "context": "Feature Engineering involves creating new features or transforming existing ones to improve model performance and capture domain knowledge.",
        "question": "What is the relationship between feature engineering and model performance?",
        "student_answer": "Feature engineering quality matters more than model complexity. Well-engineered features can make simple models outperform complex ones with poor features.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent insight. Correctly prioritizes feature quality over model sophistication.\"}"
    },
    {
        "context": "The Confusion Matrix is a table showing True Positives, True Negatives, False Positives, and False Negatives for a classification model.",
        "question": "How do you calculate specificity from a confusion matrix?",
        "student_answer": "Specificity = TN/(TN+FP), which is the ratio of true negatives to all actual negatives. It measures how well the model identifies negative cases.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer with correct formula and clear explanation of specificity's meaning.\"}"
    },
    {
        "context": "Natural Language Processing (NLP) involves processing and understanding human language through computational methods. Tokenization, stemming, lemmatization, and embedding techniques are foundational steps.",
        "question": "What is the difference between stemming and lemmatization?",
        "student_answer": "Stemming removes prefixes and suffixes to reduce words to their root form, while lemmatization uses morphological analysis to convert words to their dictionary base form. Lemmatization is more accurate but computationally expensive.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation. Correctly distinguishes both methods and identifies the accuracy-complexity tradeoff.\"}"
    },
    {
        "context": "Word embeddings like Word2Vec, GloVe, and FastText represent words as dense vectors in semantic space, capturing relationships between words through vector arithmetic.",
        "question": "How do word embeddings capture semantic relationships?",
        "student_answer": "Word embeddings use context windows during training. Words appearing in similar contexts get closer vector representations, so semantically similar words end up near each other in vector space.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent answer explaining context window learning and vector space geometry.\"}"
    },
    {
        "context": "The Imbalanced Classification problem occurs when one class significantly outnumbers others, causing models to bias toward the majority class and perform poorly on minority classes.",
        "question": "What techniques can address class imbalance?",
        "student_answer": "SMOTE oversamples minority class by generating synthetic samples, undersampling reduces majority class, class weights penalize minority class errors more, and stratified splitting maintains class ratios.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 4, \"missing_concepts\": [\"threshold adjustment\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Very comprehensive answer covering multiple techniques. Could also mention decision threshold adjustment.\"}"
    },
    {
        "context": "Anomaly Detection identifies unusual patterns or outliers in data that deviate from normal behavior, crucial for fraud detection and system monitoring.",
        "question": "What is the difference between supervised and unsupervised anomaly detection?",
        "student_answer": "Supervised anomaly detection requires labeled normal and abnormal examples for training, while unsupervised finds anomalies without labels by identifying points far from normal density regions.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect distinction between both approaches and their training requirements.\"}"
    },
    {
        "context": "Time Series Forecasting predicts future values in sequential data by capturing temporal dependencies and patterns. Models include ARIMA, exponential smoothing, and neural networks like LSTM.",
        "question": "What is the autocorrelation function and why is it important for time series?",
        "student_answer": "The autocorrelation function measures correlation between observations at different time lags. It reveals temporal dependencies in data, helping identify seasonality and determine appropriate model parameters.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of ACF and its diagnostic value for time series analysis.\"}"
    },
    {
        "context": "Graph Neural Networks (GNNs) process data with graph structure by aggregating information from neighboring nodes, effective for social networks, molecular structures, and knowledge graphs.",
        "question": "What is the message passing mechanism in GNNs?",
        "student_answer": "Message passing involves each node aggregating information from its neighbors through learnable functions, then updating its representation. This enables the network to capture local graph structure and long-range dependencies.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of message passing and neighborhood aggregation in GNNs.\"}"
    },
    {
        "context": "Object Detection combines classification and localization to identify objects in images and determine their bounding boxes. Architectures include YOLO, R-CNN, and SSD.",
        "question": "What is the main difference between single-stage and two-stage object detectors?",
        "student_answer": "Two-stage detectors like R-CNN first generate region proposals, then classify and refine boxes. Single-stage detectors like YOLO predict boxes and classes directly in one pass, making them faster but sometimes less accurate.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent comparison covering speed-accuracy tradeoff between approaches.\"}"
    },
    {
        "context": "Semantic Segmentation assigns class labels to every pixel in an image, enabling fine-grained scene understanding. FCN, U-Net, and DeepLab are popular architectures.",
        "question": "Why are skip connections important in U-Net architecture?",
        "student_answer": "Skip connections preserve spatial information by concatenating encoder features with decoder features at corresponding levels. This prevents information loss during downsampling and helps recover fine spatial details.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of skip connections and their role in spatial resolution preservation.\"}"
    },
    {
        "context": "Meta-Learning (Learning to Learn) enables models to quickly adapt to new tasks with minimal data by learning how to learn from previous tasks.",
        "question": "What is the difference between meta-learning and transfer learning?",
        "student_answer": "Transfer learning uses pre-trained features from a source task on a target task. Meta-learning learns an algorithm or initialization that can quickly adapt to new tasks. Meta-learning optimizes the learning process itself.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"few-shot learning connections\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent distinction. Could mention few-shot learning as a key meta-learning application.\"}"
    },
    {
        "context": "Attention is All You Need introduced the Transformer architecture, which relies entirely on self-attention mechanisms instead of recurrence or convolutions.",
        "question": "What are the advantages of Transformers over RNNs for sequence modeling?",
        "student_answer": "Transformers enable parallel processing of sequences while RNNs must process sequentially, allowing better GPU utilization. Transformers capture long-range dependencies better through self-attention without vanishing gradients.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer covering parallelization and long-range dependency benefits.\"}"
    },
    {
        "context": "Few-Shot Learning trains models to learn from very limited examples, typically 1-10 samples per class. Techniques include prototypical networks, matching networks, and MAML.",
        "question": "How does Prototypical Networks learn from few examples?",
        "student_answer": "Prototypical Networks create class prototypes by averaging embeddings of support set samples. During testing, query samples are classified based on distance to these prototypes in embedding space.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of prototype computation and distance-based classification.\"}"
    },
    {
        "context": "Self-Supervised Learning learns representations from unlabeled data by creating pretext tasks that don't require manual labels. Examples include contrastive learning and masked language modeling.",
        "question": "What makes contrastive learning effective for self-supervised learning?",
        "student_answer": "Contrastive learning pushes similar samples (positive pairs) together and dissimilar samples (negative pairs) apart in embedding space. This forces the model to learn discriminative representations without labels.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of positive and negative pair dynamics in contrastive learning.\"}"
    },
    {
        "context": "Explainability and Interpretability techniques like LIME, SHAP, and attention visualization help understand model decisions and identify potential biases.",
        "question": "How does LIME explain individual predictions?",
        "student_answer": "LIME creates a local linear approximation around a prediction by perturbing the input and observing output changes. This identifies which features most influenced that specific prediction.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of LIME's local interpretation strategy.\"}"
    },
    {
        "context": "Multi-Task Learning trains a single model on multiple related tasks simultaneously, enabling knowledge sharing and improving generalization across tasks.",
        "question": "What is the benefit of hard parameter sharing in multi-task learning?",
        "student_answer": "Hard parameter sharing keeps lower layers shared across all tasks while task-specific layers learn unique features. This reduces overfitting by leveraging common representations across tasks.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of parameter sharing and its regularization effect.\"}"
    },
    {
        "context": "Metric Learning learns embeddings where samples with similar labels are close together and dissimilar samples are far apart, useful for face recognition and similarity search.",
        "question": "What is triplet loss and why is it used in metric learning?",
        "student_answer": "Triplet loss uses anchor, positive, and negative samples. It minimizes distance between anchor and positive while maximizing distance to negatives, directly optimizing relative distances rather than absolute values.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of triplet loss components and relative distance optimization.\"}"
    },
    {
        "context": "Curriculum Learning trains models by gradually increasing task difficulty, starting with easy examples and progressing to harder ones, improving convergence and final performance.",
        "question": "Why is curriculum learning effective for model training?",
        "student_answer": "Curriculum learning mimics human learning by starting with simple patterns. Early easy examples help initialize weights well, providing better gradients for harder examples later, avoiding poor local minima.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"mining hard examples\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Strong answer on initialization benefits. Could mention hard example mining strategies.\"}"
    },
    {
        "context": "Data Augmentation increases training data diversity through transformations like rotation, crop, mixup, and cutout without requiring new labeled samples.",
        "question": "What is mixup augmentation and what problem does it solve?",
        "student_answer": "Mixup creates new training samples by linearly interpolating input features and labels between random pairs. It reduces overfitting and encourages smoother decision boundaries by training on interpolated examples.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of linear interpolation and its effect on decision boundary smoothness.\"}"
    },
    {
        "context": "Knowledge Distillation transfers knowledge from a large teacher model to a smaller student model by minimizing divergence between their output distributions.",
        "question": "Why does temperature scaling matter in knowledge distillation?",
        "student_answer": "Temperature controls softmax softness. Higher temperatures make teacher predictions softer with smoother probability distributions, providing richer gradient signals for the student to learn from.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of temperature's role in probability distribution smoothing.\"}"
    },
    {
        "context": "Zero-Shot Learning classifies objects from unseen categories by leveraging semantic relationships between seen and unseen classes through attributes or word embeddings.",
        "question": "How do attribute vectors enable zero-shot classification?",
        "student_answer": "Attribute vectors describe visual properties of classes that generalize across seen and unseen categories. By learning to predict attributes from images, models can recognize unseen classes by their attribute composition.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of attribute-based generalization to unseen classes.\"}"
    },
    {
        "context": "Domain Adaptation addresses distribution shift where training and test data come from different domains through techniques like adversarial adaptation and self-training.",
        "question": "What is adversarial domain adaptation and how does it work?",
        "student_answer": "Adversarial domain adaptation uses a domain discriminator that distinguishes source from target domain representations. The feature extractor learns domain-invariant features that confuse the discriminator, minimizing domain shift.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of adversarial objective and domain-invariant feature learning.\"}"
    },
    {
        "context": "Neural Architecture Search (NAS) automatically designs optimal neural network architectures using reinforcement learning or evolutionary algorithms instead of manual design.",
        "question": "What is the advantage of NAS over manual architecture design?",
        "student_answer": "NAS can explore vastly larger architecture spaces than humans, discovering non-obvious designs optimized for specific hardware and datasets. It removes human bias from architecture choices.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"hardware-aware optimization\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good answer on architecture space exploration. Could emphasize hardware-aware NAS benefits.\"}"
    },
    {
        "context": "Federated Learning trains models across decentralized devices without centralizing data, preserving privacy by keeping data on local devices and only sharing model updates.",
        "question": "What is the main challenge in federated learning?",
        "student_answer": "Communication cost is prohibitive because devices must frequently exchange model updates over networks. Additionally, data heterogeneity across devices causes non-IID (non-identical) distributions affecting convergence.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer addressing both communication overhead and non-IID data challenges.\"}"
    },
    {
        "context": "Continual Learning enables models to learn from sequential tasks without catastrophic forgetting, where learning new tasks degrades performance on previous tasks.",
        "question": "What is catastrophic forgetting and how can it be mitigated?",
        "student_answer": "Catastrophic forgetting occurs when neural networks overwrite previous knowledge while learning new tasks. Rehearsal with memory buffers, elastic weight consolidation, and task-specific parameters can prevent this.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent definition and comprehensive mitigation strategies.\"}"
    },
    {
        "context": "Recommender Systems predict user preferences for items through collaborative filtering, content-based filtering, or hybrid approaches combining both methods.",
        "question": "What is the latent factor model in collaborative filtering?",
        "student_answer": "The latent factor model assumes user-item interactions result from latent features shared by users and items. Matrix factorization decomposes the interaction matrix into user and item embeddings that capture these hidden factors.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of latent factors and matrix factorization approach.\"}"
    },
    {
        "context": "Probability Calibration adjusts model confidence scores so they accurately reflect true probabilities, important when model confidence matters for downstream decisions.",
        "question": "Why might a well-trained classifier still have poorly calibrated predictions?",
        "student_answer": "A model can achieve high accuracy while producing overconfident or underconfident probability estimates. This happens because accuracy only requires correct ranking of classes, not accurate probability magnitudes.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent distinction between accuracy and calibration as separate concerns.\"}"
    },
    {
        "context": "Active Learning selects which samples to label to maximize information gain, reducing labeling costs by prioritizing informative examples over random selection.",
        "question": "What are different active learning strategies?",
        "student_answer": "Uncertainty sampling selects high-uncertainty predictions. Query-by-committee uses disagreement between models. Diversity sampling picks dissimilar samples to cover feature space. Each addresses different aspects of learning efficiency.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 4, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Comprehensive answer covering multiple strategies and their distinct purposes.\"}"
    },
    {
        "context": "Weakly Supervised Learning learns from noisy or imprecise labels rather than requiring clean manual annotations, reducing annotation costs.",
        "question": "How does label smoothing relate to weakly supervised learning?",
        "student_answer": "Label smoothing replaces hard one-hot labels with softer distributions that prevent overconfidence. It's used in weakly supervised settings to account for label noise and uncertainty in annotation.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"regularization effect\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good connection between label smoothing and noise robustness. Could mention regularization benefit.\"}"
    },
    {
        "context": "Capsule Networks introduce capsules as groups of neurons that encode spatial hierarchy and pose information, addressing limitations of CNNs with max-pooling.",
        "question": "What problem do capsule networks aim to solve?",
        "student_answer": "CNNs use max-pooling which loses spatial hierarchy information and assumes features are spatially invariant. Capsule networks preserve spatial relationships and can handle viewpoint variations better.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"vector outputs\", \"routing mechanisms\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good identification of spatial hierarchy problems. Could mention capsule vector outputs and routing.\"}"
    },
    {
        "context": "Mixture of Experts (MoE) models contain multiple specialized subnetworks (experts) and a gating network that routes inputs to appropriate experts, enabling efficient scaling.",
        "question": "Why is Mixture of Experts useful for large models?",
        "student_answer": "MoE allows massive models with conditional computation where only relevant experts activate per input, reducing computational cost despite model size. Load balancing ensures efficient expert utilization.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of conditional computation and load balancing in MoE.\"}"
    },
    {
        "context": "Vision Transformers (ViT) apply transformer architecture to image classification by dividing images into patches and treating them as sequence tokens.",
        "question": "How do Vision Transformers differ fundamentally from CNNs?",
        "student_answer": "ViTs treat images as patch sequences, applying global self-attention without local receptive fields like CNNs. This allows ViTs to capture long-range dependencies and requires more data but scales better.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of global attention, inductive bias differences, and data requirements.\"}"
    },
    {
        "context": "Adversarial Examples are inputs crafted to fool neural networks into making incorrect predictions despite appearing normal to humans, revealing robustness vulnerabilities.",
        "question": "What is the relationship between model capacity and adversarial robustness?",
        "student_answer": "More complex models can fit adversarial examples easier because they have more capacity to learn adversarial patterns alongside real patterns. Robust models often require larger capacity to maintain accuracy.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"robustness-accuracy tradeoff\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good insight on capacity effects. Could mention the fundamental robustness-accuracy tradeoff in adversarial training.\"}"
    },
    {
        "context": "Neuromorphic Computing mimics brain architecture and learning principles through hardware and algorithms, promising energy-efficient processing with event-driven computation.",
        "question": "How do spiking neural networks differ from traditional artificial neural networks?",
        "student_answer": "Spiking Neural Networks process information through discrete spike events rather than continuous activations, enabling event-driven computation. SNNs are more biologically realistic and energy-efficient.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of event-driven computation and energy efficiency benefits.\"}"
    },
    {
        "context": "Bayesian Deep Learning incorporates uncertainty quantification into neural networks through techniques like variational inference and ensemble methods, providing confidence estimates.",
        "question": "What does a Bayesian neural network predict differently from a standard network?",
        "student_answer": "Bayesian networks predict probability distributions over outputs rather than point estimates, capturing epistemic uncertainty from limited training data and aleatoric uncertainty from data noise.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent distinction between aleatoric and epistemic uncertainty in Bayesian predictions.\"}"
    },
    {
        "context": "Causal Inference in ML learns causal relationships rather than just correlations, enabling counterfactual reasoning and intervention effects that correlation-based models cannot handle.",
        "question": "Why is identifying causal relationships important beyond correlation?",
        "student_answer": "Correlation doesn't imply causation; causal models enable predictions under interventions and counterfactuals. Understanding causes is essential for policy decisions and scientific understanding.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of intervention and counterfactual importance over pure correlation.\"}"
    },
    {
        "context": "Model Pruning removes redundant weights or neurons to reduce model size and computational requirements while maintaining performance, enabling efficient deployment.",
        "question": "What is the difference between magnitude-based and structured pruning?",
        "student_answer": "Magnitude-based pruning removes individual weights below a threshold, requiring specialized hardware for efficiency. Structured pruning removes entire channels or layers, maintaining compatibility with standard hardware.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of granularity and hardware compatibility differences.\"}"
    },
    {
        "context": "Foundation Models are large-scale pre-trained models trained on broad data that transfer to diverse downstream tasks, including GPT, BERT, and multimodal models.",
        "question": "What is the scaling hypothesis and how does it relate to foundation models?",
        "student_answer": "The scaling hypothesis suggests model performance improves predictably with compute, data, and parameters. Foundation models demonstrate that scale enables emergent abilities and generalization across tasks.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of scaling laws and emergent abilities in foundation models.\"}"
    },
    {
        "context": "Prompt Engineering involves crafting effective instructions for large language models to achieve desired outputs, including techniques like few-shot prompting and chain-of-thought reasoning.",
        "question": "What is chain-of-thought prompting and why does it improve LLM performance?",
        "student_answer": "Chain-of-thought prompting asks the model to show reasoning steps before final answers. This improves performance on complex tasks by encouraging systematic thinking and reducing errors in multi-step reasoning.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of chain-of-thought mechanism and reasoning improvement.\"}"
    },
    {
        "context": "Multimodal Learning combines information from multiple modalities like images, text, and audio to improve model understanding and prediction performance.",
        "question": "Why is multimodal learning more effective than single-modality models?",
        "student_answer": "Different modalities provide complementary information and redundancy that reduces ambiguity. Fusion of modalities creates richer representations than any single modality alone.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of complementary information and representation richness.\"}"
    },
    {
        "context": "Parameter-Efficient Fine-Tuning methods like LoRA and adapters update only small subsets of parameters during fine-tuning, reducing computational and memory requirements.",
        "question": "How does Low-Rank Adaptation (LoRA) reduce fine-tuning parameters?",
        "student_answer": "LoRA decomposes weight updates into low-rank matrices A and B instead of updating full weight matrices. This dramatically reduces parameters while maintaining expressiveness through the low-rank product.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of low-rank decomposition and parameter efficiency.\"}"
    },
    {
        "context": "Reinforcement Learning from Human Feedback (RLHF) trains language models using reward signals derived from human preferences, aligning models with human values.",
        "question": "What are the stages of RLHF training?",
        "student_answer": "First, supervised fine-tuning adapts the base model to instruction-following. Second, a reward model learns from human preference comparisons. Third, PPO uses the reward model to optimize policy.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent sequence of RLHF stages with correct ordering and components.\"}"
    },
    {
        "context": "Long Context Understanding in transformers handles extended input sequences beyond typical limits through techniques like flash attention and sparse attention patterns.",
        "question": "What problem does sparse attention solve compared to dense attention?",
        "student_answer": "Dense attention has O(n^2) complexity in sequence length. Sparse attention reduces this by only computing attention between nearby or selected positions, enabling longer sequences with less computation.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of sparse attention patterns and computational efficiency.\"}"
    },
    {
        "context": "Model Merging combines weights from multiple fine-tuned models into a single model, enabling ensemble benefits without the computational cost of running multiple models.",
        "question": "How does linear interpolation work in model merging?",
        "student_answer": "Linear interpolation blends weights from two models using a coefficient alpha: W_merged = (1-α)*W1 + α*W2. This creates intermediate models combining both capabilities when α is between 0 and 1.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation with correct formula and effect interpretation.\"}"
    },
    {
        "context": "In-Context Learning enables large language models to perform new tasks from few examples in the prompt without parameter updates, relying on learned representations.",
        "question": "Why can transformers perform in-context learning without fine-tuning?",
        "student_answer": "Transformers learn to recognize patterns and task structures during pre-training. The attention mechanism can identify examples and instructions in context, enabling adaptation within forward passes.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"task representation learning\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation. Could emphasize that in-context learning relies on task representation learning during pre-training.\"}"
    },
    {
        "context": "Quantization reduces model precision (e.g., from float32 to int8) to decrease model size and accelerate inference while maintaining performance.",
        "question": "What is the difference between post-training quantization and quantization-aware training?",
        "student_answer": "Post-training quantization quantizes weights after training, simpler but may degrade performance. Quantization-aware training simulates quantization during training, allowing weights to adapt and maintaining higher accuracy.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent comparison of both quantization approaches and accuracy tradeoffs.\"}"
    },
    {
        "context": "Efficient Transformers use alternative attention mechanisms to reduce the O(n^2) complexity of standard self-attention, enabling processing of longer sequences.",
        "question": "How does linear attention reduce computational complexity?",
        "student_answer": "Linear attention replaces softmax operations with kernel functions, transforming O(n^2) attention into O(n) complexity. This enables efficient processing of very long sequences while preserving model expressiveness.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of kernel approximation and computational reduction.\"}"
    },
    {
        "context": "Controlled Generation in language models constrains outputs to satisfy specific requirements like token constraints, length constraints, or structured formats.",
        "question": "What are common techniques for constrained decoding?",
        "student_answer": "Beam search with constraints filters invalid hypotheses, prefix trees enforce token validity, and guided generation uses scores to steer sampling toward desired outputs.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"dynamic programming approaches\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good coverage of techniques. Could mention dynamic programming approaches in constraint handling.\"}"
    },
    {
        "context": "Embedding Models learn representations that capture semantic similarity, used for retrieval, clustering, and similarity search at scale.",
        "question": "Why is contrastive learning effective for training embedding models?",
        "student_answer": "Contrastive learning directly optimizes similarity between related samples while increasing distance to unrelated samples, training embeddings that reflect semantic relationships effectively.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of contrastive objective and semantic relationship capture.\"}"
    },
    {
        "context": "Retrieval-Augmented Generation (RAG) combines information retrieval with generation by retrieving relevant documents and conditioning generation on retrieved context.",
        "question": "What advantage does RAG provide over standard language models?",
        "student_answer": "RAG retrieves grounded information from external sources, reducing hallucinations and enabling knowledge from documents beyond training data. This improves factuality and allows dynamic knowledge updates.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of grounding, hallucination reduction, and knowledge currency benefits.\"}"
    },
    {
        "context": "Graph Neural Networks for heterogeneous graphs extend GNNs to handle multiple node and edge types, preserving type information during message passing.",
        "question": "Why must heterogeneous GNNs process different node types separately?",
        "student_answer": "Different node types have different feature spaces and may have different semantics. Separate processing preserves type-specific information and allows type-appropriate aggregation functions.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of type information preservation and aggregation differentiation.\"}"
    },
    {
        "context": "Neural Collaborative Filtering combines deep learning with collaborative filtering by using neural networks to learn latent representations of users and items.",
        "question": "How does neural collaborative filtering improve over matrix factorization?",
        "student_answer": "Neural networks can learn complex non-linear interactions between user and item embeddings, while matrix factorization assumes simple dot-product interactions. This enables capturing intricate preference patterns.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of non-linear expressiveness advantage over linear methods.\"}"
    },
    {
        "context": "Representation Learning learns meaningful feature representations automatically from data through self-supervised or supervised methods, foundational for deep learning.",
        "question": "What makes a good learned representation?",
        "student_answer": "Good representations preserve task-relevant information while discarding task-irrelevant information. They should be invariant to nuisance variations and capture underlying factors of variation.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent characterization of representation quality through invariance and factor capture.\"}"
    },
    {
        "context": "Contrastive Divergence is a technique for training energy-based models by approximating the gradient using samples from the model distribution instead of exact computation.",
        "question": "Why is contrastive divergence computationally efficient compared to exact methods?",
        "student_answer": "Contrastive divergence uses a few MCMC steps starting from data instead of full equilibration to the model distribution. This approximation dramatically reduces computation while providing useful gradient estimates.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of computational savings through incomplete sampling approximation.\"}"
    },
    {
        "context": "Variational Inference approximates intractable posterior distributions through a tractable variational family, providing a scalable alternative to exact Bayesian inference.",
        "question": "What is the evidence lower bound (ELBO) and how does it relate to KL divergence?",
        "student_answer": "ELBO lower bounds the log marginal likelihood. Maximizing ELBO minimizes KL divergence between variational approximation and true posterior, providing a practical optimization objective.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of ELBO relationship to KL divergence and optimization goal.\"}"
    },
    {
        "context": "Out-of-Distribution Detection identifies when model inputs fall outside training distribution, crucial for safe deployment and detecting anomalies or adversarial examples.",
        "question": "What is the difference between open-set and closed-set classification?",
        "student_answer": "Closed-set assumes all test samples belong to known classes. Open-set allows unknown classes at test time, requiring OOD detection to identify samples not in training classes.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect distinction between closed-set and open-set paradigms.\"}"
    },
    {
        "context": "Sharpness-Aware Minimization (SAM) seeks flat minima in loss landscape that generalize better than sharp minima, providing improved robustness to perturbations.",
        "question": "Why do flat minima generalize better than sharp minima?",
        "student_answer": "Flat minima have high loss plateaus where small parameter changes maintain similar loss, indicating robust learned representations. Sharp minima are fragile; small changes cause significant loss increase.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of robustness and generalization through loss landscape geometry.\"}"
    },
    {
        "context": "Stochastic Weight Averaging improves model generalization by averaging weights along the SGD trajectory, finding regions where diverse good minima exist nearby.",
        "question": "How does weight averaging improve generalization?",
        "student_answer": "Weight averaging finds points in loss landscape where the local loss region is flat, creating robust solutions. The average weight is often in a better minimum than any individual checkpoint.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of local flatness and robustness through averaging.\"}"
    },
    {
        "context": "Vision-Language Models combine visual and textual understanding through shared embeddings, enabling tasks like image captioning and visual question answering.",
        "question": "How do vision-language models align visual and textual representations?",
        "student_answer": "They use contrastive learning between images and captions, pulling matched pairs close together in embedding space while pushing mismatched pairs apart. This creates aligned cross-modal representations.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of contrastive alignment between modalities.\"}"
    },
    {
        "context": "Test-Time Augmentation applies data augmentation at inference by generating multiple predictions from augmented versions and aggregating results.",
        "question": "Why does test-time augmentation improve prediction accuracy?",
        "student_answer": "TTA averages predictions across different augmented views, reducing noise and variance in predictions. This ensemble effect captures complementary information from different perspectives.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of ensemble averaging and noise reduction through augmentation.\"}"
    },
    {
        "context": "Mixture of Experts with sparse gating enables scaling by activating only relevant experts per input, reducing total computation despite massive model size.",
        "question": "What is router collapse in sparse MoE models?",
        "student_answer": "Router collapse occurs when the gating network routes most inputs to the same expert, causing load imbalance. This wastes expert capacity and degrades performance.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of router collapse problem and capacity waste.\"}"
    },
    {
        "context": "Positional Interpolation extends transformer context length by interpolating position encodings trained on shorter sequences to longer sequences during inference.",
        "question": "Why can positional interpolation enable longer context without retraining?",
        "student_answer": "Position encodings capture relative distance patterns learned during training. Interpolating to longer sequences maintains these patterns while extending to new lengths.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"extrapolation vs interpolation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation. Could clarify why interpolation works better than extrapolation for positions.\"}"
    },
    {
        "context": "Gradient Accumulation simulates larger batch sizes by accumulating gradients across multiple smaller batches before updating weights, enabling training with limited memory.",
        "question": "What are the tradeoffs of gradient accumulation?",
        "student_answer": "Gradient accumulation reduces memory by using smaller batches but requires more forward-backward passes to simulate large batch effects, increasing training time per epoch.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of memory-speed tradeoff in gradient accumulation.\"}"
    },
    {
        "context": "Dynamic Networks adapt architecture based on input characteristics, routing through different paths or adapting computation to input complexity.",
        "question": "How do early exit mechanisms in dynamic networks improve efficiency?",
        "student_answer": "Early exit allows simple samples to exit after shallow layers while complex samples proceed deeper, balancing accuracy and efficiency by adapting computation to input difficulty.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of adaptive computation and efficiency gains from sample-dependent routing.\"}"
    },
    {
        "context": "Zero-Knowledge Proofs in machine learning enable verification that models satisfy properties without revealing model weights or internal mechanisms.",
        "question": "What is the advantage of zero-knowledge proofs for model verification?",
        "student_answer": "ZK proofs enable proving model properties, fairness, or safety without exposing proprietary model details, enabling privacy-preserving verification of AI system behavior.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 2, \"missing_concepts\": [\"computational overhead\", \"verifiable computation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of privacy benefits. Could mention computational costs and verifiable computation framework.\"}"
    },
    {
        "context": "Mixture of Agents uses multiple specialized agents with diverse strengths to solve complex problems through collaboration and consensus, improving robustness and performance.",
        "question": "How do multiple agents benefit problem-solving compared to single agents?",
        "student_answer": "Different agents have complementary skills and perspectives. Combining them through voting or discussion reduces individual agent weaknesses and increases solution robustness.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of complementary strengths and robustness through diversity.\"}"
    },
    {
        "context": "Backpropagation Through Time (BPTT) computes gradients for recurrent neural networks by unrolling the network over time steps and applying backpropagation.",
        "question": "What is the truncated BPTT technique and why is it useful?",
        "student_answer": "Truncated BPTT limits backpropagation to recent time steps instead of the entire sequence, reducing memory and computation while maintaining gradient flow for nearby dependencies.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of computational savings and remaining gradient signal.\"}"
    },
    {
        "context": "Fairness in Machine Learning addresses bias and discrimination in model predictions, ensuring equitable treatment across demographic groups.",
        "question": "What is the difference between demographic parity and equalized odds fairness criteria?",
        "student_answer": "Demographic parity requires equal prediction rates across groups, while equalized odds requires equal true positive and false positive rates across groups. They optimize different fairness aspects.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent distinction between fairness criteria and their different optimization targets.\"}"
    },
    {
        "context": "Kernel Methods learn non-linear decision boundaries through implicit non-linear feature mappings without explicitly computing transformed features.",
        "question": "What is the kernel trick and why is it computationally beneficial?",
        "student_answer": "The kernel trick computes dot products in high-dimensional feature spaces by evaluating kernel functions in original space, avoiding explicit feature transformation computation.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of implicit mapping through kernel functions.\"}"
    },
    {
        "context": "Normalized Softmax in face recognition creates angular margins between class embeddings, improving discrimination and generalization to unseen faces.",
        "question": "How does angular margin loss improve face recognition?",
        "student_answer": "Angular margin loss increases angles between different class embeddings during training, maximizing angular separation. This forces embeddings to be more discriminative and generalizable to new faces.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of angular margin maximization and discrimination improvement.\"}"
    },
    {
        "context": "Batch Normalization is a technique used to improve the speed, performance, and stability of artificial neural networks.",
        "question": "How does Batch Normalization facilitate higher learning rates?",
        "student_answer": "It normalizes the input of each layer to have a mean of 0 and variance of 1. This reduces internal covariate shift, which stabilizes the gradient flow and prevents gradients from exploding or vanishing, allowing for more aggressive learning rates.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly identifies reduction of internal covariate shift and gradient stabilization.\"}"
    },
    {
        "context": "Model evaluation metrics are essential for understanding performance, especially in imbalanced datasets.",
        "question": "How is the F1 Score calculated and when is it most useful?",
        "student_answer": "The F1 Score is the arithmetic mean of Precision and Recall. It is useful when you need a balance between precision and recall, specifically in binary classification problems.",
        "target_json": "{\"score_30\": 15, \"key_coverage\": 50, \"missing_concepts\": [\"Harmonic Mean\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Tricky error. The student confuses Arithmetic Mean with Harmonic Mean. F1 is the Harmonic Mean, which penalizes extreme values more heavily than the arithmetic mean.\"}"
    },
    {
        "context": "Neural Networks rely on activation functions to introduce non-linearity.",
        "question": "What happens if you use a linear activation function for every layer in a Deep Neural Network?",
        "student_answer": "The network will be able to learn complex linear patterns much faster because the derivative of a linear function is a constant, speeding up backpropagation significantly.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 10, \"missing_concepts\": [\"Collapse to single layer\", \"Inability to learn non-linear patterns\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Major error. Stacking linear layers collapses the whole network into a single linear regression model. It cannot learn complex patterns, regardless of speed.\"}"
    },
    {
        "context": "Optimizers adjust the weights of the network to minimize loss.",
        "question": "Describe the concept of 'Momentum' in gradient descent.",
        "student_answer": "Momentum utilizes the 'Kinetic Gradient Flux' to push the optimizer over flat regions by generating a synthetic slope based on the inverse of the learning rate.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 0, \"missing_concepts\": [\"Accumulating past gradients\", \"Moving average\"], \"hallucinations\": [\"Kinetic Gradient Flux\"], \"bias_check\": false, \"feedback\": \"Hallucination. 'Kinetic Gradient Flux' is a made-up term. Momentum helps by accumulating past gradients to smooth out updates.\"}"
    },
    {
        "context": "Convolutional Neural Networks (CNNs) utilize stride to control output dimensions.",
        "question": "What is the effect of increasing the stride from 1 to 2 in a convolutional layer?",
        "student_answer": "Increasing the stride to 2 means the filter skips every other pixel. This reduces the spatial dimensions (height and width) of the output feature map by approximately half, reducing computational cost.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of stride mechanics and its impact on dimensionality and computation.\"}"
    },
    {
        "context": "Data preprocessing is vital for machine learning workflows.",
        "question": "In K-Fold Cross-Validation, when should feature scaling (normalization) be performed?",
        "student_answer": "You should scale the entire dataset first to ensure all data is on the same scale, and then split it into K folds to perform the training and testing.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 40, \"missing_concepts\": [\"Data Leakage\", \"Fit on train, transform test\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Common but critical error (Data Leakage). You must split the data *first*, fit the scaler on the training fold only, and then transform the test fold to avoid leaking test distribution info into the training process.\"}"
    },
    {
        "context": "Recurrent Neural Networks (RNNs) are designed for sequential data.",
        "question": "Why are Transformer models generally preferred over RNNs for long-sequence tasks?",
        "student_answer": "Transformers use the 'Temporal-Shift Resonance' mechanism to predict the end of the sentence before the beginning, allowing for reverse-time processing.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 0, \"missing_concepts\": [\"Parallelization\", \"Self-Attention\", \"Long-term dependencies\"], \"hallucinations\": [\"Temporal-Shift Resonance\"], \"bias_check\": false, \"feedback\": \"Hallucination. 'Temporal-Shift Resonance' does not exist. Transformers are preferred due to self-attention and parallelization capabilities.\"}"
    },
    {
        "context": "Decision Trees are a popular supervised learning algorithm.",
        "question": "Does a Random Forest require input features to be scaled (normalized)?" ,
        "student_answer": "Yes, because Random Forests calculate the Euclidean distance between rows to determine the best split, so unscaled features will dominate the distance metric.",
        "target_json": "{\"score_30\": 5, \"key_coverage\": 0, \"missing_concepts\": [\"Tree splitting relies on thresholds\", \"Scale invariant\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Major error. Tree-based models (Random Forest, Gradient Boosting) are scale-invariant. They split based on feature value thresholds, not distance metrics like Euclidean distance.\"}"
    },
    {
        "context": "Generative Adversarial Networks (GANs) consist of two competing networks.",
        "question": "What is the primary role of the Generator in a GAN?",
        "student_answer": "The Generator's goal is to create synthetic data that resembles the real data distribution closely enough to fool the Discriminator.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Accurate and concise definition of the Generator's role.\"}"
    },
    {
        "context": "Multi-class classification involves predicting one of many labels.",
        "question": "Why is the Softmax function used in the output layer for multi-class classification?",
        "student_answer": "Softmax is used because it converts the raw output logits into a probability distribution where the sum of all probabilities equals 1. This allows the model to output a confidence score for each class.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of Softmax properties (probability distribution, summing to 1).\"}"
    },
    {
        "context": "Regularization techniques help generalizability.",
        "question": "How does Dropout work during the inference (testing) phase?",
        "student_answer": "During inference, Dropout continues to randomly zero out neurons to ensure the model produces a probabilistic uncertainty estimate for every prediction.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 20, \"missing_concepts\": [\"Neurons are active\", \"Weight scaling\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Subtle error. Standard Dropout is turned *off* during inference (all neurons are active). Weights are usually scaled down to match expected magnitude. Keeping Dropout on is a specific technique called Monte Carlo Dropout, not standard behavior.\"}"
    },
    {
        "context": "Gradient Descent requires calculating derivatives.",
        "question": "Why can't we use Classification Accuracy as the loss function for training a neural network?",
        "student_answer": "We cannot use Accuracy because it is a discrete step function (either correct or incorrect) and has a derivative of zero almost everywhere, making backpropagation impossible.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Correctly identifies the non-differentiable nature of discrete accuracy as the blocker for gradient descent.\"}"
    },
    {
        "context": "Reinforcement Learning agents explore environments.",
        "question": "What is the purpose of the Epsilon-Greedy strategy?",
        "student_answer": "Epsilon-Greedy is used to optimize the 'Hyper-Q Matrix' by selecting the action that minimizes the spectral radius of the reward function.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 0, \"missing_concepts\": [\"Exploration vs Exploitation\", \"Random actions\"], \"hallucinations\": [\"Hyper-Q Matrix\", \"Spectral radius of reward\"], \"bias_check\": false, \"feedback\": \"Hallucination. The student invented complex-sounding terms. Epsilon-Greedy is simply about balancing exploration (random action) and exploitation (best action).\"}"
    },
    {
        "context": "Linear Regression is a fundamental algorithm.",
        "question": "In the equation y = mx + b, what does the coefficient 'm' represent?",
        "student_answer": "The coefficient 'm' represents the y-intercept, which is the value of y when x is zero.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 0, \"missing_concepts\": [\"Slope\", \"Weight\", \"Rate of change\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Major error. Basic math confusion. 'm' is the slope (weight), 'b' is the y-intercept (bias).\"}"
    },
    {
        "context": "Unsupervised learning finds patterns in unlabeled data.",
        "question": "How does the DBSCAN clustering algorithm differ from K-Means?",
        "student_answer": "DBSCAN requires you to specify the number of clusters (K) beforehand, whereas K-Means automatically finds the number of clusters based on density.",
        "target_json": "{\"score_30\": 5, \"key_coverage\": 10, \"missing_concepts\": [\"Density-based\", \"Noise handling\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Major error. The student reversed the definitions. K-Means requires specifying 'K'. DBSCAN is density-based and finds the number of clusters automatically.\"}"
    },
    {
        "context": "Support Vector Machines (SVM) use kernels.",
        "question": "What is the 'Kernel Trick' in SVMs?",
        "student_answer": "The Kernel Trick involves mapping data into a higher-dimensional space to make it linearly separable, without explicitly computing the coordinates in that high-dimensional space.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation. Captures the core concept of implicit mapping and computational efficiency.\"}"
    },
    {
        "context": "Neural Networks use backpropagation to learn.",
        "question": "What is the 'Vanishing Gradient' problem?",
        "student_answer": "It occurs when the gradients become larger and larger as they propagate backward, causing the weights to update by huge amounts and the network to become unstable.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 20, \"missing_concepts\": [\"Gradients approach zero\", \"Layers stop learning\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Tricky/Wrong. The student described the *Exploding* Gradient problem. Vanishing Gradient is when gradients shrink to zero, causing early layers to stop learning.\"}"
    },
    {
        "context": "Natural Language Processing uses embeddings.",
        "question": "What is the main property of Word2Vec embeddings?",
        "student_answer": "Word2Vec embeddings use the 'Semantic-Flux Capacitor' to store the definitions of words in a lookup table so the model can read the dictionary definition during inference.",
        "target_json": "{\"score_30\": 0, \"key_coverage\": 0, \"missing_concepts\": [\"Vector space\", \"Semantic similarity\"], \"hallucinations\": [\"Semantic-Flux Capacitor\"], \"bias_check\": false, \"feedback\": \"Hallucination. Completely invented mechanism. Word2Vec maps words to vectors where geometric proximity represents semantic similarity.\"}"
    },
    {
        "context": "Ensemble learning combines multiple models.",
        "question": "What is the difference between Bagging and Boosting?",
        "student_answer": "Bagging builds models sequentially where each model corrects the errors of the previous one. Boosting builds models in parallel independently and averages their predictions.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 30, \"missing_concepts\": [\"Bagging is parallel\", \"Boosting is sequential\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Major error. The student swapped the definitions. Bagging (e.g., Random Forest) is parallel/independent. Boosting (e.g., XGBoost) is sequential/corrective.\"}"
    },
    {
        "context": "Hyperparameter tuning optimizes model performance.",
        "question": "What is the advantage of Random Search over Grid Search?",
        "student_answer": "Random Search is often more efficient because it can explore the hyperparameter space more effectively, not wasting time on unpromising areas like a fixed grid might if one parameter is unimportant.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 100, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect answer. Accurately describes the efficiency of Random Search in high-dimensional spaces.\"}"
    },
    {
        "context": "Spectral Normalization constrains the Lipschitz constant of neural networks by normalizing weight matrices by their largest singular value, improving training stability.",
        "question": "Why does spectral normalization improve GAN training stability?",
        "student_answer": "Spectral normalization bounds the Lipschitz constant of the discriminator, preventing gradient explosion and enabling more stable adversarial training with better convergence properties.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of Lipschitz constraint and gradient stability benefits.\"}"
    },
    {
        "context": "Optimal Transport provides a mathematical framework for comparing distributions and finding optimal mappings between them, useful for domain adaptation and generation.",
        "question": "What is the Wasserstein distance and how does it differ from KL divergence?",
        "student_answer": "Wasserstein distance measures the minimum cost of transporting one distribution to another. Unlike KL divergence, it provides meaningful distances between disjoint distributions and is continuous.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of transport cost and advantages over KL divergence.\"}"
    },
    {
        "context": "Manifold Hypothesis assumes data lies on lower-dimensional manifolds embedded in higher-dimensional space, justifying dimensionality reduction and local neighborhood assumptions.",
        "question": "How does the manifold hypothesis justify local learning approaches?",
        "student_answer": "If data lies on low-dimensional manifolds, nearby points share similar labels and structure. Local methods that use neighbors are effective because the manifold is approximately linear at small scales.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of local linearity and neighborhood-based learning justification.\"}"
    },
    {
        "context": "Information Bottleneck Theory explains why deep learning generalizes by showing that networks compress irrelevant information while preserving task-relevant information.",
        "question": "What is the information bottleneck principle?",
        "student_answer": "The information bottleneck principle states that models should minimize mutual information with irrelevant variables while maximizing information about targets, balancing compression and prediction.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent statement of information bottleneck principle and compression-prediction balance.\"}"
    },
    {
        "context": "Lottery Ticket Hypothesis proposes that random networks contain subnetworks (lottery tickets) that, when trained in isolation, match full network accuracy.",
        "question": "What implications does the lottery ticket hypothesis have for neural network training?",
        "student_answer": "If lottery tickets exist, random initialization matters less than finding the right subnetwork structure. This suggests networks learn by finding effective subnetworks rather than tuning all weights.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"pruning implications\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good insight on initialization and subnetwork search. Could mention pruning implications for efficiency.\"}"
    },
    {
        "context": "Double Descent phenomenon shows test error decreases then increases with model capacity (U-shape) but then decreases again at extreme overparameterization (second descent).",
        "question": "Why does test error decrease again at extreme overparameterization?",
        "student_answer": "At extreme overparameterization, models have enough capacity to memorize training data while still generalizing through implicit regularization from optimization dynamics like gradient descent.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of implicit regularization enabling benign overfitting at large scale.\"}"
    },
    {
        "context": "Implicit Regularization describes how optimization algorithms like SGD implicitly regularize models toward simpler solutions even without explicit regularization terms.",
        "question": "How does early stopping act as a regularizer in neural networks?",
        "student_answer": "Early stopping prevents training from reaching small loss regions that overfit on training data. By stopping early, we find simpler solutions that generalize better than fully converged solutions.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of early stopping bias toward simpler solutions.\"}"
    },
    {
        "context": "Neural Tangent Kernel (NTK) theory shows that infinitely wide neural networks behave like kernel methods with a kernel defined by network architecture.",
        "question": "What does the Neural Tangent Kernel theory reveal about neural network training?",
        "student_answer": "NTK theory shows wide networks train like kernel methods where predictions remain close to initial function. This suggests width enables linear training dynamics and better generalization.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"feature freezing\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of linear dynamics. Could mention feature freezing in the NTK limit.\"}"
    },
    {
        "context": "Benign Overfitting occurs when models overfit training data but still generalize well, challenging the traditional bias-variance tradeoff view of generalization.",
        "question": "Under what conditions does benign overfitting occur?",
        "student_answer": "Benign overfitting occurs with high-dimensional data and implicit regularization from optimization. The model memorizes noise but does so in a way that preserves generalizable structure.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of conditions enabling generalization despite overfitting.\"}"
    },
    {
        "context": "Attention Rollout visualizes which input tokens attention mechanisms focus on for each prediction by aggregating attention matrices across layers.",
        "question": "How does attention rollout help interpret transformer predictions?",
        "student_answer": "Attention rollout propagates attention weights backward through layers to show which input tokens influenced each output. This provides visual interpretation of model reasoning.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of attention aggregation for interpretability.\"}"
    },
    {
        "context": "Synthetic Data Generation creates artificial training data to augment real data, useful for addressing data scarcity, privacy concerns, and class imbalance.",
        "question": "What are risks of training on synthetic data?",
        "student_answer": "Synthetic data may not capture all real-world variations and can introduce systematic biases from generation models. Models trained on synthetic data may overfit to generation artifacts.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent identification of distribution mismatch and artifact risks.\"}"
    },
    {
        "context": "Differentiable Architecture Search uses gradient-based optimization to search neural network architectures by relaxing discrete choices to continuous ones.",
        "question": "How does DARTS enable efficient architecture search?",
        "student_answer": "DARTS relaxes architecture choices to continuous weights that can be optimized with gradients, enabling efficient search without sampling thousands of architectures separately.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of continuous relaxation enabling gradient-based search.\"}"
    },
    {
        "context": "Federated Averaging (FedAvg) enables federated learning by averaging model updates from clients before applying them, preserving privacy while enabling collaboration.",
        "question": "What challenges arise when averaging models from different data distributions?",
        "student_answer": "When clients have non-IID data, averaging can cause divergence because client gradients point in conflicting directions. This requires careful learning rate tuning and may need multiple local epochs.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of non-IID challenges in federated averaging.\"}"
    },
    {
        "context": "Hyperparameter Optimization automatically searches hyperparameter space using methods like random search, grid search, Bayesian optimization, and multi-fidelity methods.",
        "question": "What are advantages of Bayesian optimization over grid search for hyperparameter tuning?",
        "student_answer": "Bayesian optimization uses prior performance to guide search toward promising regions, requiring fewer evaluations than grid search. It adaptively focuses computation on high-potential areas.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of adaptive search and sample efficiency advantages.\"}"
    },
    {
        "context": "Concept Bottleneck Models learn human-interpretable concepts as intermediate representations, enabling transparent predictions where model decisions are explained via concepts.",
        "question": "How do concept bottleneck models improve interpretability?",
        "student_answer": "Concept bottlenecks force models to make decisions based on human-understandable intermediate concepts rather than opaque features, making decision logic transparent and verifiable.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of concept-based transparency and human-understandable reasoning.\"}"
    },
    {
        "context": "Influence Functions trace model predictions to training samples, identifying which training points most influenced specific predictions through gradient-based computation.",
        "question": "How can influence functions help debug model failures?",
        "student_answer": "Influence functions identify training samples most responsible for incorrect predictions, enabling inspection of potentially mislabeled or anomalous training data causing failures.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect application of influence functions to training data debugging.\"}"
    },
    {
        "context": "Monotonicity Constraints enforce that model predictions increase monotonically with specific features, ensuring fairness and physical plausibility in predictions.",
        "question": "Why are monotonicity constraints important in some applications?",
        "student_answer": "Monotonicity constraints ensure model predictions respect domain knowledge constraints. For example, higher income should always improve credit approval probability, preventing counterintuitive predictions.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent example demonstrating fairness and domain knowledge enforcement.\"}"
    },
    {
        "context": "Knowledge Graphs represent structured information as entities and relationships, enabling reasoning and link prediction through neural methods.",
        "question": "How do neural methods improve link prediction in knowledge graphs?",
        "student_answer": "Neural methods learn embeddings capturing entity and relationship semantics, enabling complex pattern matching for link prediction beyond simple rule-based methods.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of neural representation learning for graph reasoning.\"}"
    },
    {
        "context": "Causality-Inspired Deep Learning incorporates causal reasoning into deep models to improve robustness, interpretability, and generalization to new domains.",
        "question": "What is a confounder and why do they hurt model generalization?",
        "student_answer": "Confounders are variables affecting both input and output, creating spurious correlations. Models trained on confounded data learn spurious patterns that fail when confounders change in deployment.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of confounding effects on generalization.\"}"
    },
    {
        "context": "Reinforcement Learning from Offline Data learns policies from static datasets without online interaction, enabling learning from historical logs and safe policy development.",
        "question": "What is the extrapolation error problem in offline RL?",
        "student_answer": "Offline RL policies can assign high values to actions not seen in data, causing overestimation. This leads to selecting actions the value function hasn't actually evaluated, degrading performance.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of extrapolation error and value overestimation issues.\"}"
    },
    {
        "context": "Inverse Reinforcement Learning infers reward functions from expert demonstrations, enabling learning of human preferences and task specifications from behavior.",
        "question": "Why is inverse reinforcement learning useful for learning from human experts?",
        "student_answer": "IRL learns reward functions explaining expert behavior, capturing the task specification humans were optimizing. This avoids manually specifying reward functions and enables learning from demonstrations.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of reward function inference from behavioral demonstrations.\"}"
    },
    {
        "context": "Imitation Learning enables models to learn policies from expert demonstrations, useful when reward functions are hard to specify but expert trajectories are available.",
        "question": "What is distribution shift in imitation learning?",
        "student_answer": "Distribution shift occurs when the policy's distribution of visited states differs from expert data distribution. Small errors compound as the policy enters states unlike expert training data.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of compounding errors from distribution shift.\"}"
    },
    {
        "context": "Policy Gradient Methods optimize policies directly by estimating policy gradients through sampling, enabling end-to-end learning in RL.",
        "question": "What is the advantage of policy gradients over value-based methods?",
        "student_answer": "Policy gradients directly optimize the objective of interest and handle continuous action spaces naturally. Value-based methods require action space discretization or optimization.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of policy gradient advantages for continuous spaces.\"}"
    },
    {
        "context": "Actor-Critic Methods combine policy gradients with value functions, using value estimates to reduce variance in policy gradient estimates for more efficient learning.",
        "question": "How do actor-critic methods reduce variance compared to vanilla policy gradient?",
        "student_answer": "Actor-critic uses value estimates as baselines to center returns before computing gradients, reducing variance while maintaining unbiased gradient estimates through the baseline subtraction.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of baseline reduction variance and unbiasedness preservation.\"}"
    },
    {
        "context": "Proximal Policy Optimization (PPO) prevents policy updates from deviating too far from the old policy through clipped surrogate objectives, enabling stable and efficient training.",
        "question": "How does the clipped surrogate objective in PPO prevent large policy updates?",
        "student_answer": "PPO clips probability ratios to a fixed range, preventing oversized updates when policy diverges from data. This constrains trust region implicitly without explicit constraints.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of clipping mechanism and implicit trust region.\"}"
    },
    {
        "context": "Distributional RL learns value distributions instead of point estimates, capturing uncertainty and providing richer representations for decision making.",
        "question": "What advantage does distributional RL provide?",
        "student_answer": "Learning distributions enables better handling of uncertainty and multimodal value distributions. Policies can make risk-aware decisions using distributional information.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"risk-sensitive strategies\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation. Could emphasize risk-sensitive decision making advantages.\"}"
    },
    {
        "context": "Model-Based Reinforcement Learning learns environment models for planning, enabling sample efficiency through imagination and simulation.",
        "question": "What challenges does model-based RL face?",
        "student_answer": "Model errors compound during planning, causing erratic behavior from inaccurate predictions. Long-horizon planning requires accurate models, which is difficult to learn with limited data.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of error compounding and long-horizon challenges.\"}"
    },
    {
        "context": "Model-Agnostic Meta-Learning (MAML) learns initial parameters enabling rapid adaptation to new tasks through few gradient steps, enabling true few-shot learning.",
        "question": "Why does MAML initialization enable fast task adaptation?",
        "student_answer": "MAML optimizes for initialization that lies in loss landscape regions where few gradient steps toward any task find good solutions. This creates a well-positioned starting point.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of loss landscape positioning for rapid task adaptation.\"}"
    },
    {
        "context": "Prototypical Networks learn metric spaces where classification is done by comparing embeddings to prototype embeddings, enabling few-shot learning through distance-based decisions.",
        "question": "How do prototypical networks generalize to new classes without retraining?",
        "student_answer": "Prototypical networks create class prototypes from support sets and classify query samples based on proximity in learned metric space, enabling zero-parameters classification to new classes.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of distance-based generalization without parameter updates.\"}"
    },
    {
        "context": "Graph Isomorphism Networks extend GNNs with powerful message passing that can distinguish non-isomorphic graphs, addressing expressiveness limitations of simpler GNNs.",
        "question": "What expressiveness limitation do GINs address?",
        "student_answer": "Basic GNNs use mean aggregation which loses information about neighborhood structure. GINs use injective aggregation functions that preserve neighborhood patterns, enabling distinction of non-isomorphic graphs.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of injective aggregation and expressiveness improvement.\"}"
    },
    {
        "context": "Curriculum Learning trains models by presenting data in a meaningful order, starting with simpler examples and gradually increasing difficulty.",
        "question": "Why does curriculum learning help stabilize and accelerate training?",
        "student_answer": "It lets the model learn easy patterns first, building strong foundations before handling complex samples, leading to more stable gradients and faster convergence.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of progressive difficulty and its effect on gradient stability and convergence.\"}"
    },
    {
        "context": "Knowledge Distillation transfers information from a large teacher model to a smaller student model using soft labels and guidance.",
        "question": "How do soft labels improve knowledge transfer in distillation?",
        "student_answer": "Soft labels reveal teacher confidence levels across classes, giving richer learning signals than hard labels and helping the student generalize better.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Great explanation of confidence distribution and generalization benefits.\"}"
    },
    {
        "context": "Self-Supervised Learning uses intrinsic data properties to create supervisory signals without manual labels, enabling large-scale representation learning.",
        "question": "Why is self-supervised learning effective on unlabeled data?",
        "student_answer": "It leverages structure within the data—like predicting masked parts or solving contrastive tasks—to learn useful representations without explicit labels.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Clear explanation of intrinsic supervision and representation benefits.\"}"
    },
    {
        "context": "Diffusion Models generate data by reversing a gradual noising process using learned denoising steps.",
        "question": "What is the role of the forward noising process in diffusion models?",
        "student_answer": "It slowly corrupts data with noise, creating training targets for the model to learn denoising steps that reverse this corruption during generation.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of corruption scheduling and denoising objective.\"}"
    },
    {
        "context": "Federated Learning enables collaborative model training across decentralized devices without sharing raw data.",
        "question": "Why is federated learning beneficial for privacy?",
        "student_answer": "Data stays on local devices and only gradients or model updates are shared, reducing exposure of sensitive information.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"secure aggregation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good answer. Could mention secure aggregation's role in preventing update leakage.\"}"
    },
    {
        "context": "Active Learning aims to reduce labeling cost by selecting the most informative samples for annotation.",
        "question": "How does uncertainty sampling improve sample efficiency?",
        "student_answer": "It queries labels for samples where the model is most uncertain, focusing human effort on examples that will most improve learning.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of uncertainty-driven query efficiency.\"}"
    },
    {
        "context": "Meta-Learning trains models that can quickly adapt to new tasks with minimal data, often using episodic training.",
        "question": "Why do meta-learned models adapt quickly to new tasks?",
        "student_answer": "They learn initialization states or update rules that are optimized for fast adaptation, requiring only a few gradient steps for new tasks.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Correct description of meta-initialization and rapid adaptation.\"}"
    },
    {
        "context": "Knowledge Graph Embeddings encode entities and relations into continuous vectors for reasoning and link prediction.",
        "question": "What is the purpose of relation-specific transformations in KG embeddings?",
        "student_answer": "They model how entities interact under different relations, helping the embeddings reflect relational structure instead of simple similarity.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Strong explanation of relational structure modeling.\"}"
    },
    {
        "context": "Temporal Convolutional Networks model sequence data using 1D convolutions with dilation to capture long-range dependencies.",
        "question": "How does dilation improve the receptive field of TCNs?",
        "student_answer": "Dilation spaces out convolutional filters, allowing each layer to cover a larger temporal range without increasing kernel size.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of expanded receptive fields through dilation.\"}"
    },
    {
        "context": "AutoML automates model selection, feature engineering, and hyperparameter tuning, reducing manual effort.",
        "question": "Why is Bayesian optimization effective for hyperparameter search?",
        "student_answer": "It models the objective function using a surrogate, guiding searches toward promising regions instead of random exploration.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of surrogate modeling and guided search.\"}"
    },
    {
        "context": "Attention Rollout visualizes transformer attention by aggregating attention weights across layers to understand which input tokens the model focuses on for predictions.",
        "question": "Why is layer-wise attention aggregation necessary for interpretability?",
        "student_answer": "Single layer attention shows only local dependencies. Aggregating across layers reveals the full attention pathway from input to output, providing comprehensive interpretability of model reasoning.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of hierarchical attention aggregation and complete reasoning pathway.\"}"
    },
    {
        "context": "Batch Effects in machine learning refer to systematic variations in data caused by experimental conditions or processing batches that confound biological or true signals.",
        "question": "How can batch effects be corrected in machine learning pipelines?",
        "student_answer": "ComBat and similar methods estimate batch effects as additive and multiplicative components, removing them before analysis. Combat normalization preserves true biological signal while removing batch variation.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"cross-batch contamination\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of batch correction. Could mention handling cross-batch contamination issues.\"}"
    },
    {
        "context": "Imbalanced Metric Learning addresses few-shot scenarios where some classes have very few samples, affecting embedding and distance-metric learning.",
        "question": "Why are standard metric learning approaches problematic for imbalanced classes?",
        "student_answer": "Standard approaches weight all samples equally, causing majority classes to dominate embedding space. Minority class embeddings cluster poorly with few examples, degrading minority class discrimination.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of majority class dominance and minority class clustering problems.\"}"
    },
    {
        "context": "Stochastic Depth randomly drops entire residual branches during training, improving training efficiency and final model performance through regularization.",
        "question": "How does stochastic depth prevent overfitting in deep networks?",
        "student_answer": "Stochastic depth randomly skips residual connections during training, effectively creating an implicit ensemble of different network depths. This forces robust feature learning at all depths.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of ensemble effect and robust depth-wise learning.\"}"
    },
    {
        "context": "Focal Loss addresses class imbalance by down-weighting easy examples and focusing on hard negatives, improving detection of rare classes.",
        "question": "How does focal loss differ from standard cross-entropy for imbalanced data?",
        "student_answer": "Focal loss adds a modulating factor that reduces loss for well-classified examples. This focuses training on hard examples, preventing easy negatives from dominating gradient estimates in imbalanced settings.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of hard example focusing and easy negative down-weighting.\"}"
    },
    {
        "context": "Spectral Clustering uses graph Laplacian eigenvectors to partition data, effective for non-convex clusters that Euclidean-based methods miss.",
        "question": "Why can spectral clustering find non-convex cluster shapes?",
        "student_answer": "Spectral clustering works in eigenvector space derived from data graph structure. This transformed space makes non-convex manifolds separable linearly, enabling K-means to find appropriate clusters.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of graph-based transformation enabling linear separability.\"}"
    },
    {
        "context": "Learning Rate Scheduling adapts learning rate during training according to predefined schedules to balance convergence speed and final model quality.",
        "question": "What is the benefit of cosine annealing compared to fixed learning rate?",
        "student_answer": "Cosine annealing smoothly decreases learning rate following a cosine curve, enabling large steps initially for rapid convergence and small steps later for fine-tuning optimal parameters.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of coarse-to-fine progression through cosine annealing.\"}"
    },
    {
        "context": "Subword Tokenization using algorithms like Byte-Pair Encoding and WordPiece balance vocabulary size and coverage, enabling efficient representation of rare words.",
        "question": "How does byte-pair encoding iteratively build vocabulary?",
        "student_answer": "BPE starts with character vocabulary and iteratively merges most frequent adjacent pairs, building vocabulary incrementally. Rare words decompose into frequent subword units automatically.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of iterative pair merging and rare word handling.\"}"
    },
    {
        "context": "Lottery Ticket Hypothesis suggests neural networks contain sparse subnetworks that achieve comparable performance to full networks when trained from specific initializations.",
        "question": "What does the lottery ticket hypothesis imply about network pruning?",
        "student_answer": "The hypothesis suggests networks contain winning ticket subnetworks that train efficiently. This justifies aggressive pruning and implies training inefficiency comes from unnecessary connections.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of pruning implications and network efficiency insights.\"}"
    },
    {
        "context": "Manifold Learning discovers low-dimensional structure in high-dimensional data through techniques like t-SNE and UMAP, revealing underlying data geometry.",
        "question": "How does t-SNE preserve both local and global structure?",
        "student_answer": "t-SNE uses Gaussian kernels for local neighborhoods and Student-t kernels for global distances, preserving local cluster structure while preventing distant cluster collapse through different kernel scales.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [\"repulsive forces\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of dual-scale approach. Could mention long-range repulsive forces more explicitly.\"}"
    },
    {
        "context": "Curriculum Learning for NLP starts with simple tokens or short sequences, gradually increasing difficulty to improve convergence and final performance.",
        "question": "Why does curriculum learning improve NLP model training?",
        "student_answer": "Starting with easy examples like simple tokens provides strong initial signals for weight initialization. Complex examples later benefit from pre-learned representations, improving optimization landscape.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of curriculum benefits through initialization and representation learning.\"}"
    },
    {
        "context": "Federated Averaging aggregates model updates from multiple clients to train global models while keeping data decentralized, the core algorithm of federated learning.",
        "question": "What privacy guarantee does federated averaging provide?",
        "student_answer": "Federated averaging prevents direct data access at the server by sharing only model updates. With differential privacy, noise can be added to updates for stronger privacy guarantees.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"membership inference attacks\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of gradient-level privacy. Could mention membership inference attack mitigations.\"}"
    },
    {
        "context": "Multi-Scale Feature Processing combines features at different spatial resolutions to capture both fine details and coarse context.",
        "question": "How do feature pyramids improve object detection?",
        "student_answer": "Feature pyramids create multi-scale representations where small objects appear at high-resolution levels and large objects at low-resolution levels, enabling detection across object scales.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of scale-appropriate feature detection through pyramid structure.\"}"
    },
    {
        "context": "Synthetic Data Generation creates artificial training data through generative models when real data is scarce, private, or expensive to obtain.",
        "question": "What are the limitations of purely synthetic data for training models?",
        "student_answer": "Synthetic data may not capture all real-world variations and corner cases. Distribution mismatch between synthetic and real data can cause domain gap, reducing generalization to production environments.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent identification of distribution mismatch and real-world variation limitations.\"}"
    },
    {
        "context": "Orthogonal Regularization constrains weight matrices to have orthogonal columns or rows, improving stability and convergence properties in neural networks.",
        "question": "How does orthogonality help preserve gradient magnitudes in deep networks?",
        "student_answer": "Orthogonal transformations preserve vector norms, preventing gradients from vanishing or exploding when multiplied by orthogonal weight matrices. This stabilizes backpropagation through many layers.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of norm preservation and gradient stability through orthogonality.\"}"
    },
    {
        "context": "Optimal Transport provides a framework for comparing distributions and learning mappings between them, useful for domain adaptation and generative modeling.",
        "question": "What advantage does optimal transport have over Wasserstein distance?",
        "student_answer": "The Wasserstein distance from optimal transport theory provides geometric interpretation of distribution differences. It's differentiable and enables gradient-based optimization unlike some divergence measures.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 2, \"missing_concepts\": [\"computational complexity\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of Wasserstein differentiability. Could mention computational complexity considerations.\"}"
    },
    {
        "context": "Compositional Generalization enables models to understand new combinations of known concepts, beyond simple interpolation of training data.",
        "question": "Why do neural networks struggle with compositional generalization?",
        "student_answer": "Neural networks often learn surface-level correlations rather than compositional structure. Without explicit compositional inductive biases, they fail on novel combinations even of familiar concepts.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of surface correlation learning and missing compositional structure.\"}"
    },
    {
        "context": "Symmetry in Neural Networks exploits data symmetries through equivariant architectures that naturally respect problem structure, improving efficiency and generalization.",
        "question": "What is the benefit of equivariant neural networks?",
        "student_answer": "Equivariant networks transform outputs consistently with input transformations, capturing symmetries in the problem. This reduces sample complexity and improves generalization to transformed inputs.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of symmetry exploitation and sample efficiency improvements.\"}"
    },
    {
        "context": "Temperature in Softmax Controls output probability distribution sharpness, affecting model confidence and exploration-exploitation balance in sampling.",
        "question": "Why does temperature tuning matter for language model decoding?",
        "student_answer": "Low temperature produces sharp distributions favoring high-probability tokens, while high temperature smooths probabilities encouraging diversity. Temperature tunes model confidence and output variety.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of temperature effects on probability distributions and output characteristics.\"}"
    },
    {
        "context": "Cross-Domain Generalization requires models to perform well across multiple domains despite distribution shifts, a critical challenge for real-world deployment.",
        "question": "What is domain randomization and how does it improve generalization?",
        "student_answer": "Domain randomization trains on diverse synthetic domains with varied visual properties to create environment-agnostic policies. This improves robustness to real-world domain shifts.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of diversity-induced robustness through domain randomization.\"}"
    },
    {
        "context": "Anchor-Free Object Detection predicts object locations directly without predefined anchor boxes, simplifying architecture and improving efficiency.",
        "question": "What advantage does anchor-free detection have over anchor-based methods?",
        "student_answer": "Anchor-free methods eliminate manual anchor design, reducing hyperparameter tuning. They predict object centers and sizes directly, simplifying architecture while often achieving better performance.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of hyperparameter reduction and architectural simplification benefits.\"}"
    },
    {
        "context": "Group Normalization normalizes by channel groups instead of batch statistics, maintaining performance with small batch sizes where batch normalization fails.",
        "question": "Why does group normalization work with small batches while batch normalization struggles?",
        "student_answer": "Batch normalization relies on large batch statistics which become unreliable with few samples. Group normalization uses channel group statistics independent of batch size, remaining stable for small batches.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of batch size independence through group statistics.\"}"
    },
    {
        "context": "Structured Outputs in neural networks handle prediction of complex objects like sequences, trees, or graphs rather than simple class labels.",
        "question": "How do sequence labeling models handle variable-length outputs?",
        "student_answer": "Sequence models like BiLSTMs process sequences through RNN cells that maintain state, predicting labels for each position. CRF layers enforce label sequence validity constraints.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of position-wise prediction and sequence constraint modeling.\"}"
    },
    {
        "context": "Mixup regularization interpolates between training examples and their labels to improve generalization and model robustness.",
        "question": "Why does mixing labels along with features improve generalization in mixup?",
        "student_answer": "Label interpolation creates soft targets that reduce overfitting to hard labels. Combined with feature interpolation, this encourages models to learn smooth decision boundaries.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of soft target regularization and smooth boundary learning.\"}"
    },
    {
        "context": "Gumbel-Softmax enables differentiable sampling from categorical distributions through temperature annealing, crucial for discrete variables in neural networks.",
        "question": "How does Gumbel-Softmax enable backpropagation through discrete sampling?",
        "student_answer": "Gumbel-softmax transforms discrete sampling into continuous approximation using temperature. Low temperatures recover discrete behavior while gradients flow during training.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of continuous relaxation and gradient flow recovery.\"}"
    },
    {
        "context": "Instance Normalization normalizes feature maps individually per sample rather than across batch, crucial for style transfer where batch statistics hurt style representation.",
        "question": "Why is instance normalization better than batch normalization for style transfer?",
        "student_answer": "Batch normalization removes style information encoded in feature magnitude statistics. Instance normalization preserves style-specific statistics while normalizing content, enabling proper style transfer.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of style-content separation through instance normalization.\"}"
    },
    {
        "context": "Causal Masking in autoregressive models prevents future positions from attending to current or past, enabling generation and autoregressive sampling.",
        "question": "Why is causal masking necessary for language generation?",
        "student_answer": "Causal masking ensures each position only attends to past positions, preventing data leakage during generation. This enables autoregressive decoding where tokens are generated sequentially.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of data leakage prevention and autoregressive sampling requirement.\"}"
    },
    {
        "context": "Subgroup Analysis evaluates model performance across different demographic subgroups to identify disparate impacts and fairness violations.",
        "question": "Why is subgroup analysis important beyond overall accuracy metrics?",
        "student_answer": "Overall accuracy can hide disparate performance across groups. Subgroup analysis reveals if the model systematically underperforms minorities or sensitive subpopulations, exposing hidden biases.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of aggregate metric limitations and subgroup-specific bias detection.\"}"
    },
    {
        "context": "Scene Graphs represent images as structured scenes with objects and relationships, enabling reasoning about visual content beyond pixel-level analysis.",
        "question": "How do scene graphs improve visual understanding in neural networks?",
        "student_answer": "Scene graphs explicitly model objects and their relationships, providing structured semantic information. This enables reasoning about spatial relationships and interactions beyond direct visual features.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of structured scene reasoning and relationship modeling.\"}"
    },
    {
        "context": "Neural ODE models treat residual blocks as continuous transformations, providing memory efficiency and exact gradient computation through adjoint methods.",
        "question": "What is the advantage of Neural ODEs over discrete residual networks?",
        "student_answer": "Neural ODEs compute continuous transformations with memory-efficient gradient computation. They handle variable-length sequences better and provide more expressive function approximation.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of continuous transformation benefits and memory efficiency.\"}"
    },
    {
        "context": "Batch Normalization normalizes layer inputs to have zero mean and unit variance, stabilizing and accelerating training in deep networks.",
        "question": "How does Batch Normalization improve training?",
        "student_answer": "Batch Normalization just makes all numbers the same size so they're easier to process. It doesn't really matter how it works, just that it makes training go faster.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 1, \"missing_concepts\": [\"zero mean and unit variance\", \"internal covariate shift\", \"gradient flow\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Overly simplistic and informal. Lacks technical detail about mean/variance normalization and fails to explain the stabilization mechanism.\"}"
    },
    {
        "context": "Convolutional Neural Networks (CNNs) use convolutional layers with learnable filters to extract spatial features from input data, particularly effective for image processing.",
        "question": "How do convolutional filters work in CNNs?",
        "student_answer": "Filters are just random numbers that scan pictures and make them smaller. The network learns what the best random numbers are to use.",
        "target_json": "{\"score_30\": 12, \"key_coverage\": 1, \"missing_concepts\": [\"learnable kernels\", \"local feature detection\", \"spatial hierarchy\", \"weight sharing\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Extremely vague and informal. Completely misses that filters are learnable and detect meaningful patterns, not just random numbers.\"}"
    },
    {
        "context": "Dropout is a regularization technique that randomly deactivates neurons during training, preventing overfitting by reducing co-adaptation.",
        "question": "What does Dropout do?",
        "student_answer": "Dropout removes some neurons so the network doesn't memorize everything. It's kinda like making the network smaller to prevent cheating.",
        "target_json": "{\"score_30\": 16, \"key_coverage\": 1, \"missing_concepts\": [\"stochastic deactivation\", \"ensemble interpretation\", \"co-adaptation prevention\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Informal language and imprecise explanation. The network doesn't actually get smaller; neurons are temporarily deactivated, creating ensemble effects.\"}"
    },
    {
        "context": "Backpropagation is the algorithm that computes gradients of the loss function with respect to weights through the chain rule.",
        "question": "Explain how backpropagation works.",
        "student_answer": "Backpropagation is when you go backwards through the network and make the weights better. It's complicated math but basically it finds the right direction to change weights.",
        "target_json": "{\"score_30\": 14, \"key_coverage\": 1, \"missing_concepts\": [\"chain rule\", \"gradient computation\", \"dynamic programming\", \"efficient reuse\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Extremely vague and informal. Fails to explain the chain rule mechanism or why backpropagation is efficient.\"}"
    },
    {
        "context": "L1 and L2 regularization are techniques that add penalty terms to the loss function to discourage large weights.",
        "question": "What is the difference between L1 and L2 regularization?",
        "student_answer": "L1 makes weights smaller and L2 also makes weights smaller, but they're basically the same thing just slightly different.",
        "target_json": "{\"score_30\": 6, \"key_coverage\": 0, \"missing_concepts\": [\"sparsity\", \"absolute vs squared\", \"feature selection\", \"weight distribution\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. L1 promotes sparsity by driving weights to zero, while L2 distributes penalties evenly. They have fundamentally different effects.\"}"
    },
    {
        "context": "Reinforcement Learning involves an agent learning to make decisions by interacting with an environment, receiving rewards or penalties based on actions.",
        "question": "What is the goal of a reinforcement learning agent?",
        "student_answer": "The goal is to get as much reward as possible really quickly, like winning immediately without thinking about the future.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 1, \"missing_concepts\": [\"cumulative reward\", \"temporal discounting\", \"long-term strategy\", \"exploration-exploitation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely misses that RL maximizes cumulative reward over time, not immediate reward. Ignores long-term strategy and temporal aspects.\"}"
    },
    {
        "context": "Precision and Recall are evaluation metrics where Precision is true positives divided by all positive predictions, and Recall is true positives divided by all actual positives.",
        "question": "What is the relationship between Precision and Recall?",
        "student_answer": "Precision and Recall are the exact same thing, they just measure how accurate the model is. There's no real difference between them.",
        "target_json": "{\"score_30\": 5, \"key_coverage\": 0, \"missing_concepts\": [\"different denominators\", \"inverse relationship\", \"threshold tradeoff\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Precision and Recall have different denominators and move inversely as thresholds change. They measure different classification aspects.\"}"
    },
    {
        "context": "Overfitting occurs when a model learns the training data too well, including noise and outliers, leading to poor generalization.",
        "question": "What causes overfitting?",
        "student_answer": "Overfitting happens because neural networks are too dumb and can't understand real patterns, so they just memorize everything randomly.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 1, \"missing_concepts\": [\"model capacity\", \"training data size\", \"regularization\", \"complexity\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Extremely insulting and incorrect. Neural networks overfit due to high capacity relative to data, not due to being dumb. Misses key causes.\"}"
    },
    {
        "context": "Attention Mechanisms allow models to focus on relevant parts of input by computing weighted combinations of all elements.",
        "question": "How do attention mechanisms work?",
        "student_answer": "Attention just randomly picks some parts of the input to look at and ignores the rest. It's like the model is distracted sometimes.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"weighted combinations\", \"query-key-value\", \"softmax weighting\", \"learned focus\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Completely wrong and informal. Attention computes learned weighted combinations, not random selection. Misses mathematical mechanism entirely.\"}"
    },
    {
        "context": "Transfer Learning involves taking a pre-trained model and fine-tuning it on a new task to leverage learned features.",
        "question": "Why is transfer learning useful?",
        "student_answer": "Transfer learning is useful because you don't have to train from scratch, so it's faster I guess. But honestly the results are probably worse because the model wasn't trained on your data.",
        "target_json": "{\"score_30\": 11, \"key_coverage\": 1, \"missing_concepts\": [\"feature reuse\", \"generalization\", \"limited data benefit\", \"domain adaptation\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Completely wrong conclusion. Transfer learning usually improves results by leveraging learned features and reducing required data, not worsening them.\"}"
    },
    {
        "context": "Gradient Descent is an optimization algorithm that iteratively updates parameters by moving in the direction of the negative gradient.",
        "question": "What does the learning rate control in gradient descent?",
        "student_answer": "The learning rate is just some random number you pick. It doesn't really matter what you choose as long as you're going downhill.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 1, \"missing_concepts\": [\"step size\", \"convergence speed\", \"stability\", \"divergence risk\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Learning rate critically controls step size and affects convergence speed and stability. Wrong choices cause divergence.\"}"
    },
    {
        "context": "Recurrent Neural Networks (RNNs) process sequences by maintaining hidden states updated at each time step.",
        "question": "What problem do LSTMs solve in RNNs?",
        "student_answer": "LSTMs make RNNs remember stuff better by having a really big hidden state. That's basically it, nothing fancy.",
        "target_json": "{\"score_30\": 12, \"key_coverage\": 1, \"missing_concepts\": [\"vanishing gradient\", \"gating mechanisms\", \"memory cells\", \"long-range dependencies\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Oversimplified and incomplete. LSTMs solve vanishing gradients through gating mechanisms and memory cells, not just larger hidden states.\"}"
    },
    {
        "context": "Feature Engineering involves creating new features or transforming existing ones to improve model performance.",
        "question": "Why is feature engineering important?",
        "student_answer": "Feature engineering is just busywork. Modern deep learning models don't need it because neural networks can figure out any features automatically.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 1, \"missing_concepts\": [\"domain knowledge\", \"model performance\", \"interpretability\", \"efficiency\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Good features dramatically improve model performance, efficiency, and interpretability even for deep learning models.\"}"
    },
    {
        "context": "K-Means clustering groups data into K clusters by minimizing within-cluster variance through iterative centroid updates.",
        "question": "What is a limitation of K-Means?",
        "student_answer": "K-Means has no limitations really. It always finds the best clusters because it's an optimal algorithm.",
        "target_json": "{\"score_30\": 6, \"key_coverage\": 0, \"missing_concepts\": [\"local minima\", \"K specification\", \"spherical assumptions\", \"initialization sensitivity\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely false. K-Means gets stuck in local minima, requires K specification, assumes spherical clusters, and is sensitive to initialization.\"}"
    },
    {
        "context": "Cross-Validation is a model evaluation technique that splits data into K folds for multiple train-test iterations.",
        "question": "Why use K-Fold Cross-Validation?",
        "student_answer": "It doesn't really matter if you do cross-validation or not. Just pick a random train-test split and you'll get the same results anyway.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"variance reduction\", \"data efficiency\", \"robust estimation\", \"stability\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. K-Fold provides stable performance estimates with lower variance than single splits by using all data effectively.\"}"
    },
    {
        "context": "Dimensionality Reduction projects high-dimensional data onto lower-dimensional subspaces while preserving information.",
        "question": "What does PCA do?",
        "student_answer": "PCA just removes columns from the dataset to make it smaller. You can delete any columns and get the same results.",
        "target_json": "{\"score_30\": 5, \"key_coverage\": 0, \"missing_concepts\": [\"principal components\", \"variance preservation\", \"orthogonal projection\", \"dimensionality\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. PCA doesn't remove columns; it creates new orthogonal axes capturing maximum variance through linear combinations.\"}"
    },
    {
        "context": "Activation Functions introduce non-linearity into neural networks enabling learning of complex patterns.",
        "question": "Why are activation functions necessary?",
        "student_answer": "Activation functions are optional really. You could just stack linear layers and get the same expressive power.",
        "target_json": "{\"score_30\": 6, \"key_coverage\": 0, \"missing_concepts\": [\"non-linearity\", \"composition of linear functions\", \"universal approximation\", \"function expressiveness\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Without activations, stacking linear layers remains linear. Non-linearity is essential for function expressiveness and approximation.\"}"
    },
    {
        "context": "Unsupervised Learning learns patterns from unlabeled data without predefined target variables.",
        "question": "Why is unsupervised learning difficult?",
        "student_answer": "Unsupervised learning is impossible to use in real applications because you can never know if the results are correct without labels.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 1, \"missing_concepts\": [\"evaluation metrics\", \"practical applications\", \"clustering quality\", \"validation approaches\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Unsupervised learning is widely used in production for clustering, anomaly detection, and dimensionality reduction with appropriate evaluations.\"}"
    },
    {
        "context": "Support Vector Machines find optimal hyperplanes separating classes by maximizing margins.",
        "question": "How do SVMs handle non-linearly separable data?",
        "student_answer": "SVMs can't handle non-linear data at all. If the data isn't linearly separable, SVM just fails and you have to use a different model.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 0, \"missing_concepts\": [\"kernel trick\", \"feature mapping\", \"implicit transformation\", \"non-linear boundaries\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. SVMs use the kernel trick to implicitly map data to higher dimensions enabling non-linear separation without explicit transformation.\"}"
    },
    {
        "context": "Regularization prevents overfitting by constraining model complexity through penalties or constraints.",
        "question": "Why is regularization important?",
        "student_answer": "Regularization doesn't really help. If your model overfits, you should just use less data and that solves everything.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 1, \"missing_concepts\": [\"complexity control\", \"generalization\", \"bias-variance tradeoff\", \"training efficiency\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Regularization improves generalization by controlling complexity. Less data worsens the problem; regularization helps existing data work better.\"}"
    },
    {
        "context": "Ensemble Methods combine multiple models to improve predictions through voting or averaging.",
        "question": "Why do ensemble methods work better than single models?",
        "student_answer": "Ensemble methods just average predictions together. Since averaging reduces numbers, it somehow makes predictions better.",
        "target_json": "{\"score_30\": 11, \"key_coverage\": 1, \"missing_concepts\": [\"diversity\", \"independent errors\", \"complementary strengths\", \"robustness\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Oversimplified. Ensembles work because diverse models make different mistakes. Averaging only helps when errors are independent and mistakes differ.\"}"
    },
    {
        "context": "Bias-Variance Tradeoff describes the tension between model bias and variance in affecting generalization error.",
        "question": "What is bias-variance tradeoff?",
        "student_answer": "Bias and variance are just statistics terms that don't really matter for machine learning. You should just focus on minimizing training error.",
        "target_json": "{\"score_30\": 5, \"key_coverage\": 0, \"missing_concepts\": [\"error decomposition\", \"underfitting vs overfitting\", \"model complexity\", \"generalization\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Bias-variance tradeoff is fundamental to understanding generalization. Minimizing training error alone causes overfitting and poor test performance.\"}"
    },
    {
        "context": "Hyperparameter Tuning selects optimal values for learning rate, regularization, and other non-learned parameters.",
        "question": "How should hyperparameters be tuned?",
        "student_answer": "Just pick random hyperparameters. Neural networks are robust to hyperparameters so any choice works about the same.",
        "target_json": "{\"score_30\": 6, \"key_coverage\": 0, \"missing_concepts\": [\"parameter sensitivity\", \"grid search\", \"Bayesian optimization\", \"validation strategies\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Hyperparameters dramatically affect performance. Systematic tuning through grid search or Bayesian methods is essential for good results.\"}"
    },
    {
        "context": "Normalization scales input features to have similar ranges, important for distance-based algorithms and optimization.",
        "question": "Why is feature normalization important?",
        "student_answer": "Normalization is just for cosmetic purposes. It doesn't actually affect model performance, just makes numbers look nicer.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"gradient convergence\", \"algorithm sensitivity\", \"distance computation\", \"training stability\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Normalization critically affects convergence, distance computations, and gradient behavior. Poor normalization causes training instability.\"}"
    },
    {
        "context": "Data Augmentation artificially increases training data diversity through transformations without requiring new labeled samples.",
        "question": "What is the purpose of data augmentation?",
        "student_answer": "Data augmentation is pointless because rotated or cropped images are obviously not real data. It just confuses the model.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 1, \"missing_concepts\": [\"generalization\", \"robustness\", \"data efficiency\", \"invariance learning\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Augmentation teaches models invariances to transformations, improving generalization and robustness to variations in real data.\"}"
    },
    {
        "context": "Model Selection chooses between different model architectures and algorithms for a given task.",
        "question": "How should you select which model to use?",
        "student_answer": "Just use whatever model has the fanciest name or the biggest hype. The most complicated model is always the best one.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"task requirements\", \"computational constraints\", \"interpretability\", \"empirical validation\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Completely wrong. Model selection should consider task requirements, computational constraints, interpretability needs, and empirical performance on validation data.\"}"
    },
    {
        "context": "Imbalanced Learning addresses class imbalance where some classes significantly outnumber others.",
        "question": "How should you handle imbalanced classification?",
        "student_answer": "Just ignore the problem and train normally. Imbalance doesn't matter because the model will figure it out automatically.",
        "target_json": "{\"score_30\": 6, \"key_coverage\": 0, \"missing_concepts\": [\"resampling\", \"class weights\", \"evaluation metrics\", \"algorithms for imbalance\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Imbalance causes bias toward majority class. Solutions include resampling, class weights, and metric selection beyond accuracy.\"}"
    },
    {
        "context": "Interpretability in Machine Learning makes model decisions understandable to humans for trust and debugging.",
        "question": "Why is interpretability important?",
        "student_answer": "Interpretability doesn't matter at all. As long as the model makes good predictions, nobody cares how it works.",
        "target_json": "{\"score_30\": 5, \"key_coverage\": 0, \"missing_concepts\": [\"trust\", \"debugging\", \"regulatory compliance\", \"bias detection\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Interpretability is crucial for trust, debugging errors, regulatory compliance, and detecting biases that high accuracy masks.\"}"
    },
    {
        "context": "Model Validation uses held-out test data to estimate generalization performance on unseen data.",
        "question": "Why is a separate test set necessary?",
        "student_answer": "You don't need a separate test set. Training and test errors are the same so you can just use training accuracy as your final metric.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"generalization\", \"overfitting detection\", \"data leakage\", \"unbiased estimation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Training error drastically underestimates test error due to overfitting. Separate test sets provide unbiased generalization estimates.\"}"
    },
    {
        "context": "Loss Functions measure the difference between predicted and actual values, guiding model optimization.",
        "question": "How does loss function choice affect training?",
        "student_answer": "Loss function doesn't really matter. You could use any loss function and the model learns the same thing.",
        "target_json": "{\"score_30\": 6, \"key_coverage\": 0, \"missing_concepts\": [\"task alignment\", \"gradient flow\", \"optimization dynamics\", \"penalty structure\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Loss function choice dramatically affects optimization dynamics and final model behavior. Different losses suit different tasks.\"}"
    },
    {
        "context": "Neural Network Architecture design determines the structure of layers, connections, and parameters.",
        "question": "Does architecture choice really matter for neural networks?",
        "student_answer": "Architecture doesn't matter. You could stack random layers in any order and get basically the same results every time.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"inductive bias\", \"expressiveness\", \"task-structure alignment\", \"efficiency\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Architecture design encodes inductive biases for tasks. CNN structures exploit spatial structure; transformers exploit sequences; architecture matters greatly.\"}"
    },
    {
        "context": "Optimization in Deep Learning finds parameters that minimize loss through gradient-based algorithms.",
        "question": "What makes some optimizers better than others?",
        "student_answer": "All optimizers are basically the same. They all minimize the loss so it doesn't matter which optimizer you pick.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 1, \"missing_concepts\": [\"convergence speed\", \"local minima\", \"momentum\", \"adaptive learning rates\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Optimizers differ dramatically in convergence speed, stability, and final performance. Adam, SGD, and others have different properties.\"}"
    },
    {
        "context": "Training Dynamics describe how loss and metrics evolve during training, revealing optimization health.",
        "question": "What can training curves tell you about a model?",
        "student_answer": "Training curves are just pretty pictures. They don't actually tell you anything useful about whether your model is working.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"convergence diagnosis\", \"overfitting detection\", \"learning rate validation\", \"stability assessment\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Completely wrong. Training curves reveal overfitting, convergence issues, learning rate problems, and training stability. They're essential for diagnostics.\"}"
    },
    {
        "context": "Probabilistic Models represent uncertainty through probability distributions enabling principled reasoning about uncertainty.",
        "question": "Why use probabilistic models instead of deterministic ones?",
        "student_answer": "Probabilistic models are more complicated and slower. Deterministic models always give better predictions so probabilistic models are pointless.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"uncertainty quantification\", \"principled inference\", \"Bayesian reasoning\", \"calibration\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Probabilistic models quantify uncertainty, enable principled inference, and provide calibrated confidence estimates crucial for many applications.\"}"
    },
    {
        "context": "Deep Learning involves training neural networks with multiple hidden layers to learn hierarchical representations.",
        "question": "Why do deeper networks learn better representations?",
        "student_answer": "Deeper networks just have more layers so they're automatically better. More depth always means better performance no matter what.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 1, \"missing_concepts\": [\"hierarchical features\", \"representation learning\", \"optimization challenges\", \"depth-performance relationship\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Oversimplified. Deeper networks learn hierarchies but also get harder to train. There's a depth sweet spot; very deep networks can underperform without proper techniques.\"}"
    },
    {
        "context": "Batch Normalization normalizes layer inputs to have zero mean and unit variance, stabilizing and accelerating training in deep networks.",
        "question": "How does Batch Normalization improve training stability?",
        "student_answer": "Batch Normalization standardizes inputs to each layer, which helps prevent internal covariate shift. This makes gradient flow more stable through the network.",
        "target_json": "{\"score_30\": 22, \"key_coverage\": 2, \"missing_concepts\": [\"learning rate adaptation\", \"variance reduction specifics\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of covariate shift prevention and gradient stability. Could elaborate on how normalization reduces activation magnitudes and variance.\"}"
    },
    {
        "context": "Convolutional Neural Networks (CNNs) use convolutional layers with learnable filters to extract spatial features from input data.",
        "question": "How do CNNs reduce parameters compared to fully connected networks?",
        "student_answer": "CNNs use weight sharing where the same filter applies across the entire image. This significantly reduces parameters compared to fully connected networks that need unique weights for every connection.",
        "target_json": "{\"score_30\": 24, \"key_coverage\": 2, \"missing_concepts\": [\"local connectivity\", \"parameter efficiency calculation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of weight sharing benefit. Could mention local connectivity and quantitative parameter reduction comparison.\"}"
    },
    {
        "context": "Dropout randomly deactivates neurons during training with probability p, forcing the network to learn robust representations.",
        "question": "How does Dropout prevent overfitting?",
        "student_answer": "Dropout randomly disables neurons during training, creating an implicit ensemble of different network configurations. This prevents any single neuron from overfitting to the training data.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 3, \"missing_concepts\": [\"co-adaptation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Solid explanation of ensemble effect and neuron independence. Could mention preventing co-adaptation of neuron pairs more explicitly.\"}"
    },
    {
        "context": "Backpropagation computes gradients through the chain rule by efficiently reusing intermediate computations.",
        "question": "Why is backpropagation efficient compared to numerical gradient approximation?",
        "student_answer": "Backpropagation uses the chain rule to compute gradients in one backward pass, while numerical approximation requires multiple forward passes. This makes backpropagation much faster.",
        "target_json": "{\"score_30\": 23, \"key_coverage\": 2, \"missing_concepts\": [\"O(n) vs O(n²) complexity\", \"dynamic programming aspect\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good identification of multiple forward passes issue. Could specify complexity improvements and dynamic programming reuse more clearly.\"}"
    },
    {
        "context": "L1 and L2 regularization add penalty terms to the loss function. L1 adds absolute values of weights, L2 adds squared weights.",
        "question": "What different effects do L1 and L2 regularization have?",
        "student_answer": "L1 regularization tends to push some weights to exactly zero, creating sparse models. L2 regularization distributes penalties more evenly across weights, keeping them small but rarely at zero.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [\"geometric interpretation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of sparsity and even distribution effects. Could mention geometric interpretation with L1 ball vs L2 sphere.\"}"
    },
    {
        "context": "Reinforcement Learning agents maximize cumulative rewards by learning optimal policies through trial and error interaction with environments.",
        "question": "What is the exploration-exploitation tradeoff in RL?",
        "student_answer": "Exploration means trying new actions to discover better strategies, while exploitation means using known good actions. Balancing these prevents both sticking to suboptimal policies and wasting time on poor actions.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 3, \"missing_concepts\": [\"epsilon-greedy formalization\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Strong conceptual explanation. Could provide concrete epsilon-greedy strategy or regret bounds examples.\"}"
    },
    {
        "context": "Precision is TP/(TP+FP) and Recall is TP/(TP+FN). They measure different aspects of classification performance.",
        "question": "When should you optimize for Recall over Precision?",
        "student_answer": "You should optimize Recall when false negatives are more costly than false positives. For instance, in disease detection, missing sick patients is worse than incorrectly flagging healthy ones.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [\"cost-benefit analysis\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Great example and clear cost reasoning. Could mention formal cost-based threshold selection.\"}"
    },
    {
        "context": "Overfitting occurs when models learn training-specific noise rather than generalizable patterns, degrading test performance.",
        "question": "What are common signs of overfitting during training?",
        "student_answer": "Overfitting shows as training loss decreasing while validation loss increases or plateaus. The gap between training and validation metrics grows larger as the model memorizes training data.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 2, \"missing_concepts\": [\"metric divergence patterns\", \"monitoring strategies\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good description of diverging metrics. Could elaborate on specific monitoring strategies and pattern detection approaches.\"}"
    },
    {
        "context": "Attention Mechanisms compute weighted combinations where weights indicate importance of different input elements.",
        "question": "How do attention mechanisms improve sequence modeling?",
        "student_answer": "Attention allows each position to selectively focus on relevant positions in the sequence. This enables capturing long-range dependencies that recurrent architectures struggle with due to information bottlenecks.",
        "target_json": "{\"score_30\": 24, \"key_coverage\": 2, \"missing_concepts\": [\"quadratic complexity\", \"parallelization benefits\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of flexible dependency modeling. Could mention quadratic complexity and parallelization advantages over RNNs.\"}"
    },
    {
        "context": "Transfer Learning uses pre-trained models as initialization for new tasks, leveraging learned features to reduce data requirements.",
        "question": "When is transfer learning most beneficial?",
        "student_answer": "Transfer learning is most beneficial when the target task has limited training data or when source and target tasks are related. It enables good performance with less task-specific data.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"domain similarity metrics\", \"layer freezing strategies\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Solid answer. Could discuss domain similarity considerations and which layers to fine-tune for different scenarios.\"}"
    },
    {
        "context": "Gradient Descent minimizes loss by moving parameters in negative gradient direction with step size controlled by learning rate.",
        "question": "What problems occur with inappropriate learning rate values?",
        "student_answer": "Too high learning rates cause loss to diverge or oscillate wildly. Too low learning rates make convergence extremely slow. Finding the right balance is critical for efficient training.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 2, \"missing_concepts\": [\"adaptive learning rates\", \"learning rate scheduling\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good description of extremes. Could mention adaptive methods and scheduling strategies that address these problems.\"}"
    },
    {
        "context": "Recurrent Neural Networks process sequences by maintaining hidden states that carry information across time steps.",
        "question": "Why do standard RNNs struggle with long sequences?",
        "student_answer": "Standard RNNs suffer from vanishing gradients when backpropagating through many time steps. Gradients shrink exponentially, making it hard to update early time step weights and learn long-range dependencies.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"LSTM/GRU solutions\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent problem identification. Could explain how LSTM gating mechanisms solve this specific issue.\"}"
    },
    {
        "context": "Feature Engineering creates meaningful features from raw data to improve model performance and interpretability.",
        "question": "Why does good feature engineering matter for model performance?",
        "student_answer": "Features capture domain knowledge and domain-relevant patterns that raw data doesn't represent well. Well-engineered features can make simple models outperform complex models trained on poor features.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [\"feature interaction effects\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of domain knowledge capture and simplicity-over-complexity benefit. Could mention interaction effects.\"}"
    },
    {
        "context": "K-Means clustering partitions data into K clusters by iteratively minimizing within-cluster variance.",
        "question": "What are the main limitations of K-Means?",
        "student_answer": "K-Means requires specifying K beforehand, gets stuck in local minima, assumes spherical clusters, and is sensitive to initialization. These limitations make it unsuitable for some problems.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 4, \"missing_concepts\": [\"computational complexity\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Comprehensive limitation coverage. Could mention computational complexity and scalability considerations.\"}"
    },
    {
        "context": "Cross-Validation splits data into K folds, training K times to estimate generalization performance robustly.",
        "question": "How does K-Fold Cross-Validation reduce evaluation bias?",
        "student_answer": "K-Fold uses all data for both training and evaluation across multiple splits. This reduces variance in performance estimates compared to a single random split.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 2, \"missing_concepts\": [\"statistical properties\", \"variance computation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of multiple iteration benefits. Could discuss variance reduction mathematics and statistical properties.\"}"
    },
    {
        "context": "Principal Component Analysis finds orthogonal directions of maximum variance in data, enabling dimensionality reduction.",
        "question": "What is a limitation of PCA?",
        "student_answer": "PCA assumes linear relationships and may not work well for non-linear manifolds. Additionally, it assumes variance corresponds to importance, which isn't always true.",
        "target_json": "{\"score_30\": 24, \"key_coverage\": 2, \"missing_concepts\": [\"interpretability issues\", \"kernel PCA alternatives\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good identification of linearity and variance assumptions. Could mention interpretability issues and non-linear alternatives like kernel PCA.\"}"
    },
    {
        "context": "Activation Functions introduce non-linearity enabling neural networks to approximate complex functions.",
        "question": "Why are activation functions necessary in neural networks?",
        "student_answer": "Without activation functions, stacking linear layers produces another linear function. Activations enable non-linear transformations that let networks approximate complex non-linear relationships.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [\"universal approximation theorem\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of linearity composition. Could mention universal approximation guarantees with activation functions.\"}"
    },
    {
        "context": "Unsupervised Learning discovers patterns in unlabeled data through clustering, dimensionality reduction, and density estimation.",
        "question": "What makes unsupervised learning challenging for evaluation?",
        "student_answer": "Without labels, evaluating unsupervised results is difficult. Clustering quality metrics like silhouette score are approximate. Ground truth is unknown, making validation harder.",
        "target_json": "{\"score_30\": 23, \"key_coverage\": 2, \"missing_concepts\": [\"clustering evaluation metrics\", \"domain validation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good identification of evaluation challenges. Could discuss specific evaluation metrics and domain-expert validation approaches.\"}"
    },
    {
        "context": "Support Vector Machines find optimal separating hyperplanes by maximizing margins between classes.",
        "question": "How do kernel methods enable SVM to handle non-linear separation?",
        "student_answer": "Kernel methods compute dot products in high-dimensional feature spaces implicitly without explicit transformation. This enables non-linear decision boundaries in original space.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"kernel trick mathematics\", \"computational benefits\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of implicit mapping. Could elaborate on specific kernel functions and computational efficiency gains.\"}"
    },
    {
        "context": "Regularization constrains model complexity to prevent overfitting and improve generalization performance.",
        "question": "What is the relationship between regularization and model complexity?",
        "student_answer": "Strong regularization forces simpler models by penalizing complexity. This reduces overfitting but can increase bias if too strong. Weak regularization allows more complex fitting.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 3, \"missing_concepts\": [\"bias-variance framework\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of complexity-regularization relationship. Could frame more explicitly in bias-variance tradeoff terms.\"}"
    },
    {
        "context": "Ensemble Methods combine multiple models to reduce variance and improve prediction stability.",
        "question": "What conditions make ensemble methods effective?",
        "student_answer": "Ensembles work best when base models are accurate and diverse. If all models make the same mistakes, averaging doesn't help. Diversity in errors is what drives improvement.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [\"correlation effects\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of diversity-accuracy requirements. Could quantify correlation effects on ensemble performance.\"}"
    },
    {
        "context": "Bias-Variance Tradeoff describes how total error decomposes into bias and variance components.",
        "question": "How do bias and variance affect model generalization differently?",
        "student_answer": "High bias means the model is too simple and underfits, missing true patterns. High variance means the model is too complex and overfits to noise. Both hurt generalization.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 3, \"missing_concepts\": [\"error decomposition mathematics\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Clear explanation of underfitting and overfitting. Could show error decomposition formula explicitly.\"}"
    },
    {
        "context": "Hyperparameter Tuning selects optimal values for parameters not learned during training through systematic search.",
        "question": "What are advantages and disadvantages of grid search versus random search?",
        "student_answer": "Grid search systematically tries all combinations but is expensive for many hyperparameters. Random search samples randomly and often finds good solutions faster for high-dimensional spaces.",
        "target_json": "{\"score_30\": 24, \"key_coverage\": 2, \"missing_concepts\": [\"Bayesian optimization\", \"sample efficiency\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good comparison of both methods. Could mention Bayesian optimization as more sophisticated approach and sample efficiency metrics.\"}"
    },
    {
        "context": "Feature Normalization scales input features to similar ranges, important for distance-based algorithms and optimization.",
        "question": "Why does feature normalization affect model training?",
        "student_answer": "Without normalization, features with larger ranges dominate gradient updates. Normalization ensures all features contribute equally, enabling faster convergence and better generalization.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 3, \"missing_concepts\": [\"numerical stability\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of gradient balance. Could mention numerical stability improvements and distance computation fairness.\"}"
    },
    {
        "context": "Data Augmentation artificially increases training data through transformations preserving class labels.",
        "question": "What makes some augmentations more effective than others?",
        "student_answer": "Effective augmentations preserve task-relevant information while changing irrelevant aspects. For images, rotations and crops preserve content but change perspective. Augmentations should reflect real data variations.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 3, \"missing_concepts\": [\"domain-specific augmentation strategies\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good principle about task-relevance preservation. Could discuss domain-specific strategies and AutoAugment approaches.\"}"
    },
    {
        "context": "Model Selection chooses architectures and algorithms suited to specific tasks and constraints.",
        "question": "What factors should guide model selection?",
        "student_answer": "Model selection should consider task characteristics, data size, computational resources, interpretability needs, and expected performance. Different models excel for different problem types.",
        "target_json": "{\"score_30\": 24, \"key_coverage\": 3, \"missing_concepts\": [\"empirical benchmarking\", \"no free lunch theorem\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good coverage of selection factors. Could mention empirical validation and no free lunch principle.\"}"
    },
    {
        "context": "Imbalanced Learning addresses class imbalance where minority classes are underrepresented in training data.",
        "question": "What techniques address class imbalance?",
        "student_answer": "Oversampling replicates minority class samples, undersampling removes majority samples, and class weighting penalizes minority class errors more. SMOTE generates synthetic minority samples.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 3, \"missing_concepts\": [\"metric selection\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good technique coverage. Could emphasize metric selection beyond accuracy for imbalanced data evaluation.\"}"
    },
    {
        "context": "Interpretability makes model decisions understandable through techniques like LIME and attention visualization.",
        "question": "Why is interpretability important beyond accuracy metrics?",
        "student_answer": "Interpretability helps debug models, detect biases, and build user trust. High accuracy can hide systematic failures for specific groups. Interpretability reveals these issues.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 3, \"missing_concepts\": [\"regulatory requirements\", \"failure analysis\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Solid explanation of interpretability value. Could mention regulatory compliance and systematic failure analysis.\"}"
    },
    {
        "context": "Model Validation uses held-out test data to estimate unbiased generalization performance.",
        "question": "Why must validation data be separate from training data?",
        "student_answer": "Training error underestimates test error due to overfitting. Separate validation data provides unbiased performance estimates for real-world deployment without data leakage.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [\"statistical properties of validation estimates\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of overfitting and data leakage. Could discuss statistical properties of validation estimates.\"}"
    },
    {
        "context": "Loss Functions guide optimization by measuring prediction errors, and choice affects model behavior.",
        "question": "How does loss function selection impact model training?",
        "student_answer": "Different loss functions emphasize different aspects of error. MSE penalizes large errors heavily, MAE is robust to outliers, cross-entropy suits classification. Loss choice affects learned models.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 3, \"missing_concepts\": [\"gradient properties\", \"optimization landscape effects\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good examples of different loss properties. Could discuss gradient implications and optimization landscape changes.\"}"
    },
    {
        "context": "Neural Network Architecture defines layer structure and connections, encoding inductive biases for tasks.",
        "question": "How does architecture encode task-specific inductive biases?",
        "student_answer": "CNN architectures exploit spatial locality through local connectivity. RNNs exploit temporal structure through recurrence. Transformers exploit permutation-invariance through attention. Each architecture matches problem structure.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of architecture-task alignment and inductive bias encoding.\"}"
    },
    {
        "context": "Optimization algorithms like Adam and SGD differ in how they adapt learning rates and incorporate momentum.",
        "question": "What advantages does Adam have over SGD?",
        "student_answer": "Adam combines momentum with adaptive per-parameter learning rates, enabling faster convergence with less tuning. SGD requires careful learning rate scheduling. Adam is more robust to hyperparameter choices.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 3, \"missing_concepts\": [\"convergence guarantees\", \"generalization differences\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of Adam benefits. Could mention different convergence guarantees and generalization properties differences.\"}"
    },
    {
        "context": "Training Curves showing loss and accuracy evolution reveal model learning health and convergence properties.",
        "question": "What patterns in training curves indicate problems?",
        "student_answer": "Diverging train-test curves indicate overfitting. Stuck metrics suggest poor learning rate. Oscillating loss suggests instability. Flat curves mean no learning. These patterns guide diagnosis and adjustment.",
        "target_json": "{\"score_30\": 24, \"key_coverage\": 3, \"missing_concepts\": [\"learning rate diagnostic strategies\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good pattern identification. Could discuss specific diagnostic strategies and remediation approaches.\"}"
    },
    {
        "context": "Probabilistic Models represent uncertainty through probability distributions, enabling principled uncertainty reasoning.",
        "question": "What advantage do probabilistic models provide?",
        "student_answer": "Probabilistic models quantify uncertainty and provide confidence estimates. This enables risk-aware decisions and principled Bayesian inference compared to deterministic models.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 2, \"missing_concepts\": [\"uncertainty types\", \"decision-theoretic benefits\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of uncertainty quantification. Could distinguish epistemic vs aleatoric uncertainty and decision-theoretic implications.\"}"
    },
    {
        "context": "Deep Learning employs multiple hidden layers to learn hierarchical representations capturing increasingly abstract concepts.",
        "question": "How does depth improve representation learning?",
        "student_answer": "Deeper networks learn hierarchies where early layers capture low-level patterns and deeper layers capture high-level concepts. This hierarchical composition enables learning complex functions efficiently.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 3, \"missing_concepts\": [\"training challenges\", \"diminishing returns\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Solid explanation of hierarchical learning. Could mention training difficulties with depth and empirical diminishing returns.\"}"
    },
    {
        "context": "Vision Transformers apply transformer architecture to images by dividing them into patches and treating patches as sequence tokens.",
        "question": "How are images converted to sequences in Vision Transformers?",
        "student_answer": "Images are flattened into one-dimensional vectors and processed sequentially. Each pixel is treated as a token in the sequence like words in text.",
        "target_json": "{\"score_30\": 11, \"key_coverage\": 1, \"missing_concepts\": [\"patch embedding\", \"spatial structure preservation\", \"positional encoding\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Incorrect approach. Images are divided into patches, not individual pixels. Flattening loses spatial structure. Patches are embedded and positionally encoded.\"}"
    },
    {
        "context": "Self-Attention in transformers enables each position to attend to every other position, capturing long-range dependencies flexibly.",
        "question": "What is the computational complexity of self-attention?",
        "student_answer": "Self-attention has constant time complexity since each position just looks at a fixed set of other positions nearby, making it very efficient.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"quadratic complexity\", \"sequence length dependency\", \"attention computation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Self-attention has O(n²) complexity where each position attends to all positions. This is expensive for long sequences, not constant.\"}"
    },
    {
        "context": "Vanishing Gradient Problem occurs when gradients shrink exponentially through many layers, hampering learning in deep networks.",
        "question": "Why do gradients vanish in deep networks?",
        "student_answer": "Gradients vanish because multiplying many derivatives together can make very large numbers, which then get truncated by the computer.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 1, \"missing_concepts\": [\"chain rule multiplication\", \"ReLU advantages\", \"numerical underflow\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Backwards reasoning. Gradients shrink (not grow large then truncate). Multiplying values less than 1 repeatedly causes exponential decay through chain rule.\"}"
    },
    {
        "context": "Gradient Boosting sequentially trains models where each new model corrects errors of previous models by fitting residuals.",
        "question": "Why does Gradient Boosting typically outperform Random Forests?",
        "student_answer": "Gradient Boosting trains models one at a time which makes it smarter than Random Forests that train in parallel. Sequential training lets each model learn perfectly.",
        "target_json": "{\"score_30\": 12, \"key_coverage\": 1, \"missing_concepts\": [\"residual fitting\", \"adaptive learning\", \"bias reduction\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Vague and informal. Boosting outperforms by focusing on residuals, not just from sequential training. Parallel training isn't bad; different approach, different properties.\"}"
    },
    {
        "context": "Variational Autoencoders learn probabilistic latent representations by optimizing the Evidence Lower Bound (ELBO).",
        "question": "What does the KL divergence term in VAE loss do?",
        "student_answer": "The KL divergence term makes the latent space smaller so the model compresses data better. It's just a regularization term that doesn't really matter much.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 1, \"missing_concepts\": [\"prior matching\", \"latent distribution shape\", \"posterior regularization\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Incomplete understanding. KL divergence enforces latent distribution matches prior, enabling generation and interpolation. It's critical, not just compression.\"}"
    },
    {
        "context": "Meta-Learning enables models to learn how to learn from few examples through learning algorithms that generalize across tasks.",
        "question": "How is meta-learning different from transfer learning?",
        "student_answer": "Meta-learning and transfer learning are basically the same thing. Both use pre-trained models and fine-tune them on new tasks.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"algorithm learning\", \"task distribution\", \"few-shot adaptation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Meta-learning learns algorithms/initialization for quick adaptation; transfer learning uses fixed features. Meta-learning optimizes the learning process itself.\"}"
    },
    {
        "context": "Contrastive Learning learns embeddings by pulling similar samples close and pushing dissimilar samples apart.",
        "question": "What role do negative pairs play in contrastive learning?",
        "student_answer": "Negative pairs don't really matter much. The main thing is just making sure positive pairs are close to each other.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 1, \"missing_concepts\": [\"repulsive forces\", \"representation discrimination\", \"hard negatives\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Negatives are critical for preventing collapse where all embeddings become identical. Repulsive forces enable discrimination between different samples.\"}"
    },
    {
        "context": "Adversarial Examples are inputs deliberately crafted to fool models despite appearing normal to humans.",
        "question": "Why are adversarial examples important to study?",
        "student_answer": "Adversarial examples are just theoretical curiosities with no practical importance. Real-world deployments don't need to worry about deliberately crafted attacks.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 0, \"missing_concepts\": [\"robustness\", \"security implications\", \"model fragility\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Adversarial examples reveal critical robustness vulnerabilities. They're security threats in real systems and essential for safe deployment.\"}"
    },
    {
        "context": "Graph Neural Networks aggregate information from neighbors to learn node representations, effective for structured data.",
        "question": "How do GNNs handle variable-sized neighborhoods?",
        "student_answer": "GNNs can't handle variable neighborhoods. They only work if every node has exactly the same number of neighbors, which is impossible for real graphs.",
        "target_json": "{\"score_30\": 6, \"key_coverage\": 0, \"missing_concepts\": [\"pooling\", \"averaging\", \"message aggregation functions\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. GNNs use aggregation functions like sum or average that handle variable-sized neighborhoods easily. Pooling enables flexibility.\"}"
    },
    {
        "context": "Self-Supervised Learning learns from unlabeled data by creating pretext tasks that provide training signals without manual labels.",
        "question": "What is the difference between self-supervised and unsupervised learning?",
        "student_answer": "Self-supervised and unsupervised learning are the exact same thing. They both train on data without labels so there's no real difference.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 0, \"missing_concepts\": [\"pretext tasks\", \"artificial labels\", \"learning objectives\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Self-supervised creates artificial labels through pretext tasks (e.g., next word prediction). Unsupervised has no labels or predefined tasks. Different paradigms.\"}"
    },
    {
        "context": "Explainability in AI makes model decisions interpretable through techniques like LIME that create local approximations.",
        "question": "What is a limitation of LIME for model explanation?",
        "student_answer": "LIME has no real limitations. It perfectly explains what any model is doing by looking at local regions.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"local approximation\", \"global structure loss\", \"instability\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. LIME provides local explanations which may not reflect global model behavior. Results are unstable for similar inputs and miss big-picture patterns.\"}"
    },
    {
        "context": "Multi-Task Learning trains a single model on multiple related tasks simultaneously, enabling knowledge sharing.",
        "question": "Why might multi-task learning hurt performance?",
        "student_answer": "Multi-task learning always helps because you get more training data. There's no scenario where it would hurt performance.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"negative transfer\", \"task interference\", \"conflicting gradients\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Tasks can have conflicting gradients causing negative transfer. Incompatible tasks hurt performance. Task selection and weighting are critical.\"}"
    },
    {
        "context": "Few-Shot Learning enables models to learn from very few examples per class, typically 1-10 samples.",
        "question": "How do few-shot models learn from such limited data?",
        "student_answer": "Few-shot models just memorize the few examples since there's so little data. They can't really generalize with only 1-10 samples.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 1, \"missing_concepts\": [\"meta-learning\", \"prototypes\", \"learned similarity\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong reasoning. Few-shot models learn from pre-training and use meta-learning or prototypical networks, not pure memorization. They leverage prior knowledge.\"}"
    },
    {
        "context": "Semantic Segmentation assigns class labels to every pixel in images for detailed scene understanding.",
        "question": "Why do semantic segmentation models use encoder-decoder architectures?",
        "student_answer": "Encoder-decoder is just the standard way to do segmentation. It doesn't really matter; you could use any architecture.",
        "target_json": "{\"score_30\": 11, \"key_coverage\": 1, \"missing_concepts\": [\"downsampling recovery\", \"spatial resolution\", \"feature combination\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Incomplete. Encoders reduce spatial resolution efficiently; decoders recover spatial detail. Skip connections restore fine features. Architecture choice is critical.\"}"
    },
    {
        "context": "Object Detection combines classification and localization by predicting both class labels and bounding boxes.",
        "question": "What is the advantage of anchor-free detection methods?",
        "student_answer": "Anchor-free methods don't work as well as anchor-based methods. They're just a gimmick that removes the need for anchor design but performs worse.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 0, \"missing_concepts\": [\"hyperparameter reduction\", \"performance improvements\", \"design simplicity\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Anchor-free methods reduce hyperparameter tuning and often achieve better performance than anchor-based approaches by predicting centers directly.\"}"
    },
    {
        "context": "Natural Language Processing handles text through tokenization, embedding, and contextual understanding.",
        "question": "Why do pre-trained language models perform well on new tasks?",
        "student_answer": "Pre-trained models are just big, so they're good at everything. Size is what matters, not the pre-training.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 1, \"missing_concepts\": [\"language understanding\", \"contextual representations\", \"transfer of knowledge\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Oversimplified and incorrect. Pre-training on large corpora teaches language understanding and creates rich contextual representations that transfer effectively.\"}"
    },
    {
        "context": "Reinforcement Learning from Human Feedback trains models using reward signals derived from human preferences.",
        "question": "Why is RLHF important for language model alignment?",
        "student_answer": "RLHF doesn't really improve models. Humans are just biased and inconsistent, so their feedback makes models worse.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"value alignment\", \"safety\", \"human preferences\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. RLHF aligns models with human values and preferences, essential for safe and useful systems. Human feedback is imperfect but valuable.\"}"
    },
    {
        "context": "Neural Architecture Search automatically discovers optimal network architectures through optimization algorithms.",
        "question": "What is a major challenge in Neural Architecture Search?",
        "student_answer": "Neural Architecture Search has no challenges. It always finds the best architecture automatically.",
        "target_json": "{\"score_30\": 6, \"key_coverage\": 0, \"missing_concepts\": [\"computational cost\", \"search space\", \"evaluation expense\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. NAS is computationally expensive requiring thousands of model evaluations. Search space is huge and evaluation is costly.\"}"
    },
    {
        "context": "Federated Learning trains models on decentralized devices while keeping data private by sharing only model updates.",
        "question": "What privacy guarantees does federated learning provide?",
        "student_answer": "Federated learning is completely private. Sharing model gradients is safe because gradients contain no information about data.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 0, \"missing_concepts\": [\"gradient inversion\", \"differential privacy\", \"membership inference\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Gradients can leak training data through inversion attacks. Federated alone doesn't guarantee privacy; differential privacy must be added.\"}"
    },
    {
        "context": "Continual Learning enables models to learn from sequential tasks without catastrophic forgetting of previous knowledge.",
        "question": "How can continual learning prevent catastrophic forgetting?",
        "student_answer": "You can't prevent catastrophic forgetting in neural networks. Once you train on new tasks, old knowledge is always lost.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"replay buffers\", \"elastic weight consolidation\", \"task-specific parameters\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Catastrophic forgetting can be mitigated through experience replay, EWC, progressive networks, and task-specific parameters.\"}"
    },
    {
        "context": "Recommender Systems predict user preferences through collaborative filtering, content-based, or hybrid approaches.",
        "question": "What is the cold start problem in recommendation systems?",
        "student_answer": "The cold start problem doesn't really exist. Recommendation systems always work well even with new users or items.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"new user behavior\", \"new item data\", \"solution strategies\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Completely wrong. Cold start is a major problem where new users/items have no history. Solutions include content features and item popularity strategies.\"}"
    },
    {
        "context": "Model Calibration adjusts model confidence scores to accurately reflect true probabilities for reliable uncertainty estimates.",
        "question": "Why is calibration important for real applications?",
        "student_answer": "Calibration doesn't matter. If a model has high accuracy, the confidence scores are automatically well-calibrated.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"confidence vs accuracy\", \"reliability\", \"decision making\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. High accuracy doesn't ensure calibration. Models can be accurate but overconfident. Calibration is essential for reliable decision-making.\"}"
    },
    {
        "context": "Active Learning selects which samples to label to maximize learning with minimal annotation cost.",
        "question": "What makes active learning different from random sampling?",
        "student_answer": "Active learning doesn't really save much labeling effort. Random sampling works just as well for learning.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 0, \"missing_concepts\": [\"information gain\", \"uncertainty sampling\", \"label efficiency\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Active learning dramatically reduces labeling requirements by targeting informative samples. Random sampling wastes labels on uninformative examples.\"}"
    },
    {
        "context": "Weakly Supervised Learning learns from imprecise labels like noisy annotations or partial labels.",
        "question": "Why is weakly supervised learning valuable?",
        "student_answer": "Weakly supervised learning is a bad idea. Noisy labels just confuse models and make performance worse than starting with no labels.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 1, \"missing_concepts\": [\"label scarcity solutions\", \"practical efficiency\", \"cost reduction\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Weakly supervised labels, despite noise, enable learning when clean labels are expensive or unavailable. Signal outweighs noise with proper techniques.\"}"
    },
    {
        "context": "Capsule Networks use capsules as groups of neurons encoding spatial hierarchies and poses.",
        "question": "What is the main innovation of capsule networks?",
        "student_answer": "Capsule networks are just CNNs with a different name. There's no real innovation, just a marketing term.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"vector outputs\", \"routing mechanisms\", \"spatial relationships\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Oversimplified and dismissive. Capsules output vectors not scalars, use routing-by-agreement, and explicitly represent spatial relationships unlike max-pooling CNNs.\"}"
    },
    {
        "context": "Domain Adaptation addresses distribution shift between training and test domains through adversarial alignment.",
        "question": "How does adversarial domain adaptation work?",
        "student_answer": "Adversarial domain adaptation just randomly changes the data to make it different. It doesn't really help much.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"domain discriminator\", \"feature alignment\", \"adversarial objective\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Incomplete and vague. Adversarial adaptation uses domain discriminators to learn domain-invariant features through adversarial training, not random changes.\"}"
    },
    {
        "context": "Generative Models learn to create new samples from learned distributions through VAEs or GANs.",
        "question": "What distinguishes autoregressive from non-autoregressive generation?",
        "student_answer": "Autoregressive and non-autoregressive are the same thing. There's no real difference between them.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 0, \"missing_concepts\": [\"sequential vs parallel\", \"token dependency\", \"generation speed\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Autoregressive generates tokens sequentially dependent on previous tokens. Non-autoregressive generates all tokens in parallel, faster but often lower quality.\"}"
    },
    {
        "context": "Knowledge Distillation transfers knowledge from large teacher models to smaller student models for efficient deployment.",
        "question": "Why does knowledge distillation improve student model performance?",
        "student_answer": "Knowledge distillation doesn't really help. Training a smaller model from scratch works just as well as distilling from a teacher.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 1, \"missing_concepts\": [\"soft targets\", \"privileged information\", \"knowledge transfer\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Soft targets from teachers provide richer learning signals than hard labels. This privileged information enables students to outperform direct training.\"}"
    },
    {
        "context": "Few-Shot Object Detection detects objects in images with very few training examples per class.",
        "question": "What challenge makes few-shot object detection harder than few-shot classification?",
        "student_answer": "Few-shot object detection and classification are equally difficult. There's no meaningful difference in difficulty.",
        "target_json": "{\"score_30\": 11, \"key_coverage\": 1, \"missing_concepts\": [\"localization requirement\", \"spatial variation\", \"background complexity\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Detection requires precise localization in addition to classification. Background complexity, spatial variations, and localization make it harder than classification.\"}"
    },
    {
        "context": "Zero-Shot Learning recognizes unseen classes by leveraging semantic relationships between seen and unseen classes.",
        "question": "How do semantic attributes enable zero-shot learning?",
        "student_answer": "Semantic attributes don't really help. You can't possibly classify things you've never seen before.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"attribute transfer\", \"generalized concepts\", \"cross-class relationships\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Attributes provide semantic bridges between seen and unseen classes. Learning attribute classifiers enables zero-shot classification through generalized concepts.\"}"
    },
    {
        "context": "Attention Flow in transformers reveals how information propagates through attention layers to understand reasoning.",
        "question": "What information does attention flow reveal about model reasoning?",
        "student_answer": "Attention flow doesn't reveal much. Attention weights are just noise and don't correlate with actual model reasoning.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 0, \"missing_concepts\": [\"information pathway\", \"token importance\", \"reasoning traces\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Attention flow reveals information pathways between tokens and shows which inputs influenced outputs. This provides interpretability into model reasoning.\"}"
    },
    {
        "context": "Spiking Neural Networks process information through discrete spike events, enabling event-driven neuromorphic computation.",
        "question": "What advantage do spiking networks have over artificial neural networks?",
        "student_answer": "Spiking neural networks don't have any advantages. They're just biologically-inspired and perform worse than traditional networks.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 1, \"missing_concepts\": [\"energy efficiency\", \"event-driven computation\", \"temporal processing\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. SNNs provide energy efficiency through event-driven computation and handle temporal information naturally. They're promising for neuromorphic hardware.\"}"
    },
    {
        "context": "Causal Inference learns causal relationships rather than correlations, enabling intervention effects and counterfactual reasoning.",
        "question": "Why does causal reasoning matter if correlation works for prediction?",
        "student_answer": "Causal reasoning is pointless. If correlation works for prediction, that's all that matters. Causality is just philosophy.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"interventions\", \"policy learning\", \"counterfactuals\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Causality is essential for interventions and policy decisions. Correlations fail when conditions change. Causality enables counterfactual reasoning.\"}"
    },
    {
        "context": "Model Pruning removes redundant weights or neurons to reduce model size while maintaining performance.",
        "question": "What is a drawback of magnitude-based weight pruning?",
        "student_answer": "Magnitude-based pruning has no drawbacks. It always works perfectly and removes useless weights.",
        "target_json": "{\"score_30\": 9, \"key_coverage\": 0, \"missing_concepts\": [\"hardware compatibility\", \"specialized computation\", \"fine-grained sparsity\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Fine-grained pruning creates irregular sparsity requiring specialized hardware. Standard hardware can't exploit fine-grained sparsity efficiently.\"}"
    },
    {
        "context": "Foundation Models are large-scale pre-trained models trained on broad data that transfer to diverse downstream tasks.",
        "question": "What scaling laws predict for foundation models?",
        "student_answer": "Scaling laws don't apply to foundation models. Adding more parameters or data doesn't help since they already have enough.",
        "target_json": "{\"score_30\": 7, \"key_coverage\": 0, \"missing_concepts\": [\"predictable performance\", \"emergent abilities\", \"compute-optimal scaling\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Scaling laws show predictable power-law performance improvements. More parameters and data consistently improve models. Emergent abilities appear at scale.\"}"
    },
    {
        "context": "Prompt Engineering involves crafting effective instructions for large language models through techniques like few-shot prompting and chain-of-thought reasoning.",
        "question": "Why does chain-of-thought prompting improve model reasoning?",
        "student_answer": "Chain-of-thought prompting asks models to show their work step-by-step before answering. This encourages systematic thinking and reduces errors on multi-step problems.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of step-by-step reasoning benefits and error reduction on complex tasks.\"}"
    },
    {
        "context": "Multimodal Learning combines information from multiple modalities like images, text, and audio to create richer representations.",
        "question": "What advantage does fusion of modalities provide?",
        "student_answer": "Different modalities capture complementary information that reduces ambiguity. Combining them creates better representations than single modalities alone.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of complementary information and representation richness through multimodal fusion.\"}"
    },
    {
        "context": "Parameter-Efficient Fine-Tuning methods like LoRA reduce parameters during fine-tuning by decomposing weight updates into low-rank matrices.",
        "question": "How does LoRA maintain model expressiveness with fewer parameters?",
        "student_answer": "LoRA uses low-rank matrices A and B whose product approximates weight updates. Though individually small, their product maintains expressiveness through composition.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 2, \"missing_concepts\": [\"rank selection\", \"theoretical justification\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of matrix composition. Could discuss rank selection and why low-rank updates work in practice.\"}"
    },
    {
        "context": "Reinforcement Learning from Human Feedback aligns language models with human values through reward signals from preference comparisons.",
        "question": "What are the stages of RLHF training?",
        "student_answer": "First, supervised fine-tuning adapts the base model. Second, a reward model learns from human preferences. Third, PPO uses the reward model to optimize policy.",
        "target_json": "{\"score_30\": 30, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect sequence of RLHF stages with correct components and ordering.\"}"
    },
    {
        "context": "Long Context Understanding handles extended input sequences through techniques like sparse attention and flash attention.",
        "question": "How do sparse attention patterns reduce computational complexity?",
        "student_answer": "Sparse attention only computes attention between selected positions instead of all positions. This reduces complexity from O(n²) to something more manageable.",
        "target_json": "{\"score_30\": 24, \"key_coverage\": 2, \"missing_concepts\": [\"specific patterns\", \"complexity bounds\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good basic explanation. Could specify sparse patterns (local, strided, block-sparse) and exact complexity improvements.\"}"
    },
    {
        "context": "Model Merging combines multiple fine-tuned models into a single model through weight interpolation or averaging.",
        "question": "What are challenges in merging models from different tasks?",
        "student_answer": "Different models may have conflicting weights optimized for different tasks. Merging them can degrade performance if task objectives aren't compatible.",
        "target_json": "{\"score_30\": 23, \"key_coverage\": 2, \"missing_concepts\": [\"performance degradation\", \"interference patterns\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good identification of task conflicts. Could discuss specific degradation patterns and when merging succeeds vs fails.\"}"
    },
    {
        "context": "In-Context Learning enables models to perform new tasks from few examples in context without parameter updates.",
        "question": "What mechanisms enable in-context learning in transformers?",
        "student_answer": "Transformers learn to recognize patterns in context and adapt through attention mechanisms. The model recognizes examples in the prompt and applies learned task structures.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of pattern recognition and attention-based adaptation in context.\"}"
    },
    {
        "context": "Quantization reduces model precision to decrease size and accelerate inference while maintaining performance.",
        "question": "What is the accuracy-efficiency tradeoff in quantization?",
        "student_answer": "Lower precision reduces model size and computation but may degrade accuracy. Quantization-aware training helps by letting weights adapt to lower precision.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 2, \"missing_concepts\": [\"per-layer sensitivity\", \"mixed precision\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of tradeoff. Could mention per-layer sensitivity differences and mixed precision strategies.\"}"
    },
    {
        "context": "Efficient Transformers use alternative attention mechanisms to reduce O(n²) complexity to O(n) or O(n log n).",
        "question": "How do kernel methods reduce attention complexity?",
        "student_answer": "Kernel methods replace softmax attention with kernel functions that enable linear attention computation. This transforms O(n²) attention into O(n) operations.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of kernel approximation and complexity reduction mechanism.\"}"
    },
    {
        "context": "Controlled Generation in language models constrains outputs to satisfy specific requirements like format or token constraints.",
        "question": "What techniques enable constrained decoding?",
        "student_answer": "Beam search can filter invalid hypotheses during search. Prefix trees enforce valid tokens at each step. Guided generation uses scores to steer toward valid outputs.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent coverage of multiple constraint satisfaction techniques.\"}"
    },
    {
        "context": "Embedding Models learn dense vector representations capturing semantic similarity for retrieval and clustering tasks.",
        "question": "How does contrastive learning train embeddings effectively?",
        "student_answer": "Contrastive learning pulls matched pairs close while pushing non-matched pairs apart in embedding space. This trains embeddings to reflect semantic relationships.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of contrastive objective and semantic relationship capture.\"}"
    },
    {
        "context": "Retrieval-Augmented Generation retrieves relevant documents and conditions generation on retrieved context.",
        "question": "How does RAG reduce hallucinations compared to standard LLMs?",
        "student_answer": "RAG retrieves factual information from external sources and conditions generation on retrieved context. This grounds generation in real documents rather than training data alone.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of grounding and factual reference benefits in RAG.\"}"
    },
    {
        "context": "Heterogeneous Graph Neural Networks process graphs with multiple node and edge types through type-specific transformations.",
        "question": "Why do heterogeneous graphs require specialized processing?",
        "student_answer": "Different node and edge types have different semantics and feature spaces. Type-specific transformations preserve this heterogeneity while learning appropriate representations.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of type-specific semantics and preservation through specialized processing.\"}"
    },
    {
        "context": "Neural Collaborative Filtering uses neural networks to learn complex user-item interactions beyond simple dot products.",
        "question": "What expressiveness advantage do neural networks provide over matrix factorization?",
        "student_answer": "Neural networks learn non-linear interactions between user and item embeddings. Matrix factorization only captures linear dot-product relationships.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of non-linear vs linear expressiveness difference.\"}"
    },
    {
        "context": "Representation Learning automatically learns meaningful feature representations from data through self-supervised or supervised methods.",
        "question": "What properties characterize good learned representations?",
        "student_answer": "Good representations preserve task-relevant information while discarding noise. They should be invariant to irrelevant variations and capture underlying factors of variation.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent characterization of representation quality through information preservation and invariance.\"}"
    },
    {
        "context": "Contrastive Divergence trains energy-based models by approximating gradients using limited MCMC sampling.",
        "question": "Why is contrastive divergence computationally efficient?",
        "student_answer": "Contrastive divergence uses a few MCMC steps starting from data instead of full sampling to the model distribution. This approximation dramatically reduces computation.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of computational savings through incomplete sampling approximation.\"}"
    },
    {
        "context": "Variational Inference approximates intractable posteriors through tractable variational families, optimizing the ELBO.",
        "question": "How does ELBO relate to KL divergence minimization?",
        "student_answer": "ELBO lower bounds log marginal likelihood. Maximizing ELBO minimizes KL divergence between the variational approximation and true posterior.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of ELBO-KL relationship and its optimization significance.\"}"
    },
    {
        "context": "Out-of-Distribution Detection identifies when inputs fall outside training distribution, crucial for safe deployment.",
        "question": "What challenge makes OOD detection difficult?",
        "student_answer": "OOD detection is hard because models can be confident on out-of-distribution examples. High confidence doesn't always indicate in-distribution data.",
        "target_json": "{\"score_30\": 24, \"key_coverage\": 2, \"missing_concepts\": [\"semantic shift\", \"detection methods comparison\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good identification of confidence-reliability decoupling. Could discuss semantic drift and various detection approaches.\"}"
    },
    {
        "context": "Sharpness-Aware Minimization seeks flat minima that generalize better than sharp minima.",
        "question": "Why do flat minima generalize better?",
        "student_answer": "Flat minima have high loss plateaus where small parameter changes maintain similar loss. This indicates robust representations compared to sharp minima.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of robustness and generalization through loss landscape geometry.\"}"
    },
    {
        "context": "Stochastic Weight Averaging improves generalization by averaging weights along SGD trajectories.",
        "question": "How does weight averaging find better solutions?",
        "student_answer": "Weight averaging finds regions where diverse good minima exist nearby. The average weight often sits in a flatter region than individual checkpoints.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of local flatness and robustness through averaging.\"}"
    },
    {
        "context": "Vision-Language Models combine visual and textual understanding through shared embeddings and alignment.",
        "question": "How do vision-language models enable zero-shot transfer?",
        "student_answer": "Vision-language models learn aligned embeddings between images and text. Zero-shot transfer works by matching new image embeddings to text class descriptions.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"scaling benefits\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of embedding alignment. Could mention scaling benefits enabling rich concept transfer.\"}"
    },
    {
        "context": "Test-Time Augmentation generates multiple predictions from augmented versions and aggregates results.",
        "question": "When is test-time augmentation most beneficial?",
        "student_answer": "TTA helps most when the model is uncertain or when augmentations create informative variations. It averages complementary perspectives from different augmented views.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 2, \"missing_concepts\": [\"computational cost\", \"augmentation type effects\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of uncertainty and perspective averaging. Could discuss computational costs and augmentation selection.\"}"
    },
    {
        "context": "Mixture of Experts with sparse gating enables scaling by activating only relevant experts per input.",
        "question": "What is router collapse in sparse MoE?",
        "student_answer": "Router collapse occurs when the gating network routes most inputs to the same expert. This wastes expert capacity and degrades performance through load imbalance.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of router collapse problem and capacity waste consequences.\"}"
    },
    {
        "context": "Positional Interpolation extends transformer context by interpolating position encodings to longer sequences.",
        "question": "Why does interpolation work better than extrapolation for positions?",
        "student_answer": "Interpolation stays within the distribution of training lengths, maintaining learned position patterns. Extrapolation ventures into unseen positions with no pattern guarantee.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"scaling factors\", \"generalization behavior\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of distribution preservation. Could discuss scaling factors and generalization degradation rates.\"}"
    },
    {
        "context": "Gradient Accumulation simulates larger batch sizes by accumulating gradients before updating, enabling training with limited memory.",
        "question": "What are the computational tradeoffs of gradient accumulation?",
        "student_answer": "Gradient accumulation reduces memory by using smaller batches but requires more forward-backward passes. This trades memory for computation time.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of memory-computation tradeoff in gradient accumulation.\"}"
    },
    {
        "context": "Dynamic Networks adapt computation based on input characteristics, routing through different paths.",
        "question": "How do early exit mechanisms improve efficiency?",
        "student_answer": "Early exits let simple samples leave after shallow layers while complex samples proceed deeper. This balances accuracy and efficiency by adapting computation to input difficulty.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of adaptive computation and sample-dependent efficiency gains.\"}"
    },
    {
        "context": "Zero-Knowledge Proofs enable verification of model properties without revealing weights or internal mechanisms.",
        "question": "What is the benefit of zero-knowledge proofs for AI systems?",
        "student_answer": "ZK proofs enable privacy-preserving verification of model safety and fairness properties. This allows trust verification without exposing proprietary model details.",
        "target_json": "{\"score_30\": 25, \"key_coverage\": 2, \"missing_concepts\": [\"computational overhead\", \"verifiable computation\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of privacy-preserving verification. Could mention computational costs and verifiable computation frameworks.\"}"
    },
    {
        "context": "Mixture of Agents uses multiple specialized agents with diverse strengths to solve complex problems through collaboration.",
        "question": "How do multiple agents improve problem-solving?",
        "student_answer": "Different agents have complementary strengths and perspectives. Combining them through voting or discussion reduces individual weaknesses and increases robustness.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of complementary strengths and robustness through agent diversity.\"}"
    },
    {
        "context": "Backpropagation Through Time computes gradients for RNNs by unrolling over time and applying backpropagation.",
        "question": "Why does truncated BPTT reduce computational requirements?",
        "student_answer": "Truncated BPTT limits backpropagation to recent time steps instead of the entire sequence. This reduces memory and computation while maintaining gradient signals for nearby dependencies.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of computational savings and maintained gradient flow.\"}"
    },
    {
        "context": "Fairness in Machine Learning ensures equitable treatment across demographic groups through fairness metrics and constraints.",
        "question": "What is the difference between demographic parity and equalized odds?",
        "student_answer": "Demographic parity requires equal prediction rates across groups. Equalized odds requires equal true positive and false positive rates across groups.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect distinction between fairness criteria and their different optimization targets.\"}"
    },
    {
        "context": "Kernel Methods learn non-linear decisions through implicit feature mapping without explicit transformation.",
        "question": "What is the computational benefit of the kernel trick?",
        "student_answer": "The kernel trick computes dot products in high-dimensional spaces by evaluating kernel functions in original space. This avoids expensive explicit transformation.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of implicit mapping and computational efficiency.\"}"
    },
    {
        "context": "Normalized Softmax in face recognition creates angular margins between class embeddings for improved discrimination.",
        "question": "How does angular margin loss improve discrimination?",
        "student_answer": "Angular margin loss increases angles between different class embeddings during training. This forces embeddings to be more separable and discriminative.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of angular separation and improved discrimination.\"}"
    },
    {
        "context": "Attention Rollout visualizes transformer attention by aggregating weights across layers for comprehensive interpretability.",
        "question": "Why is layer aggregation necessary for attention interpretability?",
        "student_answer": "Single layer attention shows local dependencies. Aggregating across layers reveals the full attention pathway from input to output prediction.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 2, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of complete reasoning pathway through layer aggregation.\"}"
    },
    {
        "context": "Batch Effects in machine learning refer to systematic variations from experimental processing confounding true signals.",
        "question": "How can batch effects be corrected?",
        "student_answer": "ComBat and similar methods estimate batch effects as additive and multiplicative components, removing them before analysis while preserving biological signal.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"validation strategies\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of batch removal. Could discuss validation approaches for correction effectiveness.\"}"
    },
    {
        "context": "Imbalanced Metric Learning addresses few-shot scenarios where minority classes have limited samples.",
        "question": "Why are standard metric learning approaches problematic for imbalanced classes?",
        "student_answer": "Standard approaches weight all samples equally, causing majority classes to dominate embedding space. Minority class embeddings cluster poorly with few examples.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of majority class dominance and minority class clustering degradation.\"}"
    },
    {
        "context": "Stochastic Depth randomly drops residual branches during training, improving efficiency and regularization.",
        "question": "How does stochastic depth prevent overfitting?",
        "student_answer": "Stochastic depth randomly skips connections, creating an implicit ensemble of different network depths. This forces robust feature learning at all depths.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of ensemble effect and depth-wise robust learning.\"}"
    },
    {
        "context": "Focal Loss addresses class imbalance by down-weighting easy examples and focusing on hard negatives.",
        "question": "How does focal loss differ from standard cross-entropy?",
        "student_answer": "Focal loss adds a modulating factor reducing loss for well-classified examples. This focuses training on hard examples instead of easy negatives dominating gradients.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of hard example focusing and easy negative down-weighting.\"}"
    },
    {
        "context": "Spectral Clustering uses graph Laplacian eigenvectors to partition data, effective for non-convex clusters.",
        "question": "Why can spectral clustering find non-convex cluster shapes?",
        "student_answer": "Spectral clustering transforms data using eigenvectors derived from graph structure. This transformed space makes non-convex manifolds separable linearly.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of graph-based transformation enabling linear separability.\"}"
    },
    {
        "context": "Learning Rate Scheduling adapts learning rate during training to balance convergence speed and final quality.",
        "question": "What is the benefit of cosine annealing?",
        "student_answer": "Cosine annealing smoothly decreases learning rate following a cosine curve. This enables large initial steps for rapid convergence and small steps for fine-tuning.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of coarse-to-fine progression through cosine annealing.\"}"
    },
    {
        "context": "Subword Tokenization using BPE and WordPiece balances vocabulary size and coverage for rare word representation.",
        "question": "How does BPE iteratively build vocabulary?",
        "student_answer": "BPE starts with character vocabulary and iteratively merges most frequent adjacent pairs. Rare words decompose into frequent subword units automatically.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of iterative pair merging and rare word handling.\"}"
    },
    {
        "context": "Lottery Ticket Hypothesis suggests networks contain sparse subnetworks achieving comparable performance when trained from specific initializations.",
        "question": "What does lottery ticket hypothesis imply about network pruning?",
        "student_answer": "The hypothesis suggests networks contain efficient subnetworks. This justifies aggressive pruning and implies training inefficiency comes from unnecessary connections.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of pruning implications. Could discuss initialization importance and weight retraining.\"}"
    },
    {
        "context": "Manifold Learning discovers low-dimensional structure in high-dimensional data through t-SNE and UMAP.",
        "question": "How does t-SNE preserve local and global structure?",
        "student_answer": "t-SNE uses different kernels for local and global distances: Gaussian for nearby points and Student-t for far points. This preserves both local clusters and global geometry.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of dual-scale approach and structure preservation.\"}"
    },
    {
        "context": "Curriculum Learning for NLP starts with simple examples and gradually increases difficulty to improve convergence.",
        "question": "Why does curriculum learning improve NLP model training?",
        "student_answer": "Starting with easy examples provides strong initial signals for weight initialization. Complex examples later benefit from pre-learned representations, improving convergence.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of initialization benefits and representation transfer.\"}"
    },
    {
        "context": "Federated Averaging aggregates model updates from multiple clients to train global models while keeping data decentralized.",
        "question": "What privacy guarantee does federated averaging provide?",
        "student_answer": "Federated averaging prevents direct data access by sharing only model updates. With differential privacy, noise can be added to updates for stronger privacy.",
        "target_json": "{\"score_30\": 26, \"key_coverage\": 2, \"missing_concepts\": [\"gradient attack vulnerabilities\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Good explanation of gradient-level privacy. Could mention vulnerability to gradient inversion attacks.\"}"
    },
    {
        "context": "Multi-Scale Feature Processing combines features at different resolutions to capture both details and context.",
        "question": "How do feature pyramids improve object detection?",
        "student_answer": "Feature pyramids create multi-scale representations where objects appear at appropriate resolution levels. Small objects show at high-resolution and large objects at low-resolution.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of scale-appropriate feature detection through pyramid structure.\"}"
    },
    {
        "context": "Synthetic Data Generation creates artificial training data when real data is scarce, private, or expensive through generative models.",
        "question": "What are the limitations of purely synthetic data for training models?",
        "student_answer": "Synthetic data may not capture all real-world variations and corner cases. Distribution mismatch between synthetic and real data causes domain gap reducing generalization.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent identification of distribution mismatch and real-world variation limitations.\"}"
    },
    {
        "context": "Orthogonal Regularization constrains weight matrices to have orthogonal columns or rows, improving stability.",
        "question": "How does orthogonality help preserve gradient magnitudes in deep networks?",
        "student_answer": "Orthogonal transformations preserve vector norms, preventing gradients from vanishing or exploding when multiplied by orthogonal weight matrices.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of norm preservation and gradient stability through orthogonality.\"}"
    },
    {
        "context": "Optimal Transport provides a framework for comparing distributions and learning mappings through Wasserstein distance.",
        "question": "What advantage does optimal transport have over other divergence measures?",
        "student_answer": "Optimal transport is just a fancy name for distance computation but doesn't really provide practical benefits over simpler methods.",
        "target_json": "{\"score_30\": 12, \"key_coverage\": 1, \"missing_concepts\": [\"geometric interpretation\", \"differentiability\", \"computational efficiency\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Dismissive tone and incorrect conclusion. Wasserstein distance is differentiable and enables gradient-based optimization unlike some divergence measures.\"}"
    },
    {
        "context": "Compositional Generalization enables models to understand new combinations of known concepts beyond interpolation.",
        "question": "Why do neural networks struggle with compositional generalization?",
        "student_answer": "Neural networks often learn surface-level correlations rather than compositional structure. Without explicit compositional inductive biases, they fail on novel combinations.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of surface correlation learning and missing compositional structure.\"}"
    },
    {
        "context": "Symmetry in Neural Networks exploits data symmetries through equivariant architectures respecting problem structure.",
        "question": "What is the benefit of equivariant neural networks?",
        "student_answer": "Equivariant networks transform outputs consistently with input transformations, capturing symmetries. This reduces sample complexity and improves generalization to transformed inputs.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of symmetry exploitation and sample efficiency improvements.\"}"
    },
    {
        "context": "Temperature in Softmax controls output probability distribution sharpness affecting model confidence and exploration.",
        "question": "Why does temperature tuning matter for language model decoding?",
        "student_answer": "Low temperature produces sharp distributions favoring high-probability tokens. High temperature smooths probabilities encouraging diversity. Temperature tunes confidence and variety.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of temperature effects on probability distributions and output characteristics.\"}"
    },
    {
        "context": "Cross-Domain Generalization requires models to perform well across multiple domains despite distribution shifts.",
        "question": "What is domain randomization and how does it improve generalization?",
        "student_answer": "Domain randomization just changes colors randomly. It's not very effective and doesn't really help with real domain shifts.",
        "target_json": "{\"score_30\": 11, \"key_coverage\": 1, \"missing_concepts\": [\"environment variation\", \"diversity effects\", \"sim-to-real transfer\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Incomplete understanding. Domain randomization trains on diverse synthetic domains improving robustness to real domain shifts, not just random colors.\"}"
    },
    {
        "context": "Anchor-Free Object Detection predicts object locations directly without predefined anchor boxes.",
        "question": "What advantage does anchor-free detection have over anchor-based methods?",
        "student_answer": "Anchor-free methods eliminate manual anchor design, reducing hyperparameter tuning. They predict object centers and sizes directly, simplifying architecture.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of hyperparameter reduction and architectural simplification benefits.\"}"
    },
    {
        "context": "Group Normalization normalizes by channel groups instead of batch statistics, maintaining performance with small batch sizes.",
        "question": "Why does group normalization work with small batches?",
        "student_answer": "Batch normalization relies on large batch statistics which become unreliable with few samples. Group normalization uses channel group statistics independent of batch size.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of batch size independence through group statistics.\"}"
    },
    {
        "context": "Structured Outputs in neural networks handle prediction of complex objects like sequences, trees, or graphs.",
        "question": "How do sequence labeling models handle variable-length outputs?",
        "student_answer": "Sequence models like BiLSTMs process sequences through RNN cells maintaining state, predicting labels for each position. CRF layers enforce sequence constraint validity.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of position-wise prediction and sequence constraint enforcement.\"}"
    },
    {
        "context": "Mixup regularization interpolates between training examples and labels to improve generalization and robustness.",
        "question": "Why does mixing labels along with features improve generalization?",
        "student_answer": "Label interpolation creates soft targets reducing overfitting to hard labels. Combined with feature interpolation, this encourages smooth decision boundaries.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of soft target regularization and smooth boundary learning.\"}"
    },
    {
        "context": "Gumbel-Softmax enables differentiable sampling from categorical distributions through temperature annealing.",
        "question": "How does Gumbel-Softmax enable backpropagation through discrete sampling?",
        "student_answer": "Gumbel-Softmax transforms discrete sampling into continuous approximation using temperature. Low temperatures recover discrete behavior while gradients flow during training.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of continuous relaxation and gradient flow recovery.\"}"
    },
    {
        "context": "Instance Normalization normalizes feature maps individually per sample rather than across batch.",
        "question": "Why is instance normalization better than batch normalization for style transfer?",
        "student_answer": "Batch normalization removes style information encoded in feature magnitude statistics. Instance normalization preserves style-specific statistics while normalizing content.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of style-content separation through instance normalization.\"}"
    },
    {
        "context": "Causal Masking in autoregressive models prevents future positions from attending to current or past.",
        "question": "Why is causal masking necessary for language generation?",
        "student_answer": "Causal masking ensures each position only attends to past positions, preventing data leakage during generation. This enables autoregressive decoding with sequential token generation.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of data leakage prevention and autoregressive sampling requirement.\"}"
    },
    {
        "context": "Subgroup Analysis evaluates model performance across demographic subgroups to identify disparate impacts.",
        "question": "Why is subgroup analysis important beyond overall accuracy?",
        "student_answer": "Overall accuracy can hide disparate performance across groups. Subgroup analysis reveals if the model systematically underperforms minorities or sensitive subpopulations.",
        "target_json": "{\"score_30\": 29, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of aggregate metric limitations and subgroup-specific bias detection.\"}"
    },
    {
        "context": "Scene Graphs represent images as structured scenes with objects and relationships.",
        "question": "How do scene graphs improve visual understanding?",
        "student_answer": "Scene graphs model objects and relationships providing structured semantic information. This enables reasoning about spatial relationships and interactions beyond pixel features.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of structured scene reasoning and relationship modeling.\"}"
    },
    {
        "context": "Neural ODE models treat residual blocks as continuous transformations providing memory efficiency.",
        "question": "What is the advantage of Neural ODEs over discrete residual networks?",
        "student_answer": "Neural ODEs compute continuous transformations with memory-efficient gradient computation. They handle variable-length sequences better and provide more expressive approximation.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of continuous transformation benefits and memory efficiency.\"}"
    },
    {
        "context": "Reversible Neural Networks use reversible blocks computing hidden states from outputs, reducing memory.",
        "question": "How do reversible networks reduce memory consumption?",
        "student_answer": "Reversible blocks compute activations on-the-fly during backpropagation instead of storing them. This trades computation for memory enabling larger batch sizes.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of computation-memory tradeoff and on-the-fly activation recovery.\"}"
    },
    {
        "context": "Concept Bottleneck Models use interpretable high-level concepts as intermediate representations.",
        "question": "What is the advantage of concept bottlenecks for interpretability?",
        "student_answer": "Concept bottlenecks force models to learn human-interpretable intermediate representations before predictions. This enables understanding which concepts models rely on.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of interpretability through explicit concept representation.\"}"
    },
    {
        "context": "Differentiable Reasoning integrates logical reasoning with neural networks through differentiable operations.",
        "question": "How can neural networks perform differentiable logical reasoning?",
        "student_answer": "Differentiable reasoning approximates logical operations through continuous functions like smooth AND/OR gates. This enables backpropagation while maintaining logical structure.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of continuous logic approximation enabling gradient-based reasoning.\"}"
    },
    {
        "context": "Implicit Bias in gradient descent describes implicit regularization biasing optimization toward simple solutions.",
        "question": "Why does gradient descent implicitly regularize?",
        "student_answer": "Gradient descent just optimizes the loss. It doesn't have any special regularization properties; it just finds whatever solution minimizes loss.",
        "target_json": "{\"score_30\": 10, \"key_coverage\": 1, \"missing_concepts\": [\"margin maximization\", \"norm minimization\", \"early stopping\"], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Wrong. Gradient descent has implicit bias toward simple solutions through margin maximization and norm minimization even without explicit regularization.\"}"
    },
    {
        "context": "Neural Collapse describes emergent structure in feature representations where class features form simplex geometry.",
        "question": "What is neural collapse and why does it emerge?",
        "student_answer": "Neural collapse is just a name for when neural networks converge. It doesn't really mean anything specific or important.",
        "target_json": "{\"score_30\": 8, \"key_coverage\": 0, \"missing_concepts\": [\"simplex structure\", \"distance optimization\", \"convergence behavior\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Dismissive and incorrect. Neural collapse describes specific simplex structure emerging from optimal within and between-class distance minimization in final layers.\"}"
    },
    {
        "context": "Lottery Ticket Magnitude Pruning removes weights below magnitude thresholds while maintaining accuracy.",
        "question": "Why can magnitude pruning remove 90% of weights while maintaining performance?",
        "student_answer": "Lottery ticket hypothesis suggests networks contain sparse subnetworks trained effectively. Magnitude pruning identifies important connections; removing unimportant weights has minimal impact.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect connection between lottery tickets and pruning effectiveness.\"}"
    },
    {
        "context": "Contextual Bandits extend multi-armed bandits by incorporating context to inform action selection.",
        "question": "How does context improve the exploration-exploitation tradeoff?",
        "student_answer": "Context enables learning policies mapping contexts to actions instead of learning fixed action values. This allows adapting decisions to specific situations.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of context-dependent policy learning and improved adaptation.\"}"
    },
    {
        "context": "Gradient Penalty in training GANs constrains gradient norms to stabilize training.",
        "question": "How does gradient penalty stabilize adversarial training?",
        "student_answer": "Gradient penalty just randomly modifies gradients. It doesn't really help with stability that much.",
        "target_json": "{\"score_30\": 11, \"key_coverage\": 1, \"missing_concepts\": [\"discriminator stability\", \"update moderation\", \"convergence\"], \"hallucinations\": [], \"bias_check\": true, \"feedback\": \"Incorrect and informal. Gradient penalty penalizes large gradients moderating discriminator updates, preventing rapid changes that cause training instability.\"}"
    },
    {
        "context": "Prototype Networks compute class prototypes from support examples for few-shot classification.",
        "question": "How do prototypical networks learn from few examples?",
        "student_answer": "Prototypical networks create class prototypes from support set examples, enabling classification from arbitrary numbers of shots. This differs from siamese networks requiring pair comparisons.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of flexible shot handling through prototype averaging.\"}"
    },
    {
        "context": "Momentum in optimization accumulates gradient history accelerating convergence especially through ravines.",
        "question": "Why does momentum help escape local minima and traverse ravines?",
        "student_answer": "Momentum accumulates velocity in consistent gradient directions while canceling oscillations in ravine directions. This enables traversing shallow ravines.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of oscillation damping and ravine traversal through accumulated velocity.\"}"
    },
    {
        "context": "Hierarchical Reinforcement Learning decomposes problems into task hierarchies with shared policies.",
        "question": "What advantage does hierarchical RL provide?",
        "student_answer": "Hierarchical RL enables learning reusable skills at multiple levels. Higher-level policies coordinate skills, reducing exploration space and enabling skill transfer.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of skill reusability and exploration reduction through hierarchy.\"}"
    },
    {
        "context": "Prototypical Examples are archetypal instances representing class prototypes for understanding model predictions.",
        "question": "How can prototypical examples improve model trust?",
        "student_answer": "Prototypical examples show what the model considers typical for each class. This clarifies understanding and enables debugging predictions by comparing to prototypes.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of transparency and debugging benefits through prototypes.\"}"
    },
    {
        "context": "Double Q-Learning addresses overestimation in Q-learning using separate networks for action selection and evaluation.",
        "question": "Why does overestimation harm Q-learning?",
        "student_answer": "Overestimated Q-values lead to selecting suboptimal actions. This causes policy divergence and poor convergence because agents believe actions are better than reality.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of overestimation cascades and policy divergence.\"}"
    },
    {
        "context": "Adversarial Training improves robustness by training on adversarial examples alongside natural examples.",
        "question": "What is the robustness-accuracy tradeoff?",
        "student_answer": "Robust models often have lower accuracy on clean data because robustness constrains the hypothesis space. They require learning patterns generalizing to perturbations.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of hypothesis space constraint and accuracy-robustness tension.\"}"
    },
    {
        "context": "Progressive Neural Networks learn new tasks by adding new columns while freezing previous task parameters.",
        "question": "How do progressive networks prevent catastrophic forgetting?",
        "student_answer": "Progressive networks freeze old task parameters and add new columns for new tasks. Old representations stay unchanged, preventing overwriting.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of frozen parameters and prevention through isolation.\"}"
    },
    {
        "context": "Influence Functions trace predictions back to training examples identifying influential samples.",
        "question": "How can influence functions help debug models?",
        "student_answer": "Influence functions trace influential training examples, identifying which samples most affected specific predictions. Examining these reveals data quality issues causing errors.",
        "target_json": "{\"score_30\": 28, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of data source identification for error diagnosis.\"}"
    },
    {
        "context": "Episodic Memory in RL agents stores experiences enabling fast adaptation through retrieving similar past episodes.",
        "question": "What advantage does episodic memory provide?",
        "student_answer": "Episodic memory enables rapid adaptation to new tasks by retrieving similar experiences without retraining. This is faster than gradient-based learning.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Excellent explanation of memory-based fast adaptation versus gradient-based learning.\"}"
    },
    {
        "context": "Sinkhorn Distances use optimal transport with entropic regularization for efficient distribution comparison.",
        "question": "Why is entropic regularization important?",
        "student_answer": "Entropic regularization smooths solutions enabling differentiable algorithms and providing convergence guarantees lacking in unregularized transport.",
        "target_json": "{\"score_30\": 27, \"key_coverage\": 3, \"missing_concepts\": [], \"hallucinations\": [], \"bias_check\": false, \"feedback\": \"Perfect explanation of computational smoothing and convergence guarantees.\"}"
    }
]






